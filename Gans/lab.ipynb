{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVWoX5adp7bx",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Week 4 : Generative Adversarial Networks\n",
        "```\n",
        "- Generative Artificial Intelligence (Fall semester 2023)\n",
        "- Professor: Muhammad Fahim\n",
        "- Teaching Assistant: Gcinizwe Dlamini\n",
        "```\n",
        "<hr>\n",
        "\n",
        "\n",
        "```\n",
        "Lab Plan\n",
        "    1. Vanila GAN achitecture\n",
        "    2. GAN training procedure\n",
        "    3. Conditional GAN\n",
        "```\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yMz7v3Yp7cA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 1. Vannila Generative adversarial network (GAN)\n",
        "\n",
        "![caption](https://www.researchgate.net/profile/Zhaoqing-Pan/publication/331756737/figure/fig1/AS:736526694621184@1552613056409/The-architecture-of-generative-adversarial-networks.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lE55zaEp7cA",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### 1.1 Dataset\n",
        "\n",
        "For this lesson we will use SVHN dataset which readily available in `torchvision` and we will do minimal transformation operations\n",
        "\n",
        "Install `torchvision` : `pip install torchvision`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgVjuBIo9YcY",
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abcec07f-d273-4c6b-ea86-9e5f4c21a17a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to data/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:02<00:00, 90779375.10it/s] \n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize([32, 32]),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "# SVHN training datasets\n",
        "svhn_train = datasets.SVHN(root='data/', split='train', download=True, transform=transform)\n",
        "\n",
        "batch_size = 256\n",
        "num_workers = 0\n",
        "\n",
        "# build DataLoaders for SVHN dataset\n",
        "train_loader = torch.utils.data.DataLoader(dataset=svhn_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwRO4sTip7cC",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 1.2 Generator & Discriminator Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyAK6ydmp7cC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#ngf : Number of generator filters\n",
        "#ndf : Number of discriminator filters\n",
        "nz = 32\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, ndf=3, conv_dim=32):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, ndf, 4, 2, 1, bias=False),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf * 2, 1, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(5*5,1),\n",
        "            nn.Sigmoid()\n",
        "          )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Step 1: pass the input (real or fake samples) through all hidden layers\n",
        "        return self.model(x)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, z_size, ngf, conv_dim=32):\n",
        "        super(Generator, self).__init__()\n",
        "        # Step 1: Define the generator network architecture\n",
        "        # NOTE: the input is the random noise size and output is conv_dim i.e (3,32,32)\n",
        "        self.conv_dim = conv_dim\n",
        "        self.input_layer = nn.Linear(in_features=z_size, out_features=2048, bias=True)\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_channels = 128, out_channels=ngf * 2, kernel_size=4,stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(num_features= ngf * 2),\n",
        "            nn.Tanh(),\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(num_features=ngf),\n",
        "            nn.Tanh(),\n",
        "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      # Step 1: pass the input which is random noise to generate the face samples\n",
        "      x = self.input_layer(x)\n",
        "      x = x.view(-1, self.conv_dim*4, 4, 4) # (batch_size, depth, 4, 4)\n",
        "      return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://www.researchgate.net/publication/336144594/figure/fig2/AS:808881324322820@1569863744938/An-example-of-the-deconvolution-process-using-transpose-convolution-In-the-figure.png)"
      ],
      "metadata": {
        "id": "YhvmtYs7VjlJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epToMkpwp7cD",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 1.3 Set hyperparams and training parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RgJwvYBp7cD",
        "outputId": "3ec40f12-c969-423a-e888-4c97a8268a3c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discriminator(\n",
            "  (model): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=25, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Generator(\n",
            "  (input_layer): Linear(in_features=100, out_features=2048, bias=True)\n",
            "  (model): Sequential(\n",
            "    (0): ConvTranspose2d(128, 6, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Tanh()\n",
            "    (3): ConvTranspose2d(6, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): Tanh()\n",
            "    (6): ConvTranspose2d(3, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# define hyperparams\n",
        "conv_dim = 32\n",
        "z_size = 100\n",
        "num_epochs = 10\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define discriminator and generator\n",
        "D = Discriminator(conv_dim).to(device)\n",
        "G = Generator(z_size=z_size, ngf=3,conv_dim=conv_dim).to(device)\n",
        "\n",
        "#print the models summary\n",
        "print(D)\n",
        "print()\n",
        "print(G)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHnvFXdzp7cE",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 1.4 Define the loss function for D(x) and G(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6KcJQGIp7cE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def real_loss(D_out, smooth=False):\n",
        "    batch_size = D_out.size(0)\n",
        "    # label smoothing\n",
        "    if smooth:\n",
        "        # smooth, real labels\n",
        "        labels = torch.FloatTensor(batch_size).uniform_(0.9, 1).to(device)\n",
        "    else:\n",
        "        labels = torch.ones(batch_size) # real labels = 1\n",
        "    # move labels to GPU if available\n",
        "\n",
        "    labels = labels.to(device)\n",
        "    # binary cross entropy with logits loss\n",
        "    criterion = nn.BCELoss()\n",
        "    # calculate loss\n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    return loss\n",
        "\n",
        "def fake_loss(D_out):\n",
        "    batch_size = D_out.size(0)\n",
        "    labels = torch.FloatTensor(batch_size).uniform_(0, 0.1).to(device) # fake labels = 0\n",
        "    labels = labels.to(device)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    # calculate loss\n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    return loss\n",
        "\n",
        "# params\n",
        "learning_rate = 0.0003\n",
        "beta1=0.5\n",
        "beta2=0.999 # default value\n",
        "\n",
        "# Create optimizers for the discriminator and generator\n",
        "d_optimizer = optim.Adam(D.parameters(), learning_rate)\n",
        "g_optimizer = optim.SGD(G.parameters(), learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkWInd2sp7cG",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 2. GAN training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tQDq36wp7cG",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Logging\n",
        "print_every = 2\n",
        "\n",
        "# Get some fixed data for sampling. These are images that are held\n",
        "# constant throughout training, and allow us to inspect the model's performance\n",
        "sample_size=16\n",
        "fixed_z = np.random.uniform(-1, 1, size=(sample_size, z_size))\n",
        "fixed_z = torch.from_numpy(fixed_z).float()\n",
        "\n",
        "# train the network\n",
        "for epoch in range(num_epochs):\n",
        "  g_l = 0\n",
        "  d_l = 0\n",
        "  for batch_i, (real_images, _) in enumerate(train_loader):\n",
        "\n",
        "    batch_size = real_images.size(0)\n",
        "\n",
        "\n",
        "    # TRAIN THE DISCRIMINATOR\n",
        "    # Step 1: Zero gradients (zero_grad)\n",
        "    # Step 2: Train with real images\n",
        "    # Step 3: Compute the discriminator losses on real images\n",
        "    d_optimizer.zero_grad()\n",
        "    real_images = real_images.to(device)\n",
        "    D_real = D(real_images)\n",
        "    d_real_loss = real_loss(D_real)\n",
        "\n",
        "    # Step 4: Train with fake images\n",
        "    # Step 5: Generate fake images and move x to GPU, if available\n",
        "    # Step 6: Compute the discriminator losses on fake images\n",
        "    # Step 7: add up loss and perform backprop\n",
        "\n",
        "    z = torch.FloatTensor(batch_size, z_size).uniform_(-1, 1).to(device)\n",
        "    fake_images = G(z)\n",
        "\n",
        "    D_fake = D(fake_images)\n",
        "    d_fake_loss = fake_loss(D_fake)\n",
        "\n",
        "    d_loss = d_real_loss + d_fake_loss\n",
        "    d_l += d_loss.item()\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step() # The\n",
        "\n",
        "\n",
        "    #TRAIN THE GENERATOR (Train with fake images and flipped labels)\n",
        "    g_optimizer.zero_grad()\n",
        "\n",
        "    # Step 1: Zero gradients\n",
        "    # Step 2: Generate fake images from random noise (z)\n",
        "    # Step 3: Compute the discriminator losses on fake images using flipped labels!\n",
        "    # Step 4: Perform backprop and take optimizer step\n",
        "    z = torch.FloatTensor(batch_size, z_size).uniform_(-1, 1).to(device)\n",
        "\n",
        "    fake_images = G(z)\n",
        "\n",
        "    D_fake = D(fake_images)\n",
        "    g_loss = real_loss(D_fake)\n",
        "    g_l += g_loss.item()\n",
        "\n",
        "    g_loss.backward()\n",
        "    g_optimizer.step()\n",
        "\n",
        "\n",
        "  # Print some loss stats\n",
        "  if epoch % print_every == 0:\n",
        "    print(\"Epoch: \" + str(epoch + 1) + \"/\" + str(num_epochs)\n",
        "          + \"\\td_loss:\" + str(round(d_l/len(train_loader), 4))\n",
        "          + \"\\tg_loss:\" + str(round(g_l/len(train_loader), 4))\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQsNSLUy-sbV",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Keep in mind:\n",
        "\n",
        "1. Always use a learning rate for discriminator higher than the generator.\n",
        "2. Keep training even if you see that the losses are going up.\n",
        "3. There are many variations with different loss functions which are worth exploring.\n",
        "4. If you get mode collapse, lower the learning rates.\n",
        "5. Adding noise to the training data helps make the model more stable.\n",
        "6. Label Smoothing: instead of making the labels as 1 make it 0.9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Conditional GAN"
      ],
      "metadata": {
        "id": "S__H73zr5HEd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://www.researchgate.net/profile/Gerasimos-Spanakis/publication/330474693/figure/fig1/AS:956606955139072@1605084279074/GAN-conditional-GAN-CGAN-and-auxiliary-classifier-GAN-ACGAN-architectures-where-x_Q320.jpg)"
      ],
      "metadata": {
        "id": "zybSTQqkKnRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Read Data"
      ],
      "metadata": {
        "id": "mOUeY__xaVYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "transform = transforms.Compose([transforms.Resize([32, 32]),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize([0.5], [0.5])])\n",
        "\n",
        "# SVHN training datasets\n",
        "svhn_train = datasets.SVHN(root='data/', split='train', download=True, transform=transform)\n",
        "\n",
        "batch_size = 256\n",
        "num_workers = 0\n",
        "\n",
        "# build DataLoaders for SVHN dataset\n",
        "train_loader = torch.utils.data.DataLoader(dataset=svhn_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=num_workers)"
      ],
      "metadata": {
        "id": "a-Gea6EhaZcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Define helper functions"
      ],
      "metadata": {
        "id": "DMPxfzyWayQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(c_in, c_out, k_size=4, stride=2, pad=1, use_bn=True, transpose=False):\n",
        "  module = []\n",
        "  if transpose:\n",
        "    module.append(nn.ConvTranspose2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
        "  else:\n",
        "    module.append(nn.Conv2d(c_in, c_out, k_size, stride, pad, bias=not use_bn))\n",
        "  if use_bn:\n",
        "    module.append(nn.BatchNorm2d(c_out))\n",
        "  return nn.Sequential(*module)"
      ],
      "metadata": {
        "id": "MVpI4qOla3vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Define Generator\n",
        "\n",
        "<font color='red'>**TODO:** Define Generator using achitecture of your choice</font>"
      ],
      "metadata": {
        "id": "qMM4WBWbXgS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU8Q-hacSger"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim=10, num_classes=10, label_embed_size=5, channels=3, conv_dim=64):\n",
        "    super(Generator, self).__init__()\n",
        "    self.image_size = 32\n",
        "    self.label_embedding = nn.Embedding(num_classes, label_embed_size)\n",
        "    self.l1 = conv_block(z_dim + label_embed_size, conv_dim * 4, pad=0, transpose=True)\n",
        "    self.l2 = None\n",
        "    self.l3 = None\n",
        "    self.l4 = None\n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "      if isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "  def forward(self, x, condition):\n",
        "    x = x.reshape([x.shape[0], -1, 1, 1])\n",
        "    condition_embed = self.label_embedding(condition)\n",
        "    condition_embed = condition_embed.reshape([condition_embed.shape[0], -1, 1, 1])\n",
        "    x = torch.cat((x, condition_embed), dim=1)\n",
        "    x = None # TODO\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.4 Define Discriminator\n",
        "\n",
        "<font color='red'>**TODO:** Define Discriminator using achitecture of your choice</font>"
      ],
      "metadata": {
        "id": "0-F0-FzYXtu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, num_classes=10, channels=3, conv_dim=64):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.image_size = 32\n",
        "    self.condition_embedding = nn.Embedding(num_classes, self.image_size*self.image_size)\n",
        "    self.conv1 = conv_block(channels + 1, conv_dim, use_bn=False)\n",
        "    self.conv2 = None\n",
        "    self.conv3 = None\n",
        "    self.conv4 = None\n",
        "\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "\n",
        "      if isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "  def forward(self, x, condition):\n",
        "    alpha = 0.2\n",
        "    condition_embed = self.condition_embedding(condition)\n",
        "    condition_embed = condition_embed.reshape([condition_embed.shape[0], 1, self.image_size, self.image_size])\n",
        "    x = torch.cat((x, condition_embed), dim=1)\n",
        "    x = None\n",
        "    return x.squeeze()"
      ],
      "metadata": {
        "id": "ubM2XPwAXyN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Assemble a cGAN"
      ],
      "metadata": {
        "id": "4Wi5y3v95qiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define discriminator and generator\n",
        "z_dim = 10\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "G = Generator(z_dim=z_dim, num_classes=10, label_embed_size=5, channels=3).to(device)\n",
        "D = Discriminator(num_classes=10, channels=3).to(device)\n",
        "\n",
        "#print the models summary\n",
        "print(D)\n",
        "print()\n",
        "print(G)"
      ],
      "metadata": {
        "id": "sEVm_ro7cOYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6 Define optimizer and criterion"
      ],
      "metadata": {
        "id": "ix0Gkl3M5avr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999), weight_decay=2e-5)\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "0wDpF1MyeWkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.7 Training conditional GAN (training loop)\n",
        "\n",
        "\n",
        "<font color='red'>**TODO:** Train conditional GAN</font>\n"
      ],
      "metadata": {
        "id": "sMHzU0UsgdOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "num_epochs = 5\n",
        "\n",
        "# Labels\n",
        "real_label = torch.FloatTensor(batch_size).uniform_(0.9, 1).to(device) # torch.ones(batch_size)\n",
        "fake_label = torch.FloatTensor(batch_size).uniform_(0, 0.1).to(device)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  G.train()\n",
        "  D.train()\n",
        "  for batch_i, (x_real, y_real) in enumerate(train_loader):\n",
        "    batch_size = x_real.size(0)\n",
        "    x_real = x_real.to(device)\n",
        "    y_real = y_real.to(device)\n",
        "\n",
        "    # TODO\n",
        "    # TRAIN THE DISCRIMINATOR\n",
        "    # Step 1: Zero gradients (zero_grad)\n",
        "    # Step 2: Train with real images\n",
        "    # Step 3: Compute the discriminator losses on real images\n",
        "\n",
        "    # Step 4: Train with fake images\n",
        "    # Step 5: Generate fake images and move x to GPU, if available\n",
        "    # Step 6: Compute the discriminator losses on fake images\n",
        "    # Step 7: add up loss and perform backprop\n",
        "\n",
        "\n",
        "    #TRAIN THE GENERATOR\n",
        "    # Step 1: Zero gradients\n",
        "    # Step 2: Generate fake images from random noise (z) and condition (y)\n",
        "    # Step 3: Compute the discriminator losses on fake images using flipped labels (labels -- true/fake)\n",
        "    # Step 4: Perform backprop and take optimizer step\n",
        "\n",
        "  # Print the loss for each epoch"
      ],
      "metadata": {
        "id": "dQZdP1b6ch41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resources\n",
        "\n",
        "* [Deconvolutional Networks](https://www.matthewzeiler.com/mattzeiler/deconvolutionalnetworks.pdf)\n",
        "* [PyTorch `ConvTranspose2d`](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html)\n",
        "* [Computational Imaging and Display](https://stanford.edu/class/ee367/reading/lecture6_notes.pdf)"
      ],
      "metadata": {
        "id": "YIL8lzAZUdbN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zE0YMR7XVL6r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}