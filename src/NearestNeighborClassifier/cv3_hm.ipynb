{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1c4d85",
   "metadata": {},
   "source": [
    "The code was originally written in a python script. Nevertheless, I chose to submit a jupyter notebook as it saves the code's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script contains functionalities to implement an unconventional parametric classifier\n",
    "\"\"\"\n",
    "import random\n",
    "import numpy.random\n",
    "import os\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "script_dir = os.getcwd()\n",
    "\n",
    "# a function to load the data into numpy arrays\n",
    "def load_data() -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    from torchvision import datasets, transforms as tr\n",
    "    import torch\n",
    "\n",
    "    if not os.path.isdir(os.path.join(script_dir, 'data')):\n",
    "        raise ValueError(f\"Please create a directory 'data' in the script's parent directory\")\n",
    "\n",
    "    data_folder = os.path.join(os.getcwd(), 'data')\n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "    # apply toTensor transform to each of the images\n",
    "    basic_transform = tr.Compose([tr.ToTensor()])\n",
    "    # use Pytorch to load the dataset\n",
    "    cifar_train = datasets.CIFAR10(root=os.path.join(data_folder, 'train'), train=True, download=True,\n",
    "                                   transform=basic_transform)\n",
    "    cifar_test = datasets.CIFAR10(root=os.path.join(data_folder, 'test'), train=False, download=False,\n",
    "                                  transform=basic_transform)\n",
    "\n",
    "    # build a loader for each split\n",
    "    from torch.utils.data import DataLoader\n",
    "    # convert the dataset to a Dataloader for easier manipulation\n",
    "    train_loader = DataLoader(cifar_train, batch_size=1000, shuffle=False)\n",
    "    test_loader = DataLoader(cifar_test, batch_size=1000, shuffle=False)\n",
    "\n",
    "    train_tensor = torch.stack([data for data, _ in train_loader])\n",
    "    test_tensor = torch.stack([data for data, _ in test_loader])\n",
    "\n",
    "    train_np = train_tensor.permute((0, 1, 3, 4, 2)).reshape(shape=(len(cifar_train), -1)).numpy()\n",
    "    test_np = test_tensor.permute((0, 1, 3, 4, 2)).reshape(shape=(len(cifar_test), -1)).numpy()\n",
    "\n",
    "    train_labels = torch.stack([labels for _, labels in train_loader]).reshape((-1,)).numpy()\n",
    "    test_labels = torch.stack([labels for _, labels in test_loader]).reshape((-1,)).numpy()\n",
    "\n",
    "    # the normalization of the image is necessary to avoid as many numerical issues as possible\n",
    "    # since softmax is really prone to the overflow problem\n",
    "    return train_np / 255, test_np / 255, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a70374a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next 2 functions are not technically ones of the classifier's functionalities\n",
    "# and thus will be written outside the class definition\n",
    "def softmax(array: np.ndarray):\n",
    "    if len(array.shape) != 1:\n",
    "        raise ValueError(f\"The input is expected to be 1 dimensional. Found: {len(array.shape)} dimensions\")\n",
    "\n",
    "    sum_exp = np.sum(np.exp(array))\n",
    "    return np.exp(array) / sum_exp\n",
    "\n",
    "\n",
    "def cross_entropy_loss(probs: np.ndarray, y_true: np.ndarray) -> float:\n",
    "    y_true = y_true.squeeze()\n",
    "    # as this condition is satisfied, proceed with\n",
    "    selection = probs[np.arange(len(probs)), y_true]\n",
    "    # calculate the cross entropy loss\n",
    "    loss = -np.sum(np.log(selection))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# write a function to compute the accuracy of some prediction against given labels\n",
    "def compute_accuracy(predictions: np.ndarray, y_true: np.ndarray) -> float:\n",
    "    return np.mean((predictions == y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42207a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeirdClassifier:\n",
    "    def __init__(self,\n",
    "                 input_features: int,\n",
    "                 num_classes: int,\n",
    "                 choices: int = 10 ** 3,\n",
    "                 seed: int = 69):\n",
    "        # set the seed for reproducibility\n",
    "        numpy.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        # number of input units\n",
    "        self.in_features = input_features\n",
    "        # number of output units: depends on the number of classes\n",
    "        self.out_features = num_classes if num_classes > 2 else num_classes\n",
    "        # the weights matrix: of shape\n",
    "        self.w = np.random.rand(self.in_features, self.out_features)\n",
    "        self.choices = choices\n",
    "        self.fit = False\n",
    "\n",
    "    def _compute_probs(self, x: np.ndarray) -> np.ndarray:\n",
    "        # 2 conditions must be satisfied: all values must be in the range [0, 1]\n",
    "        # the input must be a 2-dimensional matrix of shape : batch_size, self.in_features\n",
    "        if ((x < 0) & (x > 1)).any():\n",
    "            raise ValueError(\"The input is expected to have all values within the range [0, 1]\")\n",
    "\n",
    "        if len(x.shape) != 2 or x.shape[1] != self.in_features:\n",
    "            raise ValueError(f'The function expects a matrix with dimensions: {(None, self.in_features)}'\n",
    "                             f'\\nFound: {x.shape}')\n",
    "\n",
    "        logits = x @ self.w\n",
    "        # apply the softmax operation to each row\n",
    "        probs = np.apply_along_axis(softmax, axis=1, arr=logits)\n",
    "        return probs\n",
    "\n",
    "    def train(self,\n",
    "              x: np.ndarray,\n",
    "              y: np.ndarray):\n",
    "\n",
    "        min_loss = float('inf')\n",
    "        best_weight = None\n",
    "        \n",
    "        report_progress = self.choices // 25\n",
    "\n",
    "        for index in range(self.choices):                \n",
    "            if (index + 1) % report_progress == 0:\n",
    "                print(f\"{index + 1} choices considered\")\n",
    "                \n",
    "            self.w = np.random.rand(self.in_features, self.out_features)\n",
    "            # calculate the predictions and loss\n",
    "            predictions = self._compute_probs(x)\n",
    "            loss = cross_entropy_loss(predictions, y)\n",
    "            # update weight\n",
    "            best_weight = self.w if best_weight is None or loss < min_loss else best_weight\n",
    "            # update loss\n",
    "            min_loss = min(loss, min_loss)\n",
    "\n",
    "        self.fit = True\n",
    "        # set the weight\n",
    "        self.w = best_weight\n",
    "\n",
    "    def predict(self,\n",
    "                x: np.ndarray,\n",
    "                requires_train: bool = True):\n",
    "\n",
    "        if requires_train and not self.fit:\n",
    "            raise RuntimeError(f\"The model must be trained before performing predictions\")\n",
    "\n",
    "        probs = self._compute_probs(x)\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6942ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "train_x, test_x, train_y, test_y = load_data()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = WeirdClassifier(input_features=3072, num_classes=10)\n",
    "classifier.train(train_x, train_y)\n",
    "y_pred = classifier.predict(test_x)\n",
    "# evaluate the model\n",
    "accuracy = compute_accuracy(y_pred, test_y)\n",
    "print(f\"the model achieves an accuracy of {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
