{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load the data from pytorch\n",
    "import torch\n",
    "import os\n",
    "from torchvision import datasets, transforms as tr\n",
    "data_folder = os.path.join(os.getcwd(), 'data')\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# apply toTensor transform to each of the images\n",
    "basic_transform  = tr.Compose([tr.ToTensor()])\n",
    "# use Pytorch to load the dataset\n",
    "cifar_train = datasets.CIFAR10(root=os.path.join(data_folder, 'train'), train=True, download=True, transform=basic_transform)\n",
    "cifar_test = datasets.CIFAR10(root=os.path.join(data_folder, 'test'), train=False, download=True, transform=basic_transform)\n",
    "\n",
    "# build a loader for each split\n",
    "from torch.utils.data import DataLoader\n",
    "# convert the dataset to a Dataloader for easier manipulation\n",
    "train_loader = DataLoader(cifar_train, batch_size=1000, shuffle=False) \n",
    "test_loader = DataLoader(cifar_test, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save each of test and train splits in a single tensor\n",
    "# the after stacking the different batches together: the output will be of the shape: 50, 1000, 3, 32, 32\n",
    "train_tensor = torch.stack([data for data, _ in train_loader])\n",
    "test_tensor = torch.stack([data for data, _ in test_loader])\n",
    "\n",
    "\n",
    "# converting the different batches into a single large one while flattening each image in the batch \n",
    "# in other words, we will have a large tensor of shape (number of samples, number of pixels )\n",
    "train_np = train_tensor.permute((0, 1, 3, 4, 2)).reshape(shape=(len(cifar_train), -1)).numpy()\n",
    "test_np = test_tensor.permute((0, 1, 3, 4, 2)).reshape(shape=(len(cifar_test), -1)).numpy()\n",
    "    \n",
    "train_labels = torch.stack([labels for _, labels in train_loader]).reshape((-1,)).numpy()\n",
    "test_labels = torch.stack([labels for _, labels in test_loader]).reshape((-1,)).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(10000, 3072)\n",
      "(50000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# make sure the shapes are as expected\n",
    "print(train_np.shape)\n",
    "print(test_np.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "class KnnClassifier:\n",
    "    def __init__(self, k: int = 1) -> None:\n",
    "        self.k = k\n",
    "        self._train_data = None\n",
    "        self._train_labels = None           \n",
    "\n",
    "    def fit(self, train_data: np.ndarray, labels: np.ndarray):\n",
    "        # make sure to convert the data to numpy arrays\n",
    "        # saving the data as np.unint8 speeds the algorithm\n",
    "        self._train_data = train_data.astype(np.uint8)\n",
    "        self._train_labels = labels.astype(np.uint8)\n",
    "\n",
    "    def _predict(self, image: np.ndarray) -> int:        \n",
    "        # first apply np.abs(image - self._train_data): numpy will broadcast the image from (1, num_pixels) to (50000, num_pixes) \n",
    "        # np.abs(image-self._Train_data) will be the difference of difference in absolute value between the image and each item in the training data\n",
    "        # np sum() sums these difference and sum_difference is a numpy array of the shape (50000, 1)\n",
    "        sum_difference = np.sum(np.abs(image - self._train_data), axis=-1)\n",
    "        # find the indices of the 'k' nearest training samples: which correspond to the ones with the least difference        \n",
    "        k_indices = np.argsort(sum_difference, axis=-1)[:self.k].squeeze()\n",
    "        # use the extracted indices to extract the labels\n",
    "        k_labels = self._train_labels[k_indices] \n",
    "        # use majority voting: Counter counts the frequency of elements and most_common()functions returns a sorted list: [(item, frequency)]\n",
    "        # indexing by [0][0] returns the most common label in the neighborhood\n",
    "        return Counter(k_labels).most_common()[0][0]\n",
    "    \n",
    "    def predict(self, test_data:np.ndarray):\n",
    "        # apply list comprehension of efficency\n",
    "        return [self._predict(t) for t in tqdm(test_data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/10000 [00:08<47:46,  3.48it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m classifier \u001b[39m=\u001b[39m KnnClassifier(\u001b[39m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m classifier\u001b[39m.\u001b[39mfit(train_np, train_labels)\n\u001b[0;32m----> 4\u001b[0m predictions \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mpredict(test_np)\n",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36mKnnClassifier.predict\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, test_data:np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# apply list comprehension of efficency\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(t) \u001b[39mfor\u001b[39;49;00m t \u001b[39min\u001b[39;49;00m tqdm(test_data)]\n",
      "Cell \u001b[0;32mIn[6], line 31\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, test_data:np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# apply list comprehension of efficency\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tqdm(test_data)]\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mKnnClassifier._predict\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, image: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:        \n\u001b[1;32m     17\u001b[0m     \u001b[39m# first apply np.abs(image - self._train_data): numpy will broadcast the image from (1, num_pixels) to (50000, num_pixes) \u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m# np.abs(image-self._Train_data) will be the difference of difference in absolute value between the image and each item in the training data\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# np sum() sums these difference and sum_difference is a numpy array of the shape (50000, 1)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     sum_difference \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39;49mabs(image \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_data), axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[39m# find the indices of the 'k' nearest training samples: which correspond to the ones with the least difference        \u001b[39;00m\n\u001b[1;32m     22\u001b[0m     k_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(sum_difference, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk]\u001b[39m.\u001b[39msqueeze()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialize a Knn classifier with k=5\n",
    "classifier = KnnClassifier(5)\n",
    "classifier.fit(train_np, train_labels)\n",
    "predictions = classifier.predict(test_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.155\n"
     ]
    }
   ],
   "source": [
    "accuray = np.mean((predictions == test_labels))\n",
    "print(round(accuray, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
