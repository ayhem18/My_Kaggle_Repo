{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "I am using the following dataset publicly available on [Kaggle](https://www.kaggle.com/datasets/mbkinaci/image-localization-dataset?select=training_images)\n",
    "\n",
    "To run the notebook, please dowload the dataset and save it in the same directory as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    home = os.path.dirname(os.path.realpath(__file__))\n",
    "except Exception:\n",
    "    home = os.getcwd()\n",
    "    \n",
    "current = home\n",
    "\n",
    "while 'tinyBackProp' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "sys.path.append(os.path.join(str(current)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(home, 'training_images')\n",
    "if not os.path.isdir(data_folder):\n",
    "    raise ValueError(f\"PLEASE MAKE SURE THE DATA IS DOWNLOADED AND UNZIPPED IN THE SAME DIRECTORY AS THE NOTEBOOK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(os.path.join(data_folder, 'training_images')):\n",
    "    shutil.rmtree(os.path.join(data_folder, 'training_images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.dom.minidom\n",
    "\n",
    "def get_annotations(xml_file):\n",
    "    xml_doc = xml.dom.minidom.parse(xml_file)\n",
    "    bbox = xml_doc.getElementsByTagName('bndbox')[0]\n",
    "    anns = []\n",
    "    for c in bbox.childNodes:\n",
    "        data = c.childNodes\n",
    "        for d in data:\n",
    "            if len(d) > 0:\n",
    "                anns.append(d.nodeValue)\n",
    "\n",
    "    return anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's display some images\n",
    "import cv2 as cv\n",
    "import torch\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "import json\n",
    "def prepare_files(folder):\n",
    "    initial_data = os.listdir(folder)\n",
    "    for f in initial_data:\n",
    "        if f.startswith('eggplant') and f.endswith('xml'):\n",
    "            os.remove(os.path.join(folder, f)) \n",
    "        \n",
    "        elif f.endswith('xml'):\n",
    "            d = get_annotations(os.path.join(folder, f))\n",
    "            # save the data as json\n",
    "            x0, y0, x1, y1 = float(d[0]) / 227, float(d[1]) / 227, float(d[2]) / 227, float(d[3]) / 227\n",
    "            data = {\"x0\": x0, \"y0\": y0, \"x1\": x1, \"y1\": y1}\n",
    "            data_file_name = os.path.splitext(f)[0] + \".json\" \n",
    "            with open(os.path.join(folder, data_file_name), 'w') as fp:\n",
    "                json.dump(data, fp)\n",
    "            os.remove(os.path.join(folder, f))\n",
    "        else:\n",
    "            image = cv.imread(os.path.join(folder, f))\n",
    "            if image.shape != (56, 56, 3):\n",
    "                image = cv.resize(image, (56, 56))\n",
    "            # save the resized image\n",
    "            cv.imwrite(os.path.join(folder, f), image)\n",
    "\n",
    "# prepare_files(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/ayhem18/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "for index, f in enumerate(os.listdir(data_folder)):\n",
    "    if f.endswith('.jpg') and not f.startswith('eggplant'):\n",
    "        \n",
    "        anns_file_name = os.path.splitext(f)[0] + \".json\" \n",
    "\n",
    "        with open(os.path.join(data_folder, anns_file_name), 'r') as fp:\n",
    "            d = json.load(fp)\n",
    "            x0, y0, x1, y1 = float(d['x0']), float(d['y0']), float(d['x1']), float(d['y1']) \n",
    "\n",
    "            image = cv.imread(os.path.join(data_folder, f))\n",
    "\n",
    "            x0 = int(x0 * image.shape[1]) \n",
    "            y0 = int(y0 * image.shape[0]) \n",
    "\n",
    "            x1 = int(x1 * image.shape[1]) \n",
    "            y1 = int(y1 * image.shape[0]) \n",
    "\n",
    "            cv.rectangle(image, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "            cv.imshow('image', image)\n",
    "            cv.waitKey(0)\n",
    "            cv.destroyWindow(winname='image')    \n",
    "    if index >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def prepare_data(folder):\n",
    "    data, labels, boxes = [], [], []\n",
    "    for f in os.listdir(folder):\n",
    "        if f.endswith('jpg'):\n",
    "            # read the image\n",
    "            im = np.moveaxis(cv.imread(os.path.join(folder, f)), source=2, destination=0) \n",
    "            data.append(im)\n",
    "\n",
    "            if f.startswith('eggplant'):\n",
    "                boxes.append([-1, -1, -1, -1])    \n",
    "                labels.append(0)\n",
    "            else:\n",
    "                anns_file_name = os.path.splitext(f)[0] + \".json\" \n",
    "                with open(os.path.join(data_folder, anns_file_name), 'r') as fp:\n",
    "                    d = json.load(fp)\n",
    "                    x0, y0, x1, y1 = float(d['x0']), float(d['y0']), float(d['x1']), float(d['y1']) \n",
    "                    boxes.append([x0, y0, x1, y1])\n",
    "                    labels.append((1 if f.startswith('cucumber') else 2))\n",
    "\n",
    "    return np.asarray(data), np.asarray(labels), np.asarray(boxes)\n",
    "\n",
    "data, labels, boxes = prepare_data(data_folder)\n",
    "data = data / 255.0\n",
    "train_x, test_x, train_y, test_y, train_b, test_b = train_test_split(data, labels, boxes, test_size=0.05, random_state=69, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 3, 56, 56) (176,) (176, 4)\n",
      "(10, 3, 56, 56) (10,) (10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, train_b.shape)\n",
    "print(test_x.shape, test_y.shape, test_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([59, 59, 58]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import nn\n",
    "from tinyBackProp.network import Network\n",
    "from tinyBackProp.linear_layer import LinearLayer\n",
    "from tinyBackProp.conv_layer import ConvLayer\n",
    "from tinyBackProp.flatten import FlattenLayer\n",
    "from tinyBackProp.activation_layers import SigmoidLayer, SoftmaxLayer, ReLULayer\n",
    "from tinyBackProp.losses import MSELoss, CrossEntropyLoss\n",
    "import torch\n",
    "torch.manual_seed(69)\n",
    "np.random.seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cw1: np.ndarray = None\n",
    "                          , cw2: np.ndarray = None\n",
    "                          , lw1: np.ndarray = None\n",
    "                          , lw2: np.ndarray = None\n",
    "                          , lw3: np.ndarray = None) -> Network:\n",
    "    \n",
    "    if cw1 is None:\n",
    "        t_c1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(7, 7), padding='valid', bias=False) \n",
    "        cw1 = t_c1.weight.cpu().detach().numpy()\n",
    "    \n",
    "    if cw2 is None:\n",
    "        t_c2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=(7, 7), padding='valid', bias=False)\n",
    "        cw2 = t_c2.weight.cpu().detach().numpy()\n",
    "\n",
    "    if lw1 is None:\n",
    "        t_l1 = nn.Linear(in_features=10 * 44 * 44, out_features=20, bias=False)\n",
    "        lw1 = t_l1.weight.detach().numpy()\n",
    "\n",
    "    if lw2 is None:\n",
    "        t_l2 = nn.Linear(in_features=20 , out_features=3, bias=False)\n",
    "        lw2 = t_l2.weight.detach().numpy()\n",
    "\n",
    "    if lw3 is None:\n",
    "        t_l2 = nn.Linear(in_features=20 , out_features=4, bias=False)\n",
    "        lw3 = t_l2.weight.detach().numpy()\n",
    "\n",
    "\n",
    "    conv1 = ConvLayer(in_channels=3, out_channels=5, kernel_size=(7, 7), padding=None, weight_matrix=cw1) \n",
    "    conv2 = ConvLayer(in_channels=5, out_channels=10, kernel_size=(7, 7), padding=None, weight_matrix=cw2)\n",
    "    linear1 = LinearLayer(in_features=10 * 44 * 44, out_features=20, weight_matrix=lw1)\n",
    "    # linear2 = LinearLayer(in_features=20, out_features=4, weight_matrix=lw2)\n",
    "\n",
    "    flatten = FlattenLayer()\n",
    "    relu1, relu2 = ReLULayer(), ReLULayer()\n",
    "    \n",
    "    common_part = Network(layers=[conv1, relu1, conv2, relu2, flatten, linear1])\n",
    "\n",
    "    labels_layer = LinearLayer(in_features=20, out_features=3, weight_matrix=lw2)\n",
    "    boxes_layer = LinearLayer(in_features=20, out_features=4, weight_matrix=lw3)\n",
    "\n",
    "    return common_part, labels_layer, boxes_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def train(common_part: Network, \n",
    "        label_layer: LinearLayer,\n",
    "        boxes_layer: LinearLayer, \n",
    "        data: np.ndarray, \n",
    "        labels: np.ndarray,\n",
    "        boxes: np.ndarray,\n",
    "        num_epochs: int = 2, \n",
    "        batch_size: int = 10, \n",
    "        learning_rate: float = 0.1) -> Network:\n",
    "\n",
    "    ilr = learning_rate\n",
    "    num_batches = int(math.ceil(len(data) / batch_size))\n",
    "\n",
    "    # define the loss function\n",
    "    mse =  MSELoss(reduction='mean')\n",
    "    cel = CrossEntropyLoss(num_classes=3)\n",
    "\n",
    "    sigmoid = SigmoidLayer()\n",
    "    softmax = SoftmaxLayer()\n",
    "\n",
    "    for e in range(1, num_epochs + 1):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        np.random.shuffle(data)\n",
    "        np.random.shuffle(labels)\n",
    "        np.random.shuffle(boxes)\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            # print(f\"epoch: {e}, batch: {i}...\")\n",
    "\n",
    "            x = data[i * batch_size: (i + 1) * batch_size]\n",
    "            y = labels[i * batch_size: (i + 1) * batch_size]\n",
    "            b = boxes[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "            # forward pass\n",
    "            features = common_part.forward(x)\n",
    "            y_pred = softmax(label_layer(features))\n",
    "            b_pred = sigmoid(boxes_layer(features))\n",
    "\n",
    "            label_loss = cel(y_pred=y_pred, y_true=y)            \n",
    "            b_loss = mse(y_pred=b_pred * (np.expand_dims(y, axis=1) != 0), \n",
    "                         y_true=b * (np.expand_dims(y, axis=1) != 0))\n",
    "\n",
    "            # print(f\"batch: {i}, classification: {round(label_loss, 4)}, localization: {round(b_loss, 4)}\")\n",
    "\n",
    "            epoch_loss += label_loss + b_loss\n",
    "\n",
    "            # backward pass\n",
    "            label_grad = cel.grad(y_pred=y_pred, y_true=y, reduction='mean')\n",
    "            label_grad = softmax.grad(upstream_grad=label_grad)\n",
    "\n",
    "            b_grad = mse.grad(b_pred, b)\n",
    "            # select only gradients associated with non zero labels\n",
    "            b_grad = b_grad * (np.expand_dims(y, axis=1) != 0)\n",
    "            b_grad = sigmoid.grad(upstream_grad=b_grad)\n",
    "\n",
    "\n",
    "            # label layer backprop\n",
    "            g_param = label_layer.param_grad(upstream_grad=label_grad)\n",
    "            g_x_label = label_layer.grad(upstream_grad=label_grad)\n",
    "            # update the weights of the label_layers\n",
    "            label_layer.update(g_param, learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "            # do the same for box_layer\n",
    "            g_param = boxes_layer.param_grad(upstream_grad=b_grad)\n",
    "            g_x_box = boxes_layer.grad(upstream_grad=b_grad)\n",
    "            boxes_layer.update(g_param, learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "            # the final gradient to be passed to the common part is the sum of both layers\n",
    "            upstream_grad = g_x_label + g_x_box\n",
    "            common_part.backward(upstream_grad, learning_rate=ilr)\n",
    "                    \n",
    "        print(f\"epoch: {e}: loss: {round(epoch_loss / num_batches, 4)}\")\n",
    "\n",
    "    return common_part, label_layer, boxes_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1: loss: 1.6649\n",
      "epoch: 2: loss: 1.6198\n",
      "epoch: 3: loss: 1.6132\n",
      "epoch: 4: loss: 1.615\n",
      "epoch: 5: loss: 1.5914\n",
      "epoch: 6: loss: 1.6821\n",
      "epoch: 7: loss: 1.6163\n",
      "epoch: 8: loss: 1.6928\n",
      "epoch: 9: loss: 1.6322\n",
      "epoch: 10: loss: 1.7105\n"
     ]
    }
   ],
   "source": [
    "common_part, label_layer, box_layer = build_model()\n",
    "c, l, b = train(common_part=common_part, \n",
    "                label_layer=label_layer, \n",
    "                boxes_layer=box_layer, \n",
    "                data=train_x,\n",
    "                labels=train_y, \n",
    "                boxes=train_b,\n",
    "                num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(common_part, label_layer, box_layer):\n",
    "    features = common_part.forward(test_x)\n",
    "    classes = np.argmax(SoftmaxLayer()(label_layer.forward(features)), axis=1)\n",
    "    boxes = SigmoidLayer()(box_layer.forward(features))\n",
    "\n",
    "    for im, c, b in zip(test_x, classes, boxes):\n",
    "        im = np.moveaxis(im, source=0, destination=2) * 255\n",
    "        im = im.astype(np.uint8).copy()\n",
    "        # print(im.shape)\n",
    "        # cv.imshow(f'{cls}', im)\n",
    "        x0, y0, x1, y1 = b \n",
    "        \n",
    "        x0 = int(x0 * im.shape[1]) \n",
    "        y0 = int(y0 * im.shape[0]) \n",
    "\n",
    "        x1 = int(x1 * im.shape[1]) \n",
    "        y1 = int(y1 * im.shape[0])     \n",
    "        \n",
    "        cv.rectangle(im, (x0, y0), (x1, y1), (0, 255, 0), 2)\n",
    "        cv.imshow(f'{c}', im)\n",
    "        cv.waitKey(0)\n",
    "        cv.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(c, l, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
