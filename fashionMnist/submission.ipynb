{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:24:30.496521276Z",
     "start_time": "2023-10-10T16:24:30.274132655Z"
    },
    "id": "FvtlMoeqELoV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2d66b4d510>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import cv2 as cv\n",
    "\n",
    "from typing import Union, Any, Tuple\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "torch.manual_seed(69)\n",
    "\n",
    "home = os.getcwd()\n",
    "current = os.getcwd()\n",
    "\n",
    "while 'pytorch_modular' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "sys.path.append(os.path.join(str(current), 'pytorch_modular'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:24:30.504930097Z",
     "start_time": "2023-10-10T16:24:30.484113134Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = os.path.join(home, 'data', 'train.csv')\n",
    "TEST_DATA = os.path.join(home, 'data', 'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "542hhXdrIe2h"
   },
   "source": [
    "## Data reading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEMwYaImPIVh"
   },
   "source": [
    "Prepare a class for FashionMNIST dataset to easily read data and apply transformations when retrieving examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:24:34.112981202Z",
     "start_time": "2023-10-10T16:24:32.049613375Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class TrainDs(Dataset):\n",
    "    def __init__(self, train_data: Union[Path, str]) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(train_data, index_col=0)\n",
    "\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        # get the image\n",
    "        image_data, label = self.data.iloc[index, :-1].values, self.data.iloc[index, -1].item()\n",
    "        assert isinstance(label, (int, float))\n",
    "        # reshape the data and normalize\n",
    "        image_data = image_data.reshape(28, 28, 1).astype(np.uint8)\n",
    "        # convert to rgb\n",
    "        image_data = cv.cvtColor(image_data, cv.COLOR_GRAY2BGR)\n",
    "        # normalize\n",
    "        image_data = image_data / 255.0\n",
    "\n",
    "        return torch.from_numpy(image_data).permute(2, 0, 1).float(), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "\n",
    "\n",
    "class TestDs(Dataset):\n",
    "    def __init__(self, test_data: Union[Path, str]) -> None:\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(test_data, index_col=0)\n",
    "\n",
    "    def __getitem__(self, index) -> Any:\n",
    "        # get the image\n",
    "        image_data = self.data.iloc[index].values\n",
    "    \n",
    "        image_data = image_data.reshape(28, 28, 1).astype(np.uint8)\n",
    "        # convert to rgb\n",
    "        image_data = cv.cvtColor(image_data, cv.COLOR_GRAY2BGR)\n",
    "        # normalize\n",
    "        image_data = image_data / 255.0\n",
    "\n",
    "        # make sure to permute the image dimensions to be compatible with pytorch\n",
    "        return torch.from_numpy(image_data).permute(2, 0, 1).float()\n",
    "           \n",
    "    def __len__(self):\n",
    "        return len(self.data) \n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ds = TrainDs(TRAIN_DATA)\n",
    "train_ds, val_ds = train_test_split(train_ds, random_state=69, test_size=0.1)\n",
    "test_ds = TestDs(test_data=TEST_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:24:34.554154845Z",
     "start_time": "2023-10-10T16:24:34.550287314Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's create the data loaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=512,\n",
    "    shuffle=True,\n",
    "    num_workers=os.cpu_count() // 2,\n",
    "    pin_memory=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    num_workers=os.cpu_count() // 2,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    num_workers=os.cpu_count() // 2,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-10T16:24:34.548474304Z",
     "start_time": "2023-10-10T16:24:34.116892593Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's build the model\n",
    "\n",
    "from pytorch_modular.transfer_learning import resnetFeatureExtractor as rfe\n",
    "from pytorch_modular.image_classification import classification_head as ch\n",
    "from pytorch_modular.dimensions_analysis import dimension_analyser as da\n",
    "import importlib\n",
    "\n",
    "# importlib.reload(pytorch_modular)\n",
    "\n",
    "importlib.reload(rfe)\n",
    "importlib.reload(ch)\n",
    "importlib.reload(da)\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 feature_extractor, \n",
    "                 classification_head: ch.GenericClassifier,\n",
    "                 input_shape: Tuple[int, int, int], \n",
    "                 num_classes: int,\n",
    "                 *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.fe = feature_extractor\n",
    "        self.head = classification_head\n",
    "        analyser = da.DimensionsAnalyser()   \n",
    "\n",
    "        # extract the number of channels\n",
    "        c_index = np.argmin(input_shape)\n",
    "        batched_input = tuple([dim for i, dim in enumerate(input_shape) if i != c_index])\n",
    "        batched_input = (1, ) + batched_input + (input_shape[c_index], )\n",
    "\n",
    "        # find the number of input features\n",
    "        in_features = analyser.analyse_dimensions_static(feature_extractor, input_shape=batched_input)\n",
    "        \n",
    "        in_features = np.prod(in_features)\n",
    "\n",
    "        self.head.in_features = in_features\n",
    "        self.head.num_classes = num_classes\n",
    "        \n",
    "        self.model = nn.Sequential(self.fe, nn.Flatten(), self.head)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.model.forward(x)\n",
    "\n",
    "feature_extractor = rfe.ResNetFeatureExtractor(num_blocks=1, freeze=False)\n",
    "head = ch.ExponentialClassifier(num_classes=10, in_features=1024, num_layers=4)\n",
    "model = ClassificationModel(feature_extractor=feature_extractor, classification_head=head, input_shape=(1, 28, 28), num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: /home/ayhem18/DEV/My_Kaggle_Repo/fashionMnist/runs/experience_6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:02<01:04,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.1939176157826469\n",
      "train_accuracy: 0.9275855654761904\n",
      "validation loss : 0.8929219345251719\n",
      "val_accuracy: 0.7359813749790192\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [00:15<00:50,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.14240382178908303\n",
      "train_accuracy: 0.9475074404761905\n",
      "validation loss : 0.34357859939336777\n",
      "val_accuracy: 0.8848788489898046\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [00:29<00:37,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.1172335874466669\n",
      "train_accuracy: 0.9554501488095238\n",
      "validation loss : 0.35516347736120224\n",
      "val_accuracy: 0.8939014375209808\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [00:42<00:23,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.09337055807312329\n",
      "train_accuracy: 0.9647693452380952\n",
      "validation loss : 0.3947496364514033\n",
      "val_accuracy: 0.8894998331864675\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 21/25 [00:55<00:10,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.06849331811425231\n",
      "train_accuracy: 0.9747767857142857\n",
      "validation loss : 0.34883206834395725\n",
      "val_accuracy: 0.9043747186660767\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.66s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [0.1939176157826469,\n",
       "  0.17453499706018538,\n",
       "  0.16918457554919378,\n",
       "  0.15803656372286023,\n",
       "  0.1553766144883065,\n",
       "  0.14240382178908303,\n",
       "  0.14268162718841007,\n",
       "  0.1348015762510754,\n",
       "  0.12736526415461585,\n",
       "  0.12173406510126022,\n",
       "  0.1172335874466669,\n",
       "  0.1146486120564597,\n",
       "  0.10249199973685401,\n",
       "  0.09666735671815418,\n",
       "  0.09239702267306192,\n",
       "  0.09337055807312329,\n",
       "  0.08404433209271658,\n",
       "  0.0759745377160254,\n",
       "  0.07369048027765183,\n",
       "  0.07470139995926903,\n",
       "  0.06849331811425231,\n",
       "  0.06583823751480807,\n",
       "  0.0599398761278107,\n",
       "  0.05903842447414285,\n",
       "  0.05127636809788999],\n",
       " 'val_loss': [0.8929219345251719,\n",
       "  0.3610270942250888,\n",
       "  0.4890676811337471,\n",
       "  0.30484892552097637,\n",
       "  0.6841419786214828,\n",
       "  0.34357859939336777,\n",
       "  0.43326984345912933,\n",
       "  0.29298224796851474,\n",
       "  0.5401079282164574,\n",
       "  0.3155454881489277,\n",
       "  0.35516347736120224,\n",
       "  0.6624443878730139,\n",
       "  0.3716977499425411,\n",
       "  0.31419986858963966,\n",
       "  0.3339410225550334,\n",
       "  0.3947496364514033,\n",
       "  0.3763350546360016,\n",
       "  0.32325854897499084,\n",
       "  0.504818099240462,\n",
       "  0.30841343229015666,\n",
       "  0.34883206834395725,\n",
       "  0.4663243467609088,\n",
       "  0.4712231308221817,\n",
       "  0.5270816336075465,\n",
       "  0.4690007691582044],\n",
       " 'train_accuracy': [0.9275855654761904,\n",
       "  0.9352864583333333,\n",
       "  0.9373697916666667,\n",
       "  0.9405133928571429,\n",
       "  0.9418340773809524,\n",
       "  0.9475074404761905,\n",
       "  0.9461123511904762,\n",
       "  0.9488095238095238,\n",
       "  0.9518043154761905,\n",
       "  0.9557105654761905,\n",
       "  0.9554501488095238,\n",
       "  0.9572916666666667,\n",
       "  0.9612165178571429,\n",
       "  0.9635602678571429,\n",
       "  0.9662760416666667,\n",
       "  0.9647693452380952,\n",
       "  0.968452380952381,\n",
       "  0.9707403273809524,\n",
       "  0.9714285714285714,\n",
       "  0.9726376488095239,\n",
       "  0.9747767857142857,\n",
       "  0.9756510416666667,\n",
       "  0.9778459821428571,\n",
       "  0.9776785714285714,\n",
       "  0.9807291666666667],\n",
       " 'val_accuracy': [0.7359813749790192,\n",
       "  0.8820906927188238,\n",
       "  0.852093239625295,\n",
       "  0.8967957446972529,\n",
       "  0.8306867082913717,\n",
       "  0.8848788489898046,\n",
       "  0.877802312374115,\n",
       "  0.9116989374160767,\n",
       "  0.8421860883633295,\n",
       "  0.9045728594064713,\n",
       "  0.8939014375209808,\n",
       "  0.8013969113429388,\n",
       "  0.8954299738009771,\n",
       "  0.9078563749790192,\n",
       "  0.8935829947392145,\n",
       "  0.8894998331864675,\n",
       "  0.9026409685611725,\n",
       "  0.9071204165617625,\n",
       "  0.872516135374705,\n",
       "  0.915081520875295,\n",
       "  0.9043747186660767,\n",
       "  0.8981402864058813,\n",
       "  0.8947506248950958,\n",
       "  0.8794794529676437,\n",
       "  0.8979633748531342],\n",
       " 'best_train_loss': 0.05127636809788999,\n",
       " 'best_val_loss': 0.29298224796851474,\n",
       " 'best_train_accuracy': 0.9275855654761904,\n",
       " 'best_val_accuracy': 0.7359813749790192}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_modular.image_classification import engine_classification\n",
    "from pytorch_modular.image_classification import epoch_engine\n",
    "import pytorch_modular.exp_tracking as exp\n",
    "importlib.reload(engine_classification)\n",
    "importlib.reload(epoch_engine)\n",
    "importlib.reload(exp)\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "\n",
    "\n",
    "optimizer = Adam(params=model.parameters(), lr=0.05)\n",
    "scheduler = LinearLR(optimizer=optimizer, start_factor=1, end_factor=0.1, total_iters=100) \n",
    "\n",
    "train_configuration = {'optimizer': optimizer,\n",
    "                        'scheduler': scheduler,\n",
    "                        'min_val_loss': 10 ** -4,\n",
    "                        'max_epochs': 25,\n",
    "                        'report_epoch': 5,\n",
    "                        }\n",
    "\n",
    "r = engine_classification.train_model(model=model, \n",
    "                                  train_dataloader=train_dataloader, \n",
    "                                  test_dataloader=val_loader, \n",
    "                                  train_configuration=train_configuration, \n",
    "                                  log_dir=os.path.join(home,'runs'),\n",
    "                                  save_path=os.path.join(home, 'modelds'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MixzPT21QXpB"
   },
   "source": [
    "Split the dataset into training and validation subsets using `random_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "b8Z2AOzJYKkC"
   },
   "outputs": [],
   "source": [
    "# generate the submission file\n",
    "predictions = engine_classification.inference(model, test_loader, return_tensor='list')\n",
    "sub_folder = os.path.join(home, 'submissions')\n",
    "submission_df = pd.DataFrame(columns=['id', 'label'])\n",
    "submission_df['id'] = list(range(60000, 60000 + len(predictions)))\n",
    "submission_df['label'] = predictions\n",
    "submission_df.to_csv(os.path.join(home, sub_folder, f'{len(os.listdir(sub_folder))}.csv'), index=None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
