{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T13:38:15.513613632Z",
     "start_time": "2023-09-30T13:38:14.633075278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6712, 0.2613, 0.5673, 0.9451])\n",
      "tensor(0.5910)\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "tensor = torch.rand(4)\n",
    "print(tensor)\n",
    "\n",
    "t = torch.flatten(tensor)\n",
    "loss = nn.BCELoss()\n",
    "# res = loss(t, torch.tensor([1]).float())\n",
    "\n",
    "res = loss(t, torch.full(tuple(t.shape), fill_value=1).float())\n",
    "print(torch.mean(-torch.log(tensor))) \n",
    "print(type(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T13:38:15.521826545Z",
     "start_time": "2023-09-30T13:38:15.514410026Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "script_dir = os.getcwd()\n",
    "DATA_FOLDER = os.path.join(script_dir, 'training', 'data')\n",
    "current = script_dir\n",
    "while 'src' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "sys.path.append(os.path.join(str(current), 'FaceSpoofing'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T13:39:04.193537571Z",
     "start_time": "2023-09-30T13:39:04.147557274Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import src.pytorch_modular.directories_and_files as dirf\n",
    "\n",
    "\n",
    "RAW_DATA = os.path.join(DATA_FOLDER, 'raw')\n",
    "# if os.path.isdir(RAW_DATA):\n",
    "#     shutil.rmtree(RAW_DATA)\n",
    "\n",
    "# dirf.unzip_data_file(os.path.join(DATA_FOLDER, 'raw.zip'))\n",
    "# dirf.squeeze_directory(RAW_DATA)\n",
    "# # remove any non directories in RAW_DATA folder\n",
    "# # rename\n",
    "# os.rename(os.path.join(RAW_DATA, 'ClientRaw'), os.path.join(RAW_DATA, 'real'))\n",
    "# os.rename(os.path.join(RAW_DATA, 'ImposterRaw'), os.path.join(RAW_DATA, 'fake'))\n",
    "\n",
    "# initial_raw_data = os.listdir(RAW_DATA)\n",
    "# for f in initial_raw_data:\n",
    "#     pf = os.path.join(RAW_DATA, f)\n",
    "#     if not os.path.isdir(pf):\n",
    "#         os.remove(pf)\n",
    "\n",
    "# raw1 = os.path.join(DATA_FOLDER, 'raw', 'real')\n",
    "# raw0 = os.path.join(DATA_FOLDER, 'raw', 'fake')\n",
    "\n",
    "\n",
    "# initial_dirs1 = os.listdir(raw1)\n",
    "# initial_dirs0 = os.listdir(raw0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T13:38:15.710369438Z",
     "start_time": "2023-09-30T13:38:15.709838723Z"
    }
   },
   "outputs": [],
   "source": [
    "# for raw1_dir in initial_dirs1:\n",
    "#     path_dir = os.path.join(raw1, raw1_dir)\n",
    "#     if os.path.isdir(path_dir) and not str(raw1_dir).endswith('.db'):\n",
    "#         dirf.copy_directories(path_dir, raw1, copy=False, filter_directories=lambda x: not x.endswith('.db'))   \n",
    "#     else:\n",
    "#         os.remove(path_dir)\n",
    "#     # remove the directory at the end\n",
    "#     shutil.rmtree(path_dir)\n",
    "        \n",
    "# for raw0_dir in initial_dirs0:\n",
    "#     path_dir = os.path.join(raw0, raw0_dir)\n",
    "\n",
    "#     if os.path.isdir(path_dir) and not str(raw0_dir).endswith('.db'):\n",
    "#         dirf.copy_directories(path_dir, raw0,copy=False, filter_directories=lambda x: not x.endswith('.db'))\n",
    "#     else:\n",
    "#         os.remove(path_dir)\n",
    "#     shutil.rmtree(path_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T13:39:08.487526641Z",
     "start_time": "2023-09-30T13:39:08.484834482Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's put everything together\n",
    "TRAIN_DIR = os.path.join(DATA_FOLDER, 'train')\n",
    "TEST_DIR = os.path.join(DATA_FOLDER, 'test')\n",
    "\n",
    "# if os.path.isdir(TRAIN_DIR):\n",
    "#     shutil.rmtree(TRAIN_DIR)\n",
    "#     os.makedirs(TRAIN_DIR)\n",
    "\n",
    "# if os.path.isdir(TEST_DIR):\n",
    "#     shutil.rmtree(TEST_DIR)\n",
    "#     os.makedirs(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-30T13:39:09.016652710Z",
     "start_time": "2023-09-30T13:39:09.013391133Z"
    }
   },
   "outputs": [],
   "source": [
    "# pass a portion of the dataset to the training dir\n",
    "\n",
    "# dirf.dataset_portion(RAW_DATA, TRAIN_DIR, portion=0.9, copy=False)\n",
    "# dirf.copy_directories(RAW_DATA, TEST_DIR, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-30T13:47:23.574990947Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'FaceSpoofing.PixBiSupervision.model.DenseNetFE' from '/home/ayhem18/DEV/My_Kaggle_Repo/FaceSpoofing/PixBiSupervision/model/DenseNetFE.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from FaceSpoofing.PixBiSupervision.training import preprocessing as pr, losses as ls\n",
    "from  FaceSpoofing.PixBiSupervision.model import PiBiNet as binet,  DenseNetFE as dense\n",
    "import importlib\n",
    "\n",
    "importlib.reload(pr)\n",
    "importlib.reload(ls)\n",
    "importlib.reload(binet)\n",
    "importlib.reload(dense)\n",
    "\n",
    "# pr.prepare_data(TRAIN_DIR)\n",
    "# pr.prepare_data(TEST_DIR)\n",
    "# train_dl, test_dl = pr.prepare_dataloaders(TRAIN_DIR, TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prepare the data loaders\n",
    "from src.pytorch_modular.data_loaders import create_dataloaders\n",
    "train_dl, test_dl, classes_info = create_dataloaders(train_dir=TRAIN_DIR, \n",
    "                                       test_dir=TEST_DIR,\n",
    "                                       train_transform=binet.DenseNetFeatureExtractor.default_transform,\n",
    "                                       batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define the model\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "model = binet.PiBiNet()\n",
    "loss = ls.pixelBinaryLoss()\n",
    "optimizer = AdamW(params=model.parameters(), lr=10**-4, weight_decay=10**-5)\n",
    "lr_scheduler = LinearLR(optimizer=optimizer, start_factor=1, end_factor=0.5, total_iters=100)\n",
    "\n",
    "\n",
    "def compute_loss(y_pred: torch.Tensor, y: torch.Tensor, alpha: float=0.5) -> torch.Tensor:\n",
    "    bfm, logits = y_pred\n",
    "    feature_map_loss = loss(bfm, y)\n",
    "    binary_loss = nn.BCEWithLogitsLoss(logits, y)\n",
    "    return alpha * feature_map_loss + binary_loss * (1 - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "accuracy_metric = Accuracy(task='binary')\n",
    "metrics = {'accuracy': accuracy_metric}\n",
    "\n",
    "train_configuration = {'optimizer': optimizer,\n",
    "                        'scheduler': lr_scheduler,\n",
    "                        'min_val_loss': 10 ** -4,\n",
    "                        'max_epochs': 5,\n",
    "                        'report_epoch': 2,\n",
    "                        'compute_loss': compute_loss,\n",
    "                        'metrics': metrics,\n",
    "                        'no_improve_stop': 10\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: /home/ayhem18/DEV/My_Kaggle_Repo/FaceSpoofing/PixBiSupervision/runs/experience_11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [01:08<?, ?it/s]\n",
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    }
   ],
   "source": [
    "import src.pytorch_modular.image_classification.engine_classification as cls\n",
    "from  FaceSpoofing.PixBiSupervision.model import PiBiNet as binet,  DenseNetFE as dense\n",
    "importlib.reload(cls)\n",
    "importlib.reload(binet)\n",
    "HOME = os.getcwd()\n",
    "\n",
    "results = cls.train_model(model, \n",
    "                          train_dl, \n",
    "                          test_dl, \n",
    "                          train_configuration,          \n",
    "                          log_dir=os.path.join(HOME, 'runs'),         \n",
    "                          save_path=os.path.join(HOME, 'saved_models'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
