{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2 as cv\n",
    "import os\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "import sys \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.getcwd()\n",
    "DATA_FOLDER = os.path.join(HOME, 'data')\n",
    "current = HOME\n",
    "while 'src' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "PROJECT_DIR = str(current) \n",
    "sys.path.append(PROJECT_DIR)\n",
    "sys.path.append(os.path.join(str(current), 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_dir = os.path.join(HOME, 'local_faces')\n",
    "video_path = os.path.join(HOME, 'v1.MOV')\n",
    "frames_save_path = os.path.join(DATA_FOLDER, 'frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pytorch_modular.directories_and_files import process_save_path\n",
    "\n",
    "def video_to_images(video_path: Union[str, Path], \n",
    "                    output_dir: Union[Path, str], \n",
    "                    frame_stride: int = 16) -> None:\n",
    "    if os.path.isdir(output_dir):\n",
    "        # remove the directory if it already exists\n",
    "        shutil.rmtree(output_dir)\n",
    "\n",
    "    output_dir = process_save_path(output_dir, file_ok=False, dir_ok=True)    \n",
    "    count = 0\n",
    "    # create the cv2 capture video object\n",
    "    video_iterator = cv.VideoCapture(video_path)\n",
    "    \n",
    "    # count the total number of frames in the video\n",
    "    s = True\n",
    "    total_count = 0\n",
    "    \n",
    "    while s:\n",
    "        s, _ = video_iterator.read()\n",
    "        total_count += 1\n",
    "    video_iterator = cv.VideoCapture(video_path)\n",
    "    \n",
    "    while True:\n",
    "        frame_exists, image = video_iterator.read()\n",
    "\n",
    "        if not frame_exists: \n",
    "            # the video is over\n",
    "            break\n",
    "\n",
    "        count += 1\n",
    "        if count % frame_stride == frame_stride - 1:\n",
    "            frame_num_str = f\"{(len(str(total_count)) - len(str(count))) * '0'}{count}\"\n",
    "            cv.imwrite(os.path.join(output_dir, f'frame_{frame_num_str}.jpg'), image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_images(video_path=video_path,\n",
    "                output_dir=frames_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_015.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/ayhem18/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_031.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_047.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_063.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_079.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_095.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_111.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_127.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_143.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_159.jpg\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/Hack_visual_system/data/frames/frame_175.jpg\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "frames = sorted(os.listdir(frames_save_path))\n",
    "frames = [os.path.join(frames_save_path, f) for f in frames]\n",
    "test_frames = frames[:15] \n",
    "\n",
    "for image in test_frames:\n",
    "    print(image)\n",
    "    image = os.path.join(frames_save_path, image)\n",
    "    img = cv.imread(image)\n",
    "    cv.imshow('image',img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 1: 384x640 2 persons, 2: 384x640 2 persons, 3: 384x640 2 persons, 4: 384x640 2 persons, 5: 384x640 1 person, 6: 384x640 1 person, 7: 384x640 1 person, 8: 384x640 1 person, 9: 384x640 1 person, 10: 384x640 1 person, 98.5ms\n",
      "Speed: 1.7ms preprocess, 9.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlocalFR\u001b[39;00m \u001b[39mimport\u001b[39;00m FaceRecognizer\n\u001b[1;32m     14\u001b[0m fr \u001b[39m=\u001b[39m FaceRecognizer(reference_embeddings\u001b[39m=\u001b[39mfaces_dir)\n\u001b[0;32m---> 15\u001b[0m fr\u001b[39m.\u001b[39;49mrecognize_faces(test_frames)     \n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/Hack_visual_system/localFR.py:87\u001b[0m, in \u001b[0;36mFaceRecognizer.recognize_faces\u001b[0;34m(self, frames, display, debug)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecognize_faces\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     83\u001b[0m                     frames: Sequence[Union[Path, \u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray, torch\u001b[39m.\u001b[39mTensor]],\n\u001b[1;32m     84\u001b[0m                     display: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m     85\u001b[0m                     debug: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     86\u001b[0m     \u001b[39m# first analyze the video\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     frames_signatures, person_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49manalyzer\u001b[39m.\u001b[39;49manalyze_frames(frames, debug\u001b[39m=\u001b[39;49mdebug)\n\u001b[1;32m     88\u001b[0m     \u001b[39m# for each person_id finds the most probable face\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     ids_labels \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/Hack_visual_system/video_analyzer.py:193\u001b[0m, in \u001b[0;36mYoloAnalyzer.analyze_frames\u001b[0;34m(self, frames, xywh, debug)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39manalyze_frames\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m    189\u001b[0m                    frames: Sequence[Union[Path, \u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray, torch\u001b[39m.\u001b[39mTensor]],\n\u001b[1;32m    190\u001b[0m                    xywh: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    191\u001b[0m                    debug: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    192\u001b[0m     \u001b[39m# the first step is to track the frames\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     tracking_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_track(frames)\n\u001b[1;32m    194\u001b[0m     \u001b[39m# create a signature for each frame\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     frame_signatures \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframes_signature(tracking_results\u001b[39m=\u001b[39mtracking_results)\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/Hack_visual_system/video_analyzer.py:128\u001b[0m, in \u001b[0;36mYoloAnalyzer._track\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m# remove the extra ids by calling the custom tracker's method\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mtrack(tracking_results)\n\u001b[0;32m--> 128\u001b[0m \u001b[39mreturn\u001b[39;00m tracking_results\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/Hack_visual_system/video_analyzer.py:128\u001b[0m, in \u001b[0;36mYoloAnalyzer._track\u001b[0;34m(self, frames)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39m# remove the extra ids by calling the custom tracker's method\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mtrack(tracking_results)\n\u001b[0;32m--> 128\u001b[0m \u001b[39mreturn\u001b[39;00m tracking_results\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import localFR\n",
    "import video_analyzer\n",
    "import face.embeddings\n",
    "import face.helper_functions\n",
    "import face.custom_tracker\n",
    "import importlib\n",
    "importlib.reload(localFR)\n",
    "importlib.reload(video_analyzer)\n",
    "importlib.reload(face.embeddings)\n",
    "importlib.reload(face.helper_functions)\n",
    "importlib.reload(face.custom_tracker)\n",
    "\n",
    "from localFR import FaceRecognizer\n",
    "fr = FaceRecognizer(reference_embeddings=faces_dir)\n",
    "fr.recognize_faces(test_frames)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
