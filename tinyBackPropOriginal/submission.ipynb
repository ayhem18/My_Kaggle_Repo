{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The submission"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "HOME = os.getcwd()\n",
    "DATA_FOLDER = os.path.join(HOME, 'data') \n",
    "current = HOME\n",
    "\n",
    "while 'pytorch_modular' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "sys.path.append(os.path.join(current, 'tinyBackProp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tinyBackProp.conv_layer as cl\n",
    "\n",
    "import importlib\n",
    "importlib.reload(cl)\n",
    "\n",
    "conv_layer = cl.ConvLayer(in_channels=2, kernel_size=(3, 3))\n",
    "\n",
    "x = np.random.rand(2, 10, 10).astype(np.float32)\n",
    "o = conv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's test the forward pass using pytorch\n",
    "import torch\n",
    "from torch.nn import Conv2d\n",
    "\n",
    "torch_layer = Conv2d(in_channels=2, out_channels=1, kernel_size=(3, 3), padding='valid', bias=False)\n",
    "# converting the input to tensor\n",
    "x_tensor = torch.from_numpy(x)\n",
    "# let's create a custom layer with the same weights as the torch layer\n",
    "custom_layer = cl.ConvLayer(in_channels=2, kernel_size=(3, 3), weight_matrix=torch_layer.weight.squeeze().cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_o = torch_layer(x_tensor).detach().cpu().numpy().squeeze()\n",
    "# torch_o.shape\n",
    "# custom_o = custom_layer(x).squeeze()\n",
    "# custom_o.shape\n",
    "# np.allclose(custom_o, torch_o, atol=10 ** -6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_layer = Conv2d(in_channels=2, out_channels=1, kernel_size=(3, 3), padding='valid', bias=False)\n",
    "x = np.random.rand(2, 10, 10).astype(np.float32)\n",
    "# converting the input to tensor\n",
    "x_tensor = torch.from_numpy(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
