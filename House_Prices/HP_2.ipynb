{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Pricing Predictions\n",
    "This is my attempt on the data science challenge on [Kaggle](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview), predicting the house prices given a large number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary work: imports and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to store the location of the training and test datasets\n",
    "train_file = \"train.csv\"\n",
    "test_file = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_org = pd.read_csv(train_file)\n",
    "df_test_org = pd.read_csv(test_file)\n",
    "# df and df_test are copies of the original datasets with target value referred to as y\n",
    "Y = \"y\"\n",
    "df = df_train_org.rename(columns={'SalePrice': Y})\n",
    "df_test = df_test_org.rename(columns={'SalePrice':Y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration \n",
    "In this section we explore the basic aspects of the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to drop an element to both train and test dataframes\n",
    "def drop_cols(col_names:list, on='both'):\n",
    "    global df, df_test\n",
    "    try:\n",
    "        df = df.drop(col_names, axis=1)\n",
    "        df_test = df_test.drop(col_names, axis=1)\n",
    "    except:\n",
    "        print(\"The column{s} {cols} have already been dropped\".\n",
    "        format(s= \"\" if (col_names is str or len(col_names) == 1) else \"s\", cols=str(col_names)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81) (1459, 80)\n",
      "True\n",
      "(1460, 80) (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "# let's first understand the nature of our data\n",
    "print(df.shape, df_test.shape) \n",
    "# each sample is described by 81 features. This number if relatively high.\n",
    "\n",
    "print((df['Id'].values == range(1 ,len(df) + 1)).all()) \n",
    "# as we can see the Id column is merely for ennumeriation purposes. It can be either dropped or set as an index.\n",
    "drop_cols(\"Id\")\n",
    "print(df.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical and Numerical features\n",
    "Let's consider the different types of features. First, we divide them into numerical and non-numerical. The non-numerical are definitely categorical (or can be made as such). As for numerical, columns with int values, can be considered categorical if the number of unique values is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
      "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
      "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
      "       'SaleType', 'SaleCondition'],\n",
      "      dtype='object')\n",
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# consider non-numerical values\n",
    "object_type = \"object\"\n",
    "cat_type = 'category'\n",
    "non_num_cols = df.select_dtypes([object_type, cat_type]).columns\n",
    "print(non_num_cols)\n",
    "num_cols = df.select_dtypes(np.number).columns\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSSubClass': 15, 'LotArea': 1073, 'OverallQual': 10, 'OverallCond': 9, 'YearBuilt': 112, 'YearRemodAdd': 61, 'BsmtFinSF1': 637, 'BsmtFinSF2': 144, 'BsmtUnfSF': 780, 'TotalBsmtSF': 721, '1stFlrSF': 753, '2ndFlrSF': 417, 'LowQualFinSF': 24, 'GrLivArea': 861, 'BsmtFullBath': 4, 'BsmtHalfBath': 3, 'FullBath': 4, 'HalfBath': 3, 'BedroomAbvGr': 8, 'KitchenAbvGr': 4, 'TotRmsAbvGrd': 12, 'Fireplaces': 4, 'GarageCars': 5, 'GarageArea': 441, 'WoodDeckSF': 274, 'OpenPorchSF': 202, 'EnclosedPorch': 120, '3SsnPorch': 20, 'ScreenPorch': 76, 'PoolArea': 8, 'MiscVal': 21, 'MoSold': 12, 'YrSold': 5, 'y': 663}\n"
     ]
    }
   ],
   "source": [
    "# let's consider the subset of numerical columns with few discrete values\n",
    "num_discrete = df.select_dtypes('int64').columns\n",
    "num_dis_count = [len(df[num_d].unique()) for num_d in num_discrete]  \n",
    "print(dict(zip(num_discrete, num_dis_count)))\n",
    "\n",
    "# we can see that a \"MSSubClass\" is a categorical feature\n",
    "# a number of features are not categorical by say, but can be treated as such: Bath related features, Fireplaces, GarageCars, and most importantly\n",
    "# OverallQual and OveralCond\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Certain columns might contain corrupted data and thus require cleaning. I will start with categorical columns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning categorical columns \n",
    "The main procedure is as follows:\n",
    "* replace the values that do not belong to the data description set of values by the one described there, mainly typos in string typed values\n",
    "* in the worst case drop rows that have values significantly different from the pre-determined categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "['RL' 'RM' 'C (all)' 'FV' 'RH']\n",
      "\n",
      "Street\n",
      "['Pave' 'Grvl']\n",
      "\n",
      "Alley\n",
      "[nan 'Grvl' 'Pave']\n",
      "\n",
      "LotShape\n",
      "['Reg' 'IR1' 'IR2' 'IR3']\n",
      "\n",
      "LandContour\n",
      "['Lvl' 'Bnk' 'Low' 'HLS']\n",
      "\n",
      "Utilities\n",
      "['AllPub' 'NoSeWa']\n",
      "\n",
      "LotConfig\n",
      "['Inside' 'FR2' 'Corner' 'CulDSac' 'FR3']\n",
      "\n",
      "LandSlope\n",
      "['Gtl' 'Mod' 'Sev']\n",
      "\n",
      "Neighborhood\n",
      "['CollgCr' 'Veenker' 'Crawfor' 'NoRidge' 'Mitchel' 'Somerst' 'NWAmes'\n",
      " 'OldTown' 'BrkSide' 'Sawyer' 'NridgHt' 'NAmes' 'SawyerW' 'IDOTRR'\n",
      " 'MeadowV' 'Edwards' 'Timber' 'Gilbert' 'StoneBr' 'ClearCr' 'NPkVill'\n",
      " 'Blmngtn' 'BrDale' 'SWISU' 'Blueste']\n",
      "\n",
      "Condition1\n",
      "['Norm' 'Feedr' 'PosN' 'Artery' 'RRAe' 'RRNn' 'RRAn' 'PosA' 'RRNe']\n",
      "\n",
      "Condition2\n",
      "['Norm' 'Artery' 'RRNn' 'Feedr' 'PosN' 'PosA' 'RRAn' 'RRAe']\n",
      "\n",
      "BldgType\n",
      "['1Fam' '2fmCon' 'Duplex' 'TwnhsE' 'Twnhs']\n",
      "\n",
      "HouseStyle\n",
      "['2Story' '1Story' '1.5Fin' '1.5Unf' 'SFoyer' 'SLvl' '2.5Unf' '2.5Fin']\n",
      "\n",
      "RoofStyle\n",
      "['Gable' 'Hip' 'Gambrel' 'Mansard' 'Flat' 'Shed']\n",
      "\n",
      "RoofMatl\n",
      "['CompShg' 'WdShngl' 'Metal' 'WdShake' 'Membran' 'Tar&Grv' 'Roll'\n",
      " 'ClyTile']\n",
      "\n",
      "Exterior1st\n",
      "['VinylSd' 'MetalSd' 'Wd Sdng' 'HdBoard' 'BrkFace' 'WdShing' 'CemntBd'\n",
      " 'Plywood' 'AsbShng' 'Stucco' 'BrkComm' 'AsphShn' 'Stone' 'ImStucc'\n",
      " 'CBlock']\n",
      "\n",
      "Exterior2nd\n",
      "['VinylSd' 'MetalSd' 'Wd Shng' 'HdBoard' 'Plywood' 'Wd Sdng' 'CmentBd'\n",
      " 'BrkFace' 'Stucco' 'AsbShng' 'Brk Cmn' 'ImStucc' 'AsphShn' 'Stone'\n",
      " 'Other' 'CBlock']\n",
      "\n",
      "MasVnrType\n",
      "['BrkFace' 'None' 'Stone' 'BrkCmn' nan]\n",
      "\n",
      "ExterQual\n",
      "['Gd' 'TA' 'Ex' 'Fa']\n",
      "\n",
      "ExterCond\n",
      "['TA' 'Gd' 'Fa' 'Po' 'Ex']\n",
      "\n",
      "Foundation\n",
      "['PConc' 'CBlock' 'BrkTil' 'Wood' 'Slab' 'Stone']\n",
      "\n",
      "BsmtQual\n",
      "['Gd' 'TA' 'Ex' nan 'Fa']\n",
      "\n",
      "BsmtCond\n",
      "['TA' 'Gd' nan 'Fa' 'Po']\n",
      "\n",
      "BsmtExposure\n",
      "['No' 'Gd' 'Mn' 'Av' nan]\n",
      "\n",
      "BsmtFinType1\n",
      "['GLQ' 'ALQ' 'Unf' 'Rec' 'BLQ' nan 'LwQ']\n",
      "\n",
      "BsmtFinType2\n",
      "['Unf' 'BLQ' nan 'ALQ' 'Rec' 'LwQ' 'GLQ']\n",
      "\n",
      "Heating\n",
      "['GasA' 'GasW' 'Grav' 'Wall' 'OthW' 'Floor']\n",
      "\n",
      "HeatingQC\n",
      "['Ex' 'Gd' 'TA' 'Fa' 'Po']\n",
      "\n",
      "CentralAir\n",
      "['Y' 'N']\n",
      "\n",
      "Electrical\n",
      "['SBrkr' 'FuseF' 'FuseA' 'FuseP' 'Mix' nan]\n",
      "\n",
      "KitchenQual\n",
      "['Gd' 'TA' 'Ex' 'Fa']\n",
      "\n",
      "Functional\n",
      "['Typ' 'Min1' 'Maj1' 'Min2' 'Mod' 'Maj2' 'Sev']\n",
      "\n",
      "FireplaceQu\n",
      "[nan 'TA' 'Gd' 'Fa' 'Ex' 'Po']\n",
      "\n",
      "GarageType\n",
      "['Attchd' 'Detchd' 'BuiltIn' 'CarPort' nan 'Basment' '2Types']\n",
      "\n",
      "GarageFinish\n",
      "['RFn' 'Unf' 'Fin' nan]\n",
      "\n",
      "GarageQual\n",
      "['TA' 'Fa' 'Gd' nan 'Ex' 'Po']\n",
      "\n",
      "GarageCond\n",
      "['TA' 'Fa' nan 'Gd' 'Po' 'Ex']\n",
      "\n",
      "PavedDrive\n",
      "['Y' 'N' 'P']\n",
      "\n",
      "PoolQC\n",
      "[nan 'Ex' 'Fa' 'Gd']\n",
      "\n",
      "Fence\n",
      "[nan 'MnPrv' 'GdWo' 'GdPrv' 'MnWw']\n",
      "\n",
      "MiscFeature\n",
      "[nan 'Shed' 'Gar2' 'Othr' 'TenC']\n",
      "\n",
      "SaleType\n",
      "['WD' 'New' 'COD' 'ConLD' 'ConLI' 'CWD' 'ConLw' 'Con' 'Oth']\n",
      "\n",
      "SaleCondition\n",
      "['Normal' 'Abnorml' 'Partial' 'AdjLand' 'Alloca' 'Family']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col, uni_values in zip(non_num_cols, [df[col].unique() for col in non_num_cols]):\n",
    "    print(col)\n",
    "    print(uni_values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating the output of the previous cell as well as inspecting the content of the documentation\n",
    "# suggests a couple of corrupted values in certain columns such as Exterior2nd\n",
    "\n",
    "# let's define a function to replace these values both in the training and test dataframes\n",
    "\n",
    "def replace_values(col_names:list , wrong_correct:list, on='both'):\n",
    "    assert (isinstance(col_names, str) and isinstance(wrong_correct, dict)) or all([isinstance(l, dict) for l in wrong_correct]) and isinstance(col_names, list) \n",
    "    assert on in ['both', 'df', 'df_test']\n",
    "    \n",
    "    global df, df_test\n",
    "    \n",
    "    if isinstance(col_names, str):\n",
    "        for k, v in wrong_correct.items():\n",
    "            df = df.replace(k, v)\n",
    "            df_test = df_test.replace(k, v)\n",
    "        return \n",
    "    \n",
    "    try:\n",
    "        for col, dic in zip(col_names, wrong_correct):\n",
    "            for k, v in dic.items():\n",
    "                df = df.replace(k, v)\n",
    "                df_test = df_test.replace(k, v)\n",
    "                \n",
    "    except:\n",
    "        print(\"Something is wrong check again !!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have the value C (all) is correputed in MSZoning\n",
    "mszoning = \"MSZoning\"\n",
    "correct_mszoning = {\"C (all)\": \"C\"}\n",
    "ext2 = \"Exterior2nd\"\n",
    "correct_ext2 = {\"Brk Cmn\": \"BrkComm\", \"CmentBd\": \"CemntBd\"}\n",
    "\n",
    "ms_ext = [mszoning, ext2]\n",
    "correct = [correct_mszoning, correct_ext2]\n",
    "\n",
    "replace_values(ms_ext, correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning numerical columns\n",
    "This task is slightly trickier as it might require domain expertise. The main procedure is as follows:\n",
    "1. replace (or drop) values that contradict general common sense, for instance negative areas, months cannot be more than $12$\n",
    "2. consider the relationship between certain rows. values in a certain columns cannot be smaller / larger than the corresponding values in other columns. This step require more careful study of the nature of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let's first display the numerical columns\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotArea', 'MasVnrArea', 'GrLivArea', 'GarageArea', 'PoolArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'WoodDeckSF', 'OpenPorchSF']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# let's consider areas\n",
    "areas = [col for col in num_cols if (\"area\" in col.strip().lower())]\n",
    "# inverstiagating the data description, the term SF generally refers to surface (area)\n",
    "areas.extend([col for col in num_cols if \"SF\" in col.strip()]) \n",
    "print(areas)\n",
    "# verify all values are positive\n",
    "areas_with_neg = [any(df[area] < 0) for area in areas]\n",
    "areas_with_neg = [area for area, a in zip(areas, areas_with_neg) if a]\n",
    "print(areas_with_neg)\n",
    "# as we can see all areas-values are positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data description indicats that \n",
    "* OverallQuall and OverallCond should belong to the interval [1, 10]\n",
    "* YearRemodAdd is year of remodel, thus it should be larger or equal to YearBuilt\n",
    "* The relationship between the the year where the garage was built and the other year features should be investigated.\n",
    "* MSSubClass represents a label encoding of the different types of houses: values should belong to predetermined set of values specified in the data description\n",
    "* MoSold is the month where the house was sold. it should belong to [1, 12]\n",
    "* it might be worthwhile investigatinv any abnormalities in the relationship between \"BsmtFinSF1\", \"BsmtUnfSF\", \"BsmtFinSF2\" and \"TotalBsmtSF\" \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all let's define a method to replace the names of features in both training and test datasets\n",
    "\n",
    "def new_col_names(old_new_names:dict):\n",
    "    global df, df_test\n",
    "    try:\n",
    "        \n",
    "        df = df.rename(columns=old_new_names)\n",
    "        df_test = df_test.rename(columns=old_new_names)\n",
    "    except:\n",
    "        df_no_col = [col for col in old_new_names.keys if col not in df.columns]\n",
    "        df_test_no_col = [col for col in old_new_names.keys if col not in df_test.columns]\n",
    "        print(\"{cols} are not in the {dataf}\".format(df_no_col, \"training dataset\"))\n",
    "        print(\"{cols} are not in the {dataf}\".format(df_test_no_col, \"test dataset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_new_cols = {\"OverallQual\": \"qua\", \n",
    "\"OverallCond\": \"cond\", \"YearBuilt\": \"Yb\", \"YearRemodAdd\": \"Yr\", \"MSSubClass\": \"mss\" , \n",
    "\"BsmtFinSF1\": \"bSF1\", \"BsmtFinSF2\": \"bSF2\", \"BsmtUnfSF\": \"bubf\", \"GarageYrBlt\":\"GYb\"}\n",
    "new_col_names(old_new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify the integrity of overall quality and condition features\n",
    "qua = \"qua\"\n",
    "cond = \"cond\"\n",
    "print(all(df[qua].isin(range(1, 11))))\n",
    "print(all(df[cond].isin(range(1, 11))))\n",
    "\n",
    "# verify the remodeling and building years features\n",
    "yb = \"Yb\"\n",
    "yr = \"Yr\"\n",
    "print(df[df[yb] > df[yr]].empty) # the resulting dataframe is empty: no problems with neither of these features\n",
    "\n",
    "# verify the MSubclass features\n",
    "mss = \"mss\"\n",
    "mss_values = [20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 150, 160, 180, 190]\n",
    "\n",
    "print(df[~df[mss].isin(mss_values)].empty) # all values from \"MSsubclass\" feature are under check\n",
    "\n",
    "# verify the month feature\n",
    "\n",
    "print(df[~df[\"MoSold\"].isin(range(1, 13))].empty) # all values of the month feature are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let' define a function that applies a function to either \n",
    "# the whole dataframe or certain columns on the dataframe\n",
    "\n",
    "def apply_functions(funcs, col_names=None, on='both'):\n",
    "    # either have one function passed that should be applied to the whole dataframe\n",
    "    # or have an equal number of columns and functions where each funtion will be applied to the corresponding column\n",
    "    all_data = callable(funcs) and col_names is None\n",
    "    col_funcs = True\n",
    "    #  if the funcs argument is indeed a function, then the code below will raise an error \n",
    "    try:\n",
    "        col_funcs = (all([callable(f) for f in funcs]) and len(funcs) == len(col_names))\n",
    "    except:\n",
    "        col_funcs = False\n",
    "    \n",
    "    assert all_data or col_funcs\n",
    "   \n",
    "    global df, df_test\n",
    "    if col_names is None: # if the function is to be applied to the whole dataframe\n",
    "        df = df.apply(funcs, axis=1)\n",
    "        df_test = df_test.apply(funcs, axis=1)\n",
    "    else:\n",
    "        for col, f in zip(col_names, funcs):\n",
    "            df = df.apply(f)\n",
    "            df_test = df_test.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GYb    Yb    Yr\n",
      "29    1920.0  1927  1950\n",
      "93    1900.0  1910  1998\n",
      "324   1961.0  1967  2007\n",
      "600   2003.0  2005  2005\n",
      "736   1949.0  1950  1950\n",
      "1103  1954.0  1959  1959\n",
      "1376  1925.0  1930  1950\n",
      "1414  1922.0  1923  2000\n",
      "1418  1962.0  1963  1963\n",
      "         GYb    Yb    Yr\n",
      "61    1956.0  1959  1959\n",
      "116   2009.0  2010  2010\n",
      "345   1920.0  1935  1998\n",
      "380   1960.0  1978  1978\n",
      "435   1940.0  1941  1950\n",
      "437   1926.0  1935  1950\n",
      "662   1925.0  1945  1995\n",
      "803   2005.0  2006  2007\n",
      "1049  2005.0  2006  2006\n",
      "True\n",
      "Empty DataFrame\n",
      "Columns: [GYb, Yb, Yr]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [GYb, Yb, Yr]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# let's consider the year where the garage was built\n",
    "gyb = \"GYb\"\n",
    "print(df[df[gyb] < df[yb]][[gyb, yb, yr]])\n",
    "\n",
    "print(df_test[df_test[gyb] < df_test[yb]][[gyb, yb, yr]]) \n",
    "# with few exceptions the year where the garage if it is before the year where the house was built is generally few years earilier\n",
    "# which suggests that the garage was meant to be built with the house, yet the house took slightly longer to complete.\n",
    "\n",
    "# if GYb is less than Yb then we will set to Yb.\n",
    "def set_garage_year(row):\n",
    "    if row[gyb] < row[yb]:\n",
    "        row[gyb] = row[yb]\n",
    "    return row\n",
    "# set the changes in both train and test data\n",
    "print(callable(set_garage_year))\n",
    "apply_functions(set_garage_year)\n",
    "\n",
    "print(df[df[gyb] < df[yb]][[gyb, yb, yr]]) \n",
    "print(df_test[df_test[gyb] < df_test[yb]][[gyb, yb, yr]])\n",
    "# the changes were applied to both data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "The second step is imputing the missing values and making sure no Nan values are passed to our machine learning models. The main procedure is as follows:\n",
    "1. drop all columns with a nan ratio exceeding a certain treshhold\n",
    "2. imput the missing values. The strategy depends mainly on the feature in question:\n",
    "    * if the feature is highly related to other features, then a highly accurate and natural value can be deduced\n",
    "    * some statistical value could be used to impute the missing values\n",
    "    * investigating related features could help come up with an aggregated value when the data is grouped by a number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st strategy: drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage      259\n",
      "Alley           1369\n",
      "MasVnrType         8\n",
      "MasVnrArea         8\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtFinType2      38\n",
      "Electrical         1\n",
      "FireplaceQu      690\n",
      "GarageType        81\n",
      "GYb               81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "PoolQC          1453\n",
      "Fence           1179\n",
      "MiscFeature     1406\n",
      "dtype: int64\n",
      "Index(['Alley', 'PoolQC', 'Fence', 'MiscFeature'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let's first discover which columns have Nan values\n",
    "nan_values = df.isna().sum()\n",
    "cols_nan = nan_values[nan_values > 0]\n",
    "print(cols_nan)\n",
    "NAN_THRESHOLD = 0.8 # all columns with more than 0.8 nan values will be dropped\n",
    "cols_nan = cols_nan / len(df)\n",
    "# print(cols_nan)\n",
    "cols_nan_drop = cols_nan[cols_nan > NAN_THRESHOLD].index\n",
    "print(cols_nan_drop) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see: Alley, PoolQC, fence and MiscFeature have an extremely high ratio of nan values. \n",
    "before dropping these columns, it is necessary to drop features tightly related to those.  \n",
    "Investigating the data description reveals that:  \n",
    "* PoolQC is related to PoolArea\n",
    "* MiscFeature is related to MiscVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1453\n",
      "Name: PoolArea, dtype: int64\n",
      "197     235000\n",
      "810     181000\n",
      "1170    171000\n",
      "1182    745000\n",
      "1298    160000\n",
      "1386    250000\n",
      "1423    274970\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's better understand those relations\n",
    "pq = \"PoolQC\"\n",
    "pa = \"PoolArea\"\n",
    "print(df[df[pq].isna()][pa].value_counts()) \n",
    "# Nan values are associated with 0 pool area, which means that there is no pool in the first place\n",
    "# an extremely high ratio of houses do not have a pool.\n",
    "# let's consider the prices of houses with pool\n",
    "print(df[~df[pq].isna()][Y]) # we can see that the values too few and quite variant as well\n",
    "# thus is it better to drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1406\n",
      "Name: MiscVal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "misf = \"MiscFeature\"\n",
    "misv = \"MiscVal\"\n",
    "print(df[df[misf].isna()][misv].value_counts()) # we can see that houses with Nan on MiscFeature \n",
    "# have 0 on MiscVal which means that they do not any additional features to mention\n",
    "# both of these features should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop the features in questions\n",
    "cols_nan_drop = cols_nan_drop.values.tolist() + [misv, pa]\n",
    "drop_cols(cols_nan_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd strategy: deduce values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage     259\n",
      "MasVnrType        8\n",
      "MasVnrArea        8\n",
      "BsmtQual         37\n",
      "BsmtCond         37\n",
      "BsmtExposure     38\n",
      "BsmtFinType1     37\n",
      "BsmtFinType2     38\n",
      "Electrical        1\n",
      "FireplaceQu     690\n",
      "GarageType       81\n",
      "GYb              81\n",
      "GarageFinish     81\n",
      "GarageQual       81\n",
      "GarageCond       81\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's consider the columns left with nan values\n",
    "nan_values = df.isna().sum()\n",
    "cols_nan = nan_values[nan_values > 0]\n",
    "print(cols_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values with Nan can be divided into categories:\n",
    "* Masonry veneer \n",
    "* Basement\n",
    "* Garage\n",
    "* FirePlace\n",
    "* LotFrontage (only one column) and Electrical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nan(col_names:list, fill_values:list):\n",
    "    one = isinstance(col_names, str) and isinstance(fill_values, str)\n",
    "    try:\n",
    "        many = len(col_names) == len(fill_values)\n",
    "    except:\n",
    "        many = False\n",
    "    assert one or many \n",
    "    global df, df_test\n",
    "    if many: \n",
    "        for col, v in zip(col_names, fill_values):\n",
    "            df[col] = df[col].fillna(v)\n",
    "            df_test[col] = df_test[col].fillna(v)\n",
    "    else:\n",
    "        df[col_names] = df[col_names].fillna(fill_values)\n",
    "        df_test[col_names] = df_test[col_names].fillna(fill_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MasVnrArea MasVnrType\n",
      "234          NaN        NaN\n",
      "529          NaN        NaN\n",
      "650          NaN        NaN\n",
      "936          NaN        NaN\n",
      "973          NaN        NaN\n",
      "977          NaN        NaN\n",
      "1243         NaN        NaN\n",
      "1278         NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "# let's consider Masonry Veneer columns\n",
    "msvt = \"MasVnrType\"\n",
    "msva = \"MasVnrArea\"\n",
    "\n",
    "print(df[(df[msvt].isna()) | (df[msva].isna())][[msva, msvt]]) \n",
    "# we can see that type and are either both nan or both non-nan\n",
    "# a reasonable assumption is that there is no Masonry Veneer\n",
    "\n",
    "set_nan([msvt, msva], ['None', 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    81\n",
      "Name: GarageArea, dtype: int64\n",
      "Series([], Name: GYb, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# let's consider the garage columns\n",
    "gt = \"GarageType\"\n",
    "gf = \"GarageFinish\"\n",
    "gc = \"GarageCars\"\n",
    "ga = \"GarageArea\"\n",
    "gcond = \"GarageCond\"\n",
    "gqua = \"GarageQual\"\n",
    "\n",
    "g = [gt, gyb, gf, gc, ga, gcond, gqua]\n",
    "print(df[df[gt].isna() | df[gyb].isna() | df[gf].isna() | df[gcond].isna() | df[gqua].isna()][ga].value_counts())\n",
    "# if any of the garage features in a certain row is set to Nan, then its area is 0\n",
    "# which means there is no garage\n",
    "\n",
    "# let's first consider the Garage built year feature for such rows\n",
    "print(df[df[gt].isna() | df[gf].isna() | df[gcond].isna() | df[gqua].isna()][gyb].value_counts())\n",
    "\n",
    "set_nan(g, [\"NA\", 0, \"NA\", 0, 0, \"NA\", \"NA\"])\n",
    "\n",
    "garage_old_new = {gt: \"gt\", gf:\"gf\", gc:\"gc\", ga:\"ga\", gcond:\"gcond\", gqua:\"gqua\"}\n",
    "\n",
    "new_col_names(garage_old_new)\n",
    "\n",
    "gt = \"gt\"\n",
    "gf = \"gf\"\n",
    "gc = \"gc\"\n",
    "ga = \"ga\"\n",
    "gcond = \"gcond\"\n",
    "gqua = \"gqua\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37\n",
      "Name: bSF1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's consider the basement nan-values\n",
    "bqua = \"BsmtQual\"\n",
    "bcond = \"BsmtCond\"\n",
    "bexp = \"BsmtExposure\"\n",
    "bf2 = \"BsmtFinType2\"\n",
    "bf1 = \"BsmtFinType1\"\n",
    "baf1 = \"bSF1\"\n",
    "baf2 = \"bSF2\"\n",
    "\n",
    "# BsmtQual         37\n",
    "# BsmtCond         37\n",
    "# BsmtExposure     38\n",
    "# BsmtFinType1     37\n",
    "# BsmtFinType2     38\n",
    "\n",
    "print(df[df[bqua].isna() & df[bcond].isna() & df[bexp].isna() & df[bf1].isna() ][baf1].value_counts())\n",
    "# we can assume that Nan values for each of these basement features reflect No basement\n",
    "\n",
    "set_nan([bqua, bcond, bexp, bf1, bf2], [\"NA\"] * 5)\n",
    "# change the basement's features \n",
    "\n",
    "basement_new_old = {bqua: \"bqua\", bcond: \"bcond\", bexp: \"bexp\", bf1:\"bf1\", bf2: \"bf2\"}\n",
    "new_col_names(basement_new_old)\n",
    "\n",
    "bqua = \"bqua\"\n",
    "bcond = \"bcond\"\n",
    "bexp = \"bexp\"\n",
    "bf2 = \"bf2\"\n",
    "bf1 = \"bf1\"\n",
    "baf1 = \"baf1\"\n",
    "baf2 = \"baf2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    690\n",
      "Name: Fireplaces, dtype: int64\n",
      "SBrkr    1334\n",
      "FuseA      94\n",
      "FuseF      27\n",
      "FuseP       3\n",
      "Mix         1\n",
      "Name: Electrical, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's check the rest real quick\n",
    "# LotFrontage     259\n",
    "# Electrical        1\n",
    "# FireplaceQu     690\n",
    "\n",
    "firequa = \"FireplaceQu\"\n",
    "firep = \"Fireplaces\"\n",
    "print(df[df[firequa].isna()][firep].value_counts())\n",
    "# so nan values refer to NOn existing fire places\n",
    "set_nan(firequa, \"NA\")\n",
    "\n",
    "e = \"Electrical\"\n",
    "print(df[e].value_counts())\n",
    "lf = \"LotFrontage\"\n",
    "# we can assume that the only missing value is SBrkr with a high statistical possibility\n",
    "# the simplest solution for LotFrontage is to nan values to 0\n",
    "set_nan([e, lf], [\"SBrkr\", 0])\n",
    "\n",
    "fire_new_old = {firequa:\"firequa\", firep:\"firep\"}\n",
    "new_col_names(fire_new_old)\n",
    "\n",
    "firequa = \"firequa\"\n",
    "firep = \"firep\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(df[df.isna()].sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's consider once again categorical and numerical features\n",
    "non_num_cols = df.select_dtypes([object_type, cat_type]).columns\n",
    "# print(non_num_cols)\n",
    "num_cols = df.select_dtypes(np.number).columns.values.tolist()\n",
    "# print(num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the current state of the dataframes of later modifications\n",
    "df_cat = df.copy()\n",
    "df_t_cat = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal_non_num = [\"LotShape\", \"Utilities\", \"LandSlope\", \"ExterQual\"\n",
    "# , \"ExterCond\", \"bqua\", \"bcond\", \"bexp\", \"bf1\", \"bf2\", \"Heating\", \"HeatingQC\", \"Electrical\", \n",
    "# \"KitchenQual\", \"Functional\", \"firequa\", \"gf\", \"gqua\", \"gcond\", \"PavedDrive\"]\n",
    " \n",
    "# let's define the orders for each of the ordinal columns\n",
    "usual_levels = [\"NA\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "\n",
    "ordered_levels = {\n",
    "    \"ExterQual\": usual_levels,\n",
    "    \"ExterCond\": usual_levels,\n",
    "    \"bqua\": usual_levels,\n",
    "    \"bcond\": usual_levels,\n",
    "    \"HeatingQC\": usual_levels,\n",
    "    \"KitchenQual\": usual_levels,\n",
    "    \"firequa\": usual_levels,\n",
    "    \"gqua\": usual_levels,\n",
    "    \"gcond\": usual_levels,\n",
    "    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n",
    "    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n",
    "    \"bexp\": [\"NA\", \"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    \"bf1\": [\"NA\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"bf2\": [\"NA\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    \"gf\": [\"NA\", \"Unf\", \"RFn\", \"Fin\"],\n",
    "    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n",
    "    \"CentralAir\": [\"N\", \"Y\"],\n",
    "    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's encode ordinal data\n",
    "def cat_to_ord(col:list, categories:list, ordered:bool=True):\n",
    "    global df, df_test\n",
    "    final_cat = categories if ordered else categories[::-1]\n",
    "    df[col] = df[col].apply(dict(zip(final_cat, range(0, len(final_cat)))).get)\n",
    "    df_test[col] = df_test[col].apply(dict(zip(final_cat, range(0, len(final_cat)))).get)\n",
    "\n",
    "\n",
    "for k, v in ordered_levels.items():\n",
    "    cat_to_ord(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    906\n",
      "4    488\n",
      "5     52\n",
      "2     14\n",
      "Name: ExterQual, dtype: int64\n",
      "3    1282\n",
      "4     146\n",
      "2      28\n",
      "5       3\n",
      "1       1\n",
      "Name: ExterCond, dtype: int64\n",
      "3    649\n",
      "4    618\n",
      "5    121\n",
      "0     37\n",
      "2     35\n",
      "Name: bqua, dtype: int64\n",
      "3    1311\n",
      "4      65\n",
      "2      45\n",
      "0      37\n",
      "1       2\n",
      "Name: bcond, dtype: int64\n",
      "5    741\n",
      "3    428\n",
      "4    241\n",
      "2     49\n",
      "1      1\n",
      "Name: HeatingQC, dtype: int64\n",
      "3    735\n",
      "4    586\n",
      "5    100\n",
      "2     39\n",
      "Name: KitchenQual, dtype: int64\n",
      "0    690\n",
      "4    380\n",
      "3    313\n",
      "2     33\n",
      "5     24\n",
      "1     20\n",
      "Name: firequa, dtype: int64\n",
      "3    1311\n",
      "0      81\n",
      "2      48\n",
      "4      14\n",
      "5       3\n",
      "1       3\n",
      "Name: gqua, dtype: int64\n",
      "3    1326\n",
      "0      81\n",
      "2      35\n",
      "4       9\n",
      "1       7\n",
      "5       2\n",
      "Name: gcond, dtype: int64\n",
      "0    925\n",
      "1    484\n",
      "2     41\n",
      "3     10\n",
      "Name: LotShape, dtype: int64\n",
      "2    1382\n",
      "1      65\n",
      "0      13\n",
      "Name: LandSlope, dtype: int64\n",
      "1    953\n",
      "3    221\n",
      "4    134\n",
      "2    114\n",
      "0     38\n",
      "Name: bexp, dtype: int64\n",
      "1    430\n",
      "6    418\n",
      "5    220\n",
      "4    148\n",
      "3    133\n",
      "2     74\n",
      "0     37\n",
      "Name: bf1, dtype: int64\n",
      "1    1256\n",
      "3      54\n",
      "2      46\n",
      "0      38\n",
      "4      33\n",
      "5      19\n",
      "6      14\n",
      "Name: bf2, dtype: int64\n",
      "7    1360\n",
      "5      34\n",
      "6      31\n",
      "4      15\n",
      "2      14\n",
      "3       5\n",
      "1       1\n",
      "Name: Functional, dtype: int64\n",
      "1    605\n",
      "2    422\n",
      "3    352\n",
      "0     81\n",
      "Name: gf, dtype: int64\n",
      "2    1340\n",
      "0      90\n",
      "1      30\n",
      "Name: PavedDrive, dtype: int64\n",
      "2    1459\n",
      "0       1\n",
      "Name: Utilities, dtype: int64\n",
      "1    1365\n",
      "0      95\n",
      "Name: CentralAir, dtype: int64\n",
      "4    1335\n",
      "3      94\n",
      "2      27\n",
      "1       3\n",
      "0       1\n",
      "Name: Electrical, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for k in ordered_levels.keys():\n",
    "    print(df[k].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's encode non ordinal data using the label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "non_ord_cat = [cat for cat in non_num_cols if cat not in ordered_levels.keys()]\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in non_ord_cat:\n",
    "    df[col] = le.fit_transform(df[col].values)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureEngineering\n",
    "In this section we will work on improving the performance by creating a number of sythetic features out of the given ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save the dataframe before introducing any new feature\n",
    "df_base = df.copy()\n",
    "df_test_base = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance\n",
    "Creating a baseline model with the initial (left) features gives us a ground on which I base my next decisions. I will use the same performance metric as in the competition. The baseline model would be a sophisticated RandomForest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definining the cross validation procedure\n",
    "from sklearn.model_selection import KFold\n",
    "n_splits = 5 \n",
    "random_state = 3\n",
    "shuffle = True\n",
    "kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted', 'matthews_corrcoef', 'max_error', 'mutual_info_score', 'neg_brier_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_gamma_deviance', 'neg_mean_poisson_deviance', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'neg_root_mean_squared_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'rand_score', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'roc_auc_ovo', 'roc_auc_ovo_weighted', 'roc_auc_ovr', 'roc_auc_ovr_weighted', 'top_k_accuracy', 'v_measure_score']\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.get_scorer_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main score of the competition is the square of log error squared\n",
    "# let's define a function to calculate a model's performance according to this metric\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor as xgr\n",
    "def model_performance(X, y, model=xgr(seed=0)):\n",
    "    global kf, scoring\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(model, X, log_y, cv=5, scoring=scoring)\n",
    "    return np.sqrt(-score.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13672205323313016\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(Y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_base = RandomForestRegressor(max_depth=5, n_estimators=100, random_state=3)\n",
    "base_score = model_performance(X, y)\n",
    "print(base_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informative features: mutual information\n",
    "The mutual information is quite a powerful and general technique to determine the relevance of features with respect to the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    # discrete features are the ones with type int\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qua             5.786503e-01\n",
       "Neighborhood    5.253900e-01\n",
       "ga              4.927946e-01\n",
       "GrLivArea       4.328080e-01\n",
       "Yb              4.087151e-01\n",
       "                    ...     \n",
       "Condition2      2.664787e-03\n",
       "3SsnPorch       7.615664e-04\n",
       "Street          3.666896e-04\n",
       "Utilities       1.887379e-15\n",
       "MoSold          0.000000e+00\n",
       "Name: MI Scores, Length: 73, dtype: float64"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores = make_mi_scores(X, y)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_feats = mi_scores[mi_scores < 0.01].index.values.tolist()\n",
    "\n",
    "drop_cols(irrelevant_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13658118416692003\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(Y) \n",
    "\n",
    "new_score = model_performance(X, y)\n",
    "print(new_score) # a very small gain is achieved out of removing the unformative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qua             0.578650\n",
      "Neighborhood    0.525390\n",
      "ga              0.492795\n",
      "GrLivArea       0.432808\n",
      "Yb              0.408715\n",
      "TotalBsmtSF     0.399518\n",
      "LotArea         0.392427\n",
      "gc              0.360102\n",
      "bqua            0.331398\n",
      "ExterQual       0.325150\n",
      "KitchenQual     0.322472\n",
      "1stFlrSF        0.283265\n",
      "mss             0.278183\n",
      "Yr              0.275659\n",
      "FullBath        0.273156\n",
      "gf              0.262945\n",
      "GYb             0.259218\n",
      "LotFrontage     0.216092\n",
      "firequa         0.209348\n",
      "TotRmsAbvGrd    0.207962\n",
      "Name: MI Scores, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(mi_scores.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality feature\n",
    "This subsection I try to understand the Quality feature and its relations to the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a a function that returns three lists: num, ord, cat features\n",
    "def feature_types():\n",
    "    global df, df_test\n",
    "    # using the dataframe version before the numerical encoding\n",
    "    num = df_cat.select_dtypes(np.number).columns.values.tolist()\n",
    "    ord = [k for k in ordered_levels.keys()]\n",
    "    # filter the columns that are still in the dataframe\n",
    "    num = [col for col in num if col in df.columns]\n",
    "    ord = [col for col in ord if col in df.columns]\n",
    "    # the columns left in df that do not belong to the previous two are categorical\n",
    "    cat = [k for k in df.columns if k not in ord and k not in num]\n",
    "    return num, ord, cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols, ord_cols, cat_cols = feature_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MasVnrArea      0.407252\n",
      "TotRmsAbvGrd    0.427452\n",
      "HeatingQC       0.457083\n",
      "1stFlrSF        0.476224\n",
      "firequa         0.490788\n",
      "TotalBsmtSF     0.537808\n",
      "FullBath        0.550600\n",
      "Yr              0.550684\n",
      "gf              0.556863\n",
      "ga              0.562022\n",
      "Yb              0.572323\n",
      "GrLivArea       0.593007\n",
      "gc              0.600671\n",
      "bqua            0.629379\n",
      "KitchenQual     0.673331\n",
      "ExterQual       0.726278\n",
      "y               0.790982\n",
      "qua             1.000000\n",
      "Name: qua, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "num_or_ordinal = num_cols  + ord_cols\n",
    "corr_with_qua = df.loc[:, num_or_ordinal].corr()[qua] \n",
    "corr_with_qua = corr_with_qua[(corr_with_qua > 0.4) | (corr_with_qua < -0.4)]\n",
    "print(corr_with_qua.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatters(col_names, x=None):\n",
    "    global df, df_test\n",
    "    if x is None:\n",
    "        x = df.index.values.tolist()\n",
    "    for col in col_names:\n",
    "        plt.scatter(x=x, y=df[col].values)\n",
    "        \n",
    "    plt.title(str(col_names) + \" variation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_funcs = ['count', np.mean, np.median, np.min, np.max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count      mean median amin amax mode\n",
      "            qua       qua    qua  qua  qua  qua\n",
      "ExterQual                                      \n",
      "2            14  3.785714      4    1    7    4\n",
      "3           906  5.400662      5    2    9    5\n",
      "4           488  7.168033      7    3   10    7\n",
      "5            52  8.865385      9    6   10    9\n",
      "     count      mean median amin amax mode\n",
      "       qua       qua    qua  qua  qua  qua\n",
      "bqua                                      \n",
      "0       37  4.297297      4    1    7    5\n",
      "2       35  4.885714      5    1    7    5\n",
      "3      649  5.329738      5    2   10    5\n",
      "4      618  6.660194      7    4    9    7\n",
      "5      121  8.264463      8    5   10    8\n",
      "          count      mean median amin amax mode\n",
      "            qua       qua    qua  qua  qua  qua\n",
      "HeatingQC                                      \n",
      "1             1  5.000000      5    5    5    5\n",
      "2            49  5.000000      5    1    8    5\n",
      "3           428  5.371495      5    2    8    5\n",
      "4           241  5.701245      6    1   10    5\n",
      "5           741  6.723347      7    3   10    7\n",
      "            count      mean median amin amax mode\n",
      "              qua       qua    qua  qua  qua  qua\n",
      "KitchenQual                                      \n",
      "2              39  4.487179    5.0    1    7    4\n",
      "3             735  5.338776    5.0    2    8    5\n",
      "4             586  6.790102    7.0    3   10    7\n",
      "5             100  8.270000    8.5    5   10    9\n",
      "        count      mean median amin amax mode\n",
      "          qua       qua    qua  qua  qua  qua\n",
      "firequa                                      \n",
      "0         690  5.459420    5.0    1    9    5\n",
      "1          20  4.950000    5.0    2    7    5\n",
      "2          33  5.757576    6.0    5    8    6\n",
      "3         313  6.479233    6.0    4   10    6\n",
      "4         380  6.894737    7.0    3   10    6\n",
      "5          24  8.375000    8.5    5   10    9\n",
      "   count      mean median amin amax mode\n",
      "     qua       qua    qua  qua  qua  qua\n",
      "gf                                      \n",
      "0     81  4.604938      5    1    8    5\n",
      "1    605  5.404959      5    2   10    5\n",
      "2    422  6.573460      7    3   10    7\n",
      "3    352  7.068182      7    4   10    7\n"
     ]
    }
   ],
   "source": [
    "ord_corr_with_qua = [col for col in corr_with_qua.index if col in ord_cols]\n",
    "for col in ord_corr_with_qua:\n",
    "    print(pd.pivot_table(df, index=col, values=qua, aggfunc=agg_funcs + [pd.Series.mode]))\n",
    "    # plot_scatters([qua, col])\n",
    "# as for ordinal columns quality is hightly correlated with External, basement and kitchen qualityes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      qua                       \n",
      "    count  mean median amin amax\n",
      "qua                             \n",
      "1       2   1.0    1.0    1    1\n",
      "2       3   2.0    2.0    2    2\n",
      "3      20   3.0    3.0    3    3\n",
      "4     116   4.0    4.0    4    4\n",
      "5     397   5.0    5.0    5    5\n",
      "6     374   6.0    6.0    6    6\n",
      "7     319   7.0    7.0    7    7\n",
      "8     168   8.0    8.0    8    8\n",
      "9      43   9.0    9.0    9    9\n",
      "10     18  10.0   10.0   10   10\n",
      "       Yb                                 \n",
      "    count         mean  median  amin  amax\n",
      "qua                                       \n",
      "1       2  1934.000000  1934.0  1922  1946\n",
      "2       3  1935.000000  1936.0  1920  1949\n",
      "3      20  1932.700000  1935.0  1900  1955\n",
      "4     116  1948.284483  1954.0  1885  2005\n",
      "5     397  1954.732997  1959.0  1875  2007\n",
      "6     374  1967.636364  1971.0  1880  2009\n",
      "7     319  1988.269592  2000.0  1880  2009\n",
      "8     168  1996.821429  2003.0  1872  2009\n",
      "9      43  2005.116279  2006.0  1981  2010\n",
      "10     18  1991.888889  2006.0  1892  2009\n",
      "       Yr                                 \n",
      "    count         mean  median  amin  amax\n",
      "qua                                       \n",
      "1       2  1950.000000  1950.0  1950  1950\n",
      "2       3  1950.000000  1950.0  1950  1950\n",
      "3      20  1964.550000  1950.0  1950  2006\n",
      "4     116  1968.000000  1961.0  1950  2008\n",
      "5     397  1975.256927  1971.0  1950  2010\n",
      "6     374  1981.395722  1980.5  1950  2009\n",
      "7     319  1996.326019  2002.0  1950  2010\n",
      "8     168  2001.244048  2004.0  1950  2010\n",
      "9      43  2005.813953  2006.0  1987  2010\n",
      "10     18  2003.833333  2006.5  1993  2009\n",
      "    MasVnrArea                                \n",
      "         count        mean median amin    amax\n",
      "qua                                           \n",
      "1            2    0.000000    0.0  0.0     0.0\n",
      "2            3    0.000000    0.0  0.0     0.0\n",
      "3           20   17.000000    0.0  0.0   340.0\n",
      "4          116   14.008621    0.0  0.0   435.0\n",
      "5          397   44.030227    0.0  0.0  1047.0\n",
      "6          374  102.802139    0.0  0.0  1129.0\n",
      "7          319  104.382445    0.0  0.0  1600.0\n",
      "8          168  210.279762  175.0  0.0   975.0\n",
      "9           43  345.720930  300.0  0.0   870.0\n",
      "10          18  509.277778  362.5  0.0  1378.0\n",
      "    TotalBsmtSF                                 \n",
      "          count         mean  median  amin  amax\n",
      "qua                                             \n",
      "1             2   341.500000   341.5     0   683\n",
      "2             3   344.666667   290.0   264   480\n",
      "3            20   554.250000   660.5     0  1162\n",
      "4           116   755.232759   796.0     0  1768\n",
      "5           397   929.539043   927.0     0  2136\n",
      "6           374   983.526738   934.0     0  2035\n",
      "7           319  1108.514107  1080.0     0  2223\n",
      "8           168  1417.886905  1467.0   408  3206\n",
      "9            43  1734.395349  1766.0  1104  2330\n",
      "10           18  2231.777778  2041.0  1017  6110\n",
      "    1stFlrSF                                 \n",
      "       count         mean  median  amin  amax\n",
      "qua                                          \n",
      "1          2   619.000000   619.0   334   904\n",
      "2          3   572.666667   480.0   438   800\n",
      "3         20   951.400000   919.0   600  1733\n",
      "4        116   937.017241   888.0   372  1768\n",
      "5        397  1063.566751  1021.0   536  2136\n",
      "6        374  1087.163102  1046.0   483  2515\n",
      "7        319  1186.507837  1186.0   495  2223\n",
      "8        168  1462.767857  1483.0   707  3228\n",
      "9         43  1741.372093  1766.0  1130  2364\n",
      "10        18  2155.666667  2048.0  1026  4692\n",
      "    GrLivArea                                 \n",
      "        count         mean  median  amin  amax\n",
      "qua                                           \n",
      "1           2   619.000000   619.0   334   904\n",
      "2           3   572.666667   480.0   438   800\n",
      "3          20  1119.150000  1040.0   720  1733\n",
      "4         116  1106.672414  1051.5   520  2290\n",
      "5         397  1250.748111  1144.0   616  3086\n",
      "6         374  1465.874332  1440.5   720  3395\n",
      "7         319  1703.833856  1656.0   767  3493\n",
      "8         168  1947.613095  1813.5  1088  3447\n",
      "9          43  2077.511628  1922.0  1506  3140\n",
      "10         18  3001.388889  2517.5  1718  5642\n",
      "    FullBath                           \n",
      "       count      mean median amin amax\n",
      "qua                                    \n",
      "1          2  0.500000    0.5    0    1\n",
      "2          3  0.666667    1.0    0    1\n",
      "3         20  1.300000    1.0    1    2\n",
      "4        116  1.181034    1.0    0    2\n",
      "5        397  1.226700    1.0    0    3\n",
      "6        374  1.524064    2.0    0    3\n",
      "7        319  1.893417    2.0    0    3\n",
      "8        168  1.958333    2.0    1    3\n",
      "9         43  2.023256    2.0    0    3\n",
      "10        18  2.333333    2.0    2    3\n",
      "    TotRmsAbvGrd                           \n",
      "           count      mean median amin amax\n",
      "qua                                        \n",
      "1              2  3.000000    3.0    2    4\n",
      "2              3  3.666667    4.0    3    4\n",
      "3             20  5.900000    6.0    4    8\n",
      "4            116  5.500000    5.0    3   11\n",
      "5            397  6.027708    6.0    3   12\n",
      "6            374  6.339572    6.0    3   14\n",
      "7            319  6.918495    7.0    4   12\n",
      "8            168  7.428571    7.0    4   12\n",
      "9             43  8.255814    8.0    5   12\n",
      "10            18  9.388889   10.0    7   12\n",
      "       gc                           \n",
      "    count      mean median amin amax\n",
      "qua                                 \n",
      "1       2  0.000000    0.0    0    0\n",
      "2       3  0.666667    1.0    0    1\n",
      "3      20  1.200000    1.0    0    3\n",
      "4     116  1.163793    1.0    0    4\n",
      "5     397  1.367758    1.0    0    4\n",
      "6     374  1.689840    2.0    0    3\n",
      "7     319  2.062696    2.0    0    4\n",
      "8     168  2.458333    2.0    0    3\n",
      "9      43  2.813953    3.0    2    3\n",
      "10     18  2.888889    3.0    2    3\n",
      "       ga                              \n",
      "    count        mean median amin  amax\n",
      "qua                                    \n",
      "1       2    0.000000    0.0    0     0\n",
      "2       3  184.666667  246.0    0   308\n",
      "3      20  319.400000  297.5    0  1248\n",
      "4     116  321.741379  300.5    0  1356\n",
      "5     397  384.025189  352.0    0   995\n",
      "6     374  430.735294  440.0    0   924\n",
      "7     319  532.849530  527.0    0   983\n",
      "8     168  681.732143  676.0    0  1390\n",
      "9      43  753.697674  746.0  478  1166\n",
      "10     18  878.611111  841.0  641  1418\n",
      "        y                                         \n",
      "    count           mean    median    amin    amax\n",
      "qua                                               \n",
      "1       2   50150.000000   50150.0   39300   61000\n",
      "2       3   51770.333333   60000.0   35311   60000\n",
      "3      20   87473.750000   86250.0   37900  139600\n",
      "4     116  108420.655172  108000.0   34900  256000\n",
      "5     397  133523.347607  133000.0   55993  228950\n",
      "6     374  161603.034759  160000.0   76000  277000\n",
      "7     319  207716.423197  200141.0   82500  383970\n",
      "8     168  274735.535714  269750.0  122000  538000\n",
      "9      43  367513.023256  345000.0  239000  611657\n",
      "10     18  438588.388889  432390.0  160000  755000\n"
     ]
    }
   ],
   "source": [
    "# let's consider the numerical features\n",
    "num_corr_with_qua = [col for col in corr_with_qua.index if col in num_cols]\n",
    "for col in num_corr_with_qua:\n",
    "    print(df.groupby(qua).agg({col:agg_funcs}))\n",
    "# as for the numerical features, we have:\n",
    "# total area for basement, living area, year of building\n",
    "# fullbath, total rooms, gc, garea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state    0.565294\n",
      "y        1.000000\n",
      "qua      0.790982\n",
      "cond    -0.077856\n",
      "Name: y, dtype: float64\n",
      "state    0.746668\n",
      "y        1.000000\n",
      "qua      0.790982\n",
      "cond    -0.077856\n",
      "Name: y, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# let's consider a new feature: qua * cond\n",
    "df['state'] = df[qua] * df[cond]\n",
    "# print(df['state'].value_counts().sort_index())\n",
    "print(df[['state', Y, qua, cond]].corr()[Y])\n",
    "# as the condition is not as significant as the quality, it might be worth trying a different tranformation\n",
    "df['state'] = df[qua] *  np.floor(np.sqrt(df[cond]))\n",
    "print(df[['state', Y, qua, cond]].corr()[Y])\n",
    "# apparently this feature makes the best out of both features let's verify its effect with and without the old features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135245696539859\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(Y)\n",
    "print(model_performance(X, y))\n",
    "# there is some slight improvement of 0.01 \n",
    "# # the feature is worth keeping\n",
    "df_test['state'] = df_test[qua] *  np.floor(np.sqrt(df_test[cond]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Garage features\n",
    "Garage is clearly an informative element. Some more investigation is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             gt       GYb        gf        gc        ga      gqua     gcond\n",
      "gt     1.000000 -0.457129 -0.585905 -0.445903 -0.411341 -0.461255 -0.472196\n",
      "GYb   -0.457129  1.000000  0.489831  0.597991  0.560766  0.946611  0.949418\n",
      "gf    -0.585905  0.489831  1.000000  0.579729  0.516428  0.482399  0.481813\n",
      "gc    -0.445903  0.597991  0.579729  1.000000  0.882475  0.576622  0.568408\n",
      "ga    -0.411341  0.560766  0.516428  0.882475  1.000000  0.558938  0.547259\n",
      "gqua  -0.461255  0.946611  0.482399  0.576622  0.558938  1.000000  0.959172\n",
      "gcond -0.472196  0.949418  0.481813  0.568408  0.547259  0.959172  1.000000\n"
     ]
    }
   ],
   "source": [
    "garage_cols = [col for col in df.columns if col.lower().startswith(\"g\")]\n",
    "garage_cols.remove(\"GrLivArea\")\n",
    "print(df[garage_cols].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detchd     191\n",
      "NA          81\n",
      "Attchd      30\n",
      "2Types       2\n",
      "CarPort      2\n",
      "BuiltIn      2\n",
      "Name: gt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's inspect gt, GYB, and gf\n",
    "# for c in [gt, gyb, gf]:\n",
    "#     print(df_cat[c].value_counts())\n",
    "\n",
    "print(df_cat[(df_cat[gyb] != df_cat[yb]) & (df_cat[gyb]!= df_cat[yr])][gt].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     count         mean  median    amin    amax                      mode\n",
      "       GYb          GYb     GYb     GYb     GYb                       GYb\n",
      "gqua                                                                     \n",
      "0       81     0.000000     0.0     0.0     0.0                       0.0\n",
      "1        3  1918.666667  1920.0  1910.0  1926.0  [1910.0, 1920.0, 1926.0]\n",
      "2       48  1933.937500  1930.5  1908.0  1977.0                    1920.0\n",
      "3     1311  1980.254005  1982.0  1906.0  2010.0                    2005.0\n",
      "4       14  1980.928571  1985.0  1939.0  2006.0                    1990.0\n",
      "5        3  1989.000000  1993.0  1966.0  2008.0  [1966.0, 1993.0, 2008.0]\n",
      "      count         mean  median    amin    amax              mode\n",
      "        GYb          GYb     GYb     GYb     GYb               GYb\n",
      "gcond                                                             \n",
      "0        81     0.000000     0.0     0.0     0.0               0.0\n",
      "1         7  1922.714286  1920.0  1910.0  1940.0            1910.0\n",
      "2        35  1939.142857  1932.0  1914.0  1981.0            1920.0\n",
      "3      1326  1979.895928  1981.0  1906.0  2010.0            2005.0\n",
      "4         9  1972.555556  1983.0  1910.0  1997.0  [1966.0, 1990.0]\n",
      "5         2  1987.000000  1987.0  1966.0  2008.0  [1966.0, 2008.0]\n",
      "   count      mean median amin amax mode\n",
      "    gqua      gqua   gqua gqua gqua gqua\n",
      "gf                                      \n",
      "0     81  0.000000      0    0    0    0\n",
      "1    605  2.927273      3    1    5    3\n",
      "2    422  3.016588      3    3    4    3\n",
      "3    352  3.008523      3    2    5    3\n",
      "   count      mean median  amin  amax  mode\n",
      "   gcond     gcond  gcond gcond gcond gcond\n",
      "gf                                         \n",
      "0     81  0.000000      0     0     0     0\n",
      "1    605  2.928926      3     1     5     3\n",
      "2    422  3.011848      3     3     4     3\n",
      "3    352  3.005682      3     2     5     3\n"
     ]
    }
   ],
   "source": [
    "print(pd.pivot_table(df, values=gyb, index=gqua, aggfunc=agg_funcs + [pd.Series.mode]))\n",
    "print(pd.pivot_table(df, values=gyb, index=gcond, aggfunc=agg_funcs + [pd.Series.mode]))\n",
    "# we can see that the older the more likely for its quality as well as condition to degrade\n",
    "# let's try to incorporate this idea\n",
    "print(pd.pivot_table(df, values=gqua, index=gf, aggfunc=agg_funcs + [pd.Series.mode]))\n",
    "print(pd.pivot_table(df, values=gcond, index=gf, aggfunc=agg_funcs + [pd.Series.mode]))\n",
    "\n",
    "# the gf seems of little to no significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     count      mean median amin amax\n",
      "       qua       qua    qua  qua  qua\n",
      "gqua                                 \n",
      "0       81  4.604938    5.0    1    8\n",
      "1        3  5.333333    5.0    5    6\n",
      "2       48  5.166667    5.0    3    7\n",
      "3     1311  6.218917    6.0    2   10\n",
      "4       14  6.714286    6.5    5   10\n",
      "5        3  7.000000    6.0    5   10\n",
      "gqua     0.273839\n",
      "gcond    0.263191\n",
      "y        1.000000\n",
      "Name: y, dtype: float64\n",
      "y         1.000000\n",
      "gcond     0.263191\n",
      "gqua      0.273839\n",
      "gcond2    0.264539\n",
      "gstate    0.745916\n",
      "Name: y, dtype: float64\n",
      "gcond     0.078230\n",
      "gqua      0.088709\n",
      "gcond2    0.071406\n",
      "gstate    0.594170\n",
      "Name: MI Scores, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.pivot_table(df, index=gqua, values=qua, aggfunc=agg_funcs))\n",
    "print(df[[gqua, gcond, Y]].corr()[Y])\n",
    "# the new state of garage should be similar to the one created for the whole whouse\n",
    "# let's suggest the new state\n",
    "# 0, 1,2 -> 1/2 : quality is low anyway\n",
    "# 3 -> 1: only the quality matters in this case\n",
    "# in general quality is high, a better condition means a better state\n",
    "\n",
    "gcond2= \"gcond2\"\n",
    "def new_gcond(row):\n",
    "    row[gcond2] = 0\n",
    "    if row[gcond] in [0, 1, 2]:\n",
    "        row[gcond2] = 0.5\n",
    "    elif row[gcond] == 3:\n",
    "        row[gcond2] = 1\n",
    "    else:\n",
    "        row[gcond2] = 1.5\n",
    "    return row\n",
    "apply_functions(new_gcond, on='df')\n",
    "df['gstate'] = df[qua] * df[gcond2]\n",
    "print(df[[Y, gcond, gqua, gcond2, 'gstate']].corr()[Y]) \n",
    "# as we can see is highly correlated with the target variable\n",
    "# let's test the new feature\n",
    "X = df.copy()\n",
    "y = X.pop(Y)\n",
    "g_mi_scores =  make_mi_scores(X, y)[[gcond, gqua, gcond2, 'gstate']]\n",
    "print(g_mi_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14115384351745744\n",
      "0.1387419946550987\n"
     ]
    }
   ],
   "source": [
    "# at the moment the new feature seems quite promising, let's inspect its effect on the performance\n",
    "print(model_performance(X, y))\n",
    "\n",
    "# let's try removing the different subsets of [gcon, gqua, gcond2]\n",
    "X1 = df.drop([gcond, gqua, gcond2], axis=1).copy()\n",
    "y1 = X1.pop(Y)\n",
    "print(model_performance(X1, y1))\n",
    "\n",
    "## uncomment the lines of code below to \n",
    "## see the performance with the different subsets of removed featurs\n",
    "\n",
    "# X2= df.drop([gqua, gcond2], axis=1).copy()\n",
    "# y2 = X2.pop(Y)\n",
    "# print(model_performance(X2, y2))\n",
    "\n",
    "# X3= df.drop([gcond, gcond2], axis=1).copy()\n",
    "# y3 = X3.pop(Y)\n",
    "# print(model_performance(X3, y3))\n",
    "\n",
    "# X4= df.drop([gcond, gqua], axis=1).copy()\n",
    "# y4 = X4.pop(Y)\n",
    "# print(model_performance(X4, y4))\n",
    "\n",
    "# X5= df.drop([gcond], axis=1).copy()\n",
    "# y5 = X5.pop(Y)\n",
    "# print(model_performance(X5, y5))\n",
    "\n",
    "# X6= df.drop([gcond2], axis=1).copy()\n",
    "# y6 = X6.pop(Y)\n",
    "# print(model_performance(X6, y6))\n",
    "\n",
    "# X7= df.drop([gqua], axis=1).copy()\n",
    "# y7 = X7.pop(Y)\n",
    "# print(model_performance(X7, y7))\n",
    "\n",
    "## even though the performance did not improve, the mi scores as well a\n",
    "## as the correlation scores are solid proofs of the usefulness of this feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_gyb = df[gyb].min()\n",
    "max_gyb = df[gyb].max()\n",
    "# there are two possible ways, either consider age divided by the number of garages\n",
    "# or consider the square root or log of the age\n",
    "gage = \"gage\"\n",
    "df[gage] = np.log(np.sqrt((max_gyb + 2) - df[gyb]))\n",
    "\n",
    "gage_counts = df[gage].value_counts()\n",
    "plt.bar(gage_counts.index.values, gage_counts.values)\n",
    "plt.show()\n",
    "# the gage feature is promising\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop gt, gf for the moment, as they do not seem to be as informative \n",
    "drop_cols([gt, gf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GYb', 'gc', 'ga', 'gqua', 'gcond', 'gcond2', 'gstate', 'gage']\n"
     ]
    }
   ],
   "source": [
    "garage_cols = [col for col in df.columns if col.lower().startswith(\"g\")]\n",
    "garage_cols.remove(\"GrLivArea\")\n",
    "print(garage_cols )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ga        gc         y\n",
      "ga  1.000000  0.882475  0.623431\n",
      "gc  0.882475  1.000000  0.640409\n",
      "y   0.623431  0.640409  1.000000\n",
      "    count        mean median   amin    amax  \\\n",
      "       ga          ga     ga     ga      ga   \n",
      "gc                                            \n",
      "0.0    81    0.000000    0.0    0.0     0.0   \n",
      "1.0   369  300.517615  288.0  160.0   924.0   \n",
      "2.0   824  519.797330  506.0  320.0  1418.0   \n",
      "3.0   181  811.574586  818.0  478.0  1390.0   \n",
      "4.0     5  890.400000  864.0  480.0  1356.0   \n",
      "\n",
      "                                     mode  \n",
      "                                       ga  \n",
      "gc                                         \n",
      "0.0                                   0.0  \n",
      "1.0                                 240.0  \n",
      "2.0                        [440.0, 576.0]  \n",
      "3.0                                 648.0  \n",
      "4.0  [480.0, 784.0, 864.0, 968.0, 1356.0]  \n",
      "             GYb        gc        ga      gqua     gcond    gcond2    gstate  \\\n",
      "GYb     1.000000  0.603395  0.560766  0.955594  0.955389  0.771366  0.513302   \n",
      "gc      0.603395  1.000000  0.882971  0.587506  0.577960  0.494980  0.675832   \n",
      "ga      0.560766  0.882971  1.000000  0.560913  0.550892  0.488915  0.634742   \n",
      "gqua    0.955594  0.587506  0.560913  1.000000  0.968380  0.834319  0.542678   \n",
      "gcond   0.955389  0.577960  0.550892  0.968380  1.000000  0.897202  0.565256   \n",
      "gcond2  0.771366  0.494980  0.488915  0.834319  0.897202  1.000000  0.612033   \n",
      "gstate  0.513302  0.675832  0.634742  0.542678  0.565256  0.612033  1.000000   \n",
      "gage   -0.779102 -0.766572 -0.717120 -0.758838 -0.753247 -0.648358 -0.716012   \n",
      "\n",
      "            gage  \n",
      "GYb    -0.779102  \n",
      "gc     -0.766572  \n",
      "ga     -0.717120  \n",
      "gqua   -0.758838  \n",
      "gcond  -0.753247  \n",
      "gcond2 -0.648358  \n",
      "gstate -0.716012  \n",
      "gage    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# let's consider the different relation between the two garage areas\n",
    "print(df[[ga, gc, Y]].corr())\n",
    "print(pd.pivot_table(df, values=ga, index=gc, aggfunc=agg_funcs + [pd.Series.mode]))\n",
    "\n",
    "# there is practically no difference between having 3 and 4 car capacity in a garage\n",
    "# let's experiment with setting the 5 4-car capacity garages to 3\n",
    "replace_values(gc, {4:3})\n",
    "print(df[garage_cols].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's investigate the effect of the area within the garage with the same car capacity\n",
    "g1cap = df[df[gc] == 1]\n",
    "g2cap = df[df[gc] == 2]\n",
    "g3cap = df[df[gc] == 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-956580.5160000001\n",
      "           yy    gay       yga   gaga  diffga    diffy\n",
      "0     35311.0  308.0   91000.0  160.0   148.0  -55.689\n",
      "1     40000.0  250.0   87000.0  160.0    90.0  -47.000\n",
      "2     58500.0  200.0  155000.0  164.0    36.0  -96.500\n",
      "3     60000.0  246.0  259500.0  180.0    66.0 -199.500\n",
      "4     60000.0  350.0  102000.0  180.0   170.0  -42.000\n",
      "..        ...    ...       ...    ...     ...      ...\n",
      "364  234000.0  282.0  132500.0  672.0  -390.0  101.500\n",
      "365  244400.0  349.0  110000.0  684.0  -335.0  134.400\n",
      "366  250000.0  180.0  153000.0  756.0  -576.0   97.000\n",
      "367  259500.0  180.0  143000.0  796.0  -616.0  116.500\n",
      "368  266500.0  252.0  120500.0  924.0  -672.0  146.000\n",
      "\n",
      "[369 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "g1cap_y = g1cap[[Y, ga]].sort_values(Y).reset_index().drop('index', axis=1)\n",
    "g1cap_ga = g1cap[[Y, ga]].sort_values(ga).reset_index().drop('index', axis=1)\n",
    "\n",
    "g1cap_com = g1cap_y.join(g1cap_ga, lsuffix='y', rsuffix='ga')\n",
    "g1cap_com['diffga'] = g1cap_com['gay'] - g1cap_com['gaga'] \n",
    "g1cap_com['diffy'] = (g1cap_com['yy'] - g1cap_com['yga']) / 10 ** 3\n",
    "print((g1cap_com['diffga'] * g1cap_com['diffy']).sum())\n",
    "print(g1cap_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2689615.3030000003\n",
      "           yy    gay       yga    gaga  diffga    diffy\n",
      "0     55993.0  504.0  163000.0   320.0   184.0 -107.007\n",
      "1     68400.0  528.0  143000.0   324.0   204.0  -74.600\n",
      "2     73000.0  504.0  115000.0   336.0   168.0  -42.000\n",
      "3     76000.0  360.0  177000.0   342.0    18.0 -101.000\n",
      "4     79900.0  528.0  174000.0   343.0   185.0  -94.100\n",
      "..        ...    ...       ...     ...     ...      ...\n",
      "819  359100.0  380.0  148500.0   902.0  -522.0  210.600\n",
      "820  375000.0  513.0  287000.0   905.0  -392.0   88.000\n",
      "821  392000.0  567.0  149700.0   923.0  -356.0  242.300\n",
      "822  392500.0  482.0  224000.0   924.0  -442.0  168.500\n",
      "823  430000.0  546.0  160000.0  1418.0  -872.0  270.000\n",
      "\n",
      "[824 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "g2cap_y = g2cap[[Y, ga]].sort_values(Y).reset_index().drop('index', axis=1)\n",
    "g2cap_ga = g2cap[[Y, ga]].sort_values(ga).reset_index().drop('index', axis=1)\n",
    "\n",
    "g2cap_com = g2cap_y.join(g2cap_ga, lsuffix='y', rsuffix='ga')\n",
    "g2cap_com['diffga'] = g2cap_com['gay'] - g2cap_com['gaga'] \n",
    "g2cap_com['diffy'] = (g2cap_com['yy'] - g2cap_com['yga']) / 10 ** 3\n",
    "print((g2cap_com['diffga'] * g2cap_com['diffy']).sum())\n",
    "print(g2cap_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           yy     gay       yga    gaga  diffga    diffy\n",
      "0     81000.0  1248.0  370878.0   478.0   770.0 -289.878\n",
      "1     87000.0   779.0  123000.0   480.0   299.0  -36.000\n",
      "2     98000.0   513.0   98000.0   513.0     0.0    0.000\n",
      "3    105000.0   936.0  320000.0   594.0   342.0 -215.000\n",
      "4    110000.0   888.0  395192.0   606.0   282.0 -285.192\n",
      "..        ...     ...       ...     ...     ...      ...\n",
      "181  582933.0  1020.0  501837.0  1166.0  -146.0   81.096\n",
      "182  611657.0   820.0  385000.0  1220.0  -400.0  226.657\n",
      "183  625000.0   807.0   81000.0  1248.0  -441.0  544.000\n",
      "184  745000.0   813.0  168000.0  1356.0  -543.0  577.000\n",
      "185  755000.0   832.0  253293.0  1390.0  -558.0  501.707\n",
      "\n",
      "[186 rows x 6 columns]\n",
      "-2079873.781\n"
     ]
    }
   ],
   "source": [
    "g3cap_y = g3cap[[Y, ga]].sort_values(Y).reset_index().drop('index', axis=1)\n",
    "g3cap_ga = g3cap[[Y, ga]].sort_values(ga).reset_index().drop('index', axis=1)\n",
    "\n",
    "g3cap_com = g3cap_y.join(g3cap_ga, lsuffix='y', rsuffix='ga')\n",
    "g3cap_com['diffga'] = g3cap_com['gay'] - g3cap_com['gaga'] \n",
    "g3cap_com['diffy'] = (g3cap_com['yy'] - g3cap_com['yga']) / 10 ** 3\n",
    "print(g3cap_com)\n",
    "print((g3cap_com['diffga'] * g3cap_com['diffy']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gc', 'gstate', 'gage']\n"
     ]
    }
   ],
   "source": [
    "# the garage area is to be dropped\n",
    "drop_cols([ga, gcond2, gcond, gqua, gyb])\n",
    "garage_cols = [col for col in df.columns if col.lower().startswith(\"g\")]\n",
    "garage_cols.remove(\"GrLivArea\")\n",
    "print(garage_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13872407608801454\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(Y)\n",
    "print(model_performance(X, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "006414dea9a04848ce797b510a25f3f28ac8668e3d3244e777242cca6bed477f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
