{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Pricing Predictions\n",
    "This is my attempt to solve the data science challenge on [Kaggle](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/overview), predicting the house prices given a large number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary work: imports and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to store the location of the training and test datasets\n",
    "train_file = \"train.csv\"\n",
    "test_file = \"test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_org = pd.read_csv(train_file)\n",
    "df_test_org = pd.read_csv(test_file)\n",
    "# df and df_test are copies of the original datasets with target value referred to as y\n",
    "Y = \"y\"\n",
    "df = df_train_org.rename(columns={'SalePrice': Y})\n",
    "df_test = df_test_org.rename(columns={'SalePrice':Y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration \n",
    "In this section we explore the basic aspects of the provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to drop an element to both train and test dataframes\n",
    "def drop_cols(col_names:list):\n",
    "    global df, df_test\n",
    "    try:\n",
    "        df = df.drop(col_names, axis=1)\n",
    "        df_test = df_test.drop(col_names, axis=1)\n",
    "    except:\n",
    "        print(\"The column{s} {cols} have already been dropped\".\n",
    "        format(s= \"\" if (col_names is str or len(col_names) == 1) else \"s\", cols=str(col_names)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# let's first understand the nature of our data\n",
    "print(df.shape) \n",
    "# each sample is described by 81 features. This number if relatively high.\n",
    "\n",
    "print((df['Id'].values == range(1 ,len(df) + 1)).all()) \n",
    "# as we can see the Id column is merely for ennumeriation purposes. It can be either dropped or set as an index.\n",
    "drop_cols(\"Id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical and Numerical features\n",
    "Let's consider the different types of features. First, we divide them into numerical and non-numerical. The non-numerical are definitely categorical (or can be made as such). As for numerical, columns with int values, can be considered categorical if the number of unique values is limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
      "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
      "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
      "       'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual',\n",
      "       'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature',\n",
      "       'SaleType', 'SaleCondition'],\n",
      "      dtype='object')\n",
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# consider non-numerical values\n",
    "object_type = \"object\"\n",
    "cat_type = 'category'\n",
    "non_num_cols = df.select_dtypes([object_type, cat_type]).columns\n",
    "print(non_num_cols)\n",
    "num_cols = df.select_dtypes(np.number).columns\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSSubClass': 15, 'LotArea': 1073, 'OverallQual': 10, 'OverallCond': 9, 'YearBuilt': 112, 'YearRemodAdd': 61, 'BsmtFinSF1': 637, 'BsmtFinSF2': 144, 'BsmtUnfSF': 780, 'TotalBsmtSF': 721, '1stFlrSF': 753, '2ndFlrSF': 417, 'LowQualFinSF': 24, 'GrLivArea': 861, 'BsmtFullBath': 4, 'BsmtHalfBath': 3, 'FullBath': 4, 'HalfBath': 3, 'BedroomAbvGr': 8, 'KitchenAbvGr': 4, 'TotRmsAbvGrd': 12, 'Fireplaces': 4, 'GarageCars': 5, 'GarageArea': 441, 'WoodDeckSF': 274, 'OpenPorchSF': 202, 'EnclosedPorch': 120, '3SsnPorch': 20, 'ScreenPorch': 76, 'PoolArea': 8, 'MiscVal': 21, 'MoSold': 12, 'YrSold': 5, 'y': 663}\n"
     ]
    }
   ],
   "source": [
    "# let's consider the subset of numerical columns with few discrete values\n",
    "num_discrete = df.select_dtypes('int64').columns\n",
    "num_dis_count = [len(df[num_d].unique()) for num_d in num_discrete]  \n",
    "print(dict(zip(num_discrete, num_dis_count)))\n",
    "\n",
    "# we can see that a \"MSSubClass\" is a categorical feature\n",
    "# a number of features are not categorical by say, but can be treated as such: Bath related features, Fireplaces, GarageCars, and most importantly\n",
    "# OverallQual and OveralCond\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Certain columns might contain corrupted data and thus require cleaning. I will start with categorical columns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning categorical columns \n",
    "The main procedure is as follows:\n",
    "* replace the values that do not belong to the data description set of values by the one described there, mainly typos in string typed values\n",
    "* in the worst case drop rows that have values significantly different from the pre-determined categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "['RL' 'RM' 'C (all)' 'FV' 'RH']\n",
      "\n",
      "Street\n",
      "['Pave' 'Grvl']\n",
      "\n",
      "Alley\n",
      "[nan 'Grvl' 'Pave']\n",
      "\n",
      "LotShape\n",
      "['Reg' 'IR1' 'IR2' 'IR3']\n",
      "\n",
      "LandContour\n",
      "['Lvl' 'Bnk' 'Low' 'HLS']\n",
      "\n",
      "Utilities\n",
      "['AllPub' 'NoSeWa']\n",
      "\n",
      "LotConfig\n",
      "['Inside' 'FR2' 'Corner' 'CulDSac' 'FR3']\n",
      "\n",
      "LandSlope\n",
      "['Gtl' 'Mod' 'Sev']\n",
      "\n",
      "Neighborhood\n",
      "['CollgCr' 'Veenker' 'Crawfor' 'NoRidge' 'Mitchel' 'Somerst' 'NWAmes'\n",
      " 'OldTown' 'BrkSide' 'Sawyer' 'NridgHt' 'NAmes' 'SawyerW' 'IDOTRR'\n",
      " 'MeadowV' 'Edwards' 'Timber' 'Gilbert' 'StoneBr' 'ClearCr' 'NPkVill'\n",
      " 'Blmngtn' 'BrDale' 'SWISU' 'Blueste']\n",
      "\n",
      "Condition1\n",
      "['Norm' 'Feedr' 'PosN' 'Artery' 'RRAe' 'RRNn' 'RRAn' 'PosA' 'RRNe']\n",
      "\n",
      "Condition2\n",
      "['Norm' 'Artery' 'RRNn' 'Feedr' 'PosN' 'PosA' 'RRAn' 'RRAe']\n",
      "\n",
      "BldgType\n",
      "['1Fam' '2fmCon' 'Duplex' 'TwnhsE' 'Twnhs']\n",
      "\n",
      "HouseStyle\n",
      "['2Story' '1Story' '1.5Fin' '1.5Unf' 'SFoyer' 'SLvl' '2.5Unf' '2.5Fin']\n",
      "\n",
      "RoofStyle\n",
      "['Gable' 'Hip' 'Gambrel' 'Mansard' 'Flat' 'Shed']\n",
      "\n",
      "RoofMatl\n",
      "['CompShg' 'WdShngl' 'Metal' 'WdShake' 'Membran' 'Tar&Grv' 'Roll'\n",
      " 'ClyTile']\n",
      "\n",
      "Exterior1st\n",
      "['VinylSd' 'MetalSd' 'Wd Sdng' 'HdBoard' 'BrkFace' 'WdShing' 'CemntBd'\n",
      " 'Plywood' 'AsbShng' 'Stucco' 'BrkComm' 'AsphShn' 'Stone' 'ImStucc'\n",
      " 'CBlock']\n",
      "\n",
      "Exterior2nd\n",
      "['VinylSd' 'MetalSd' 'Wd Shng' 'HdBoard' 'Plywood' 'Wd Sdng' 'CmentBd'\n",
      " 'BrkFace' 'Stucco' 'AsbShng' 'Brk Cmn' 'ImStucc' 'AsphShn' 'Stone'\n",
      " 'Other' 'CBlock']\n",
      "\n",
      "MasVnrType\n",
      "['BrkFace' 'None' 'Stone' 'BrkCmn' nan]\n",
      "\n",
      "ExterQual\n",
      "['Gd' 'TA' 'Ex' 'Fa']\n",
      "\n",
      "ExterCond\n",
      "['TA' 'Gd' 'Fa' 'Po' 'Ex']\n",
      "\n",
      "Foundation\n",
      "['PConc' 'CBlock' 'BrkTil' 'Wood' 'Slab' 'Stone']\n",
      "\n",
      "BsmtQual\n",
      "['Gd' 'TA' 'Ex' nan 'Fa']\n",
      "\n",
      "BsmtCond\n",
      "['TA' 'Gd' nan 'Fa' 'Po']\n",
      "\n",
      "BsmtExposure\n",
      "['No' 'Gd' 'Mn' 'Av' nan]\n",
      "\n",
      "BsmtFinType1\n",
      "['GLQ' 'ALQ' 'Unf' 'Rec' 'BLQ' nan 'LwQ']\n",
      "\n",
      "BsmtFinType2\n",
      "['Unf' 'BLQ' nan 'ALQ' 'Rec' 'LwQ' 'GLQ']\n",
      "\n",
      "Heating\n",
      "['GasA' 'GasW' 'Grav' 'Wall' 'OthW' 'Floor']\n",
      "\n",
      "HeatingQC\n",
      "['Ex' 'Gd' 'TA' 'Fa' 'Po']\n",
      "\n",
      "CentralAir\n",
      "['Y' 'N']\n",
      "\n",
      "Electrical\n",
      "['SBrkr' 'FuseF' 'FuseA' 'FuseP' 'Mix' nan]\n",
      "\n",
      "KitchenQual\n",
      "['Gd' 'TA' 'Ex' 'Fa']\n",
      "\n",
      "Functional\n",
      "['Typ' 'Min1' 'Maj1' 'Min2' 'Mod' 'Maj2' 'Sev']\n",
      "\n",
      "FireplaceQu\n",
      "[nan 'TA' 'Gd' 'Fa' 'Ex' 'Po']\n",
      "\n",
      "GarageType\n",
      "['Attchd' 'Detchd' 'BuiltIn' 'CarPort' nan 'Basment' '2Types']\n",
      "\n",
      "GarageFinish\n",
      "['RFn' 'Unf' 'Fin' nan]\n",
      "\n",
      "GarageQual\n",
      "['TA' 'Fa' 'Gd' nan 'Ex' 'Po']\n",
      "\n",
      "GarageCond\n",
      "['TA' 'Fa' nan 'Gd' 'Po' 'Ex']\n",
      "\n",
      "PavedDrive\n",
      "['Y' 'N' 'P']\n",
      "\n",
      "PoolQC\n",
      "[nan 'Ex' 'Fa' 'Gd']\n",
      "\n",
      "Fence\n",
      "[nan 'MnPrv' 'GdWo' 'GdPrv' 'MnWw']\n",
      "\n",
      "MiscFeature\n",
      "[nan 'Shed' 'Gar2' 'Othr' 'TenC']\n",
      "\n",
      "SaleType\n",
      "['WD' 'New' 'COD' 'ConLD' 'ConLI' 'CWD' 'ConLw' 'Con' 'Oth']\n",
      "\n",
      "SaleCondition\n",
      "['Normal' 'Abnorml' 'Partial' 'AdjLand' 'Alloca' 'Family']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col, uni_values in zip(non_num_cols, [df[col].unique() for col in non_num_cols]):\n",
    "    print(col)\n",
    "    print(uni_values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigating the output of the previous cell as well as inspecting the content of the documentation\n",
    "# suggests a couple of corrupted values in certain columns such as Exterior2nd\n",
    "\n",
    "# let's define a function to replace these values both in the training and test dataframes\n",
    "\n",
    "def replace_values(col_names:list , wrong_correct:list):\n",
    "    assert (isinstance(col_names, str) and isinstance(wrong_correct, dict)) or all([isinstance(l, dict) for l in wrong_correct]) and isinstance(col_names, list) \n",
    "    global df, df_test\n",
    "    try:\n",
    "        for col, dic in zip(col_names, wrong_correct):\n",
    "            for k, v in dic.items():\n",
    "                df[col] = df[col].replace(k, v)\n",
    "    except:\n",
    "        print(\"Something is wrong check again !!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have the value C (all) is correputed in MSZoning\n",
    "mszoning = \"MSZoning\"\n",
    "correct_mszoning = {\"C (all)\": \"C\"}\n",
    "ext2 = \"Exterior2nd\"\n",
    "correct_ext2 = {\"Brk Cmn\": \"BrkComm\", \"CmentBd\": \"CemntBd\"}\n",
    "\n",
    "ms_ext = [mszoning, ext2]\n",
    "correct = [correct_mszoning, correct_ext2]\n",
    "\n",
    "replace_values(ms_ext, correct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning numerical columns\n",
    "This task is slightly trickier as it might require domain expertise. The main procedure is as follows:\n",
    "1. replace (or drop) values that contradict general common sense, for instance negative areas, months cannot be more than $12$\n",
    "2. consider the relationship between certain rows. values in a certain columns cannot be smaller / larger than the corresponding values in other columns. This step require more careful study of the nature of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n",
      "       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n",
      "       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
      "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
      "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n",
      "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
      "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
      "       'MoSold', 'YrSold', 'y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let's first display the numerical columns\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LotArea', 'MasVnrArea', 'GrLivArea', 'GarageArea', 'PoolArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'WoodDeckSF', 'OpenPorchSF']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# let's consider areas\n",
    "areas = [col for col in num_cols if (\"area\" in col.strip().lower())]\n",
    "# inverstiagating the data description, the term SF generally refers to surface (area)\n",
    "areas.extend([col for col in num_cols if \"SF\" in col.strip()]) \n",
    "print(areas)\n",
    "# verify all values are positive\n",
    "areas_with_neg = [any(df[area] < 0) for area in areas]\n",
    "areas_with_neg = [area for area, a in zip(areas, areas_with_neg) if a]\n",
    "print(areas_with_neg)\n",
    "# as we can see all areas-values are positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data description indicats that \n",
    "* OverallQuall and OverallCond should belong to the interval [1, 10]\n",
    "* YearRemodAdd is year of remodel, thus it should be larger or equal to YearBuilt\n",
    "* The relationship between the the year where the garage was built and the other year features should be investigated.\n",
    "* MSSubClass represents a label encoding of the different types of houses: values should belong to predetermined set of values specified in the data description\n",
    "* MoSold is the month where the house was sold. it should belong to [1, 12]\n",
    "* it might be worthwhile investigatinv any abnormalities in the relationship between \"BsmtFinSF1\", \"BsmtUnfSF\", \"BsmtFinSF2\" and \"TotalBsmtSF\" \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first of all let's define a method to replace the names of features in both training and test datasets\n",
    "\n",
    "def new_col_names(old_new_names:dict):\n",
    "    global df, df_test\n",
    "    try:\n",
    "        df = df.rename(columns=old_new_names)\n",
    "        df_test = df_test.rename(columns=old_new_names)\n",
    "    except:\n",
    "        df_no_col = [col for col in old_new_names.keys if col not in df.columns]\n",
    "        df_test_no_col = [col for col in old_new_names.keys if col not in df_test.columns]\n",
    "        print(\"{cols} are not in the {dataf}\".format(df_no_col, \"training dataset\"))\n",
    "        print(\"{cols} are not in the {dataf}\".format(df_test_no_col, \"test dataset\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_new_cols = {\"OverallQual\": \"qua\", \n",
    "\"OverallCond\": \"cond\", \"YearBuilt\": \"Yb\", \"YearRemodAdd\": \"Yr\", \"MSSubClass\": \"mss\" , \n",
    "\"BsmtFinSF1\": \"bSF1\", \"BsmtFinSF2\": \"bSF2\", \"BsmtUnfSF\": \"bubf\", \"GarageYrBlt\":\"GYb\"}\n",
    "new_col_names(old_new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify the integrity of overall quality and condition features\n",
    "qua = \"qua\"\n",
    "cond = \"cond\"\n",
    "print(all(df[qua].isin(range(1, 11))))\n",
    "print(all(df[cond].isin(range(1, 11))))\n",
    "\n",
    "# verify the remodeling and building years features\n",
    "yb = \"Yb\"\n",
    "yr = \"Yr\"\n",
    "print(df[df[yb] > df[yr]].empty) # the resulting dataframe is empty: no problems with neither of these features\n",
    "\n",
    "# verify the MSubclass features\n",
    "mss = \"mss\"\n",
    "mss_values = [20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 150, 160, 180, 190]\n",
    "\n",
    "print(df[~df[mss].isin(mss_values)].empty) # all values from \"MSsubclass\" feature are under check\n",
    "\n",
    "# verify the month feature\n",
    "\n",
    "print(df[~df[\"MoSold\"].isin(range(1, 13))].empty) # all values of the month feature are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let' define a function that applies a function to either \n",
    "# the whole dataframe or certain columns on the dataframe\n",
    "\n",
    "def apply_functions(funcs, col_names=None):\n",
    "    # either have one function passed that should be applied to the whole dataframe\n",
    "    # or have an equal number of columns and functions where each funtion will be applied to the corresponding column\n",
    "    \n",
    "    all_data = callable(funcs) and col_names is None\n",
    "    col_funcs = True\n",
    "    #  if the funcs argument is indeed a function, then the code below will raise an error \n",
    "    try:\n",
    "        col_funcs = (all([callable(f) for f in funcs]) and len(funcs) == len(col_names))\n",
    "    except:\n",
    "        col_funcs = False\n",
    "    \n",
    "    assert all_data or col_funcs\n",
    "    \n",
    "    global df, df_test\n",
    "    if col_names is None: # if the function is to be applied to the whole dataframe\n",
    "        df = df.apply(funcs, axis=1)\n",
    "        df_test = df_test.apply(funcs, axis=1)\n",
    "    else:\n",
    "        for col, f in zip(col_names, funcs):\n",
    "            df[col] = df[col].apply(f)\n",
    "            df_test[col] = df_test[col].apply(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GYb    Yb    Yr\n",
      "29    1920.0  1927  1950\n",
      "93    1900.0  1910  1998\n",
      "324   1961.0  1967  2007\n",
      "600   2003.0  2005  2005\n",
      "736   1949.0  1950  1950\n",
      "1103  1954.0  1959  1959\n",
      "1376  1925.0  1930  1950\n",
      "1414  1922.0  1923  2000\n",
      "1418  1962.0  1963  1963\n",
      "         GYb    Yb    Yr\n",
      "61    1956.0  1959  1959\n",
      "116   2009.0  2010  2010\n",
      "345   1920.0  1935  1998\n",
      "380   1960.0  1978  1978\n",
      "435   1940.0  1941  1950\n",
      "437   1926.0  1935  1950\n",
      "662   1925.0  1945  1995\n",
      "803   2005.0  2006  2007\n",
      "1049  2005.0  2006  2006\n",
      "True\n",
      "Empty DataFrame\n",
      "Columns: [GYb, Yb, Yr]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [GYb, Yb, Yr]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# let's consider the year where the garage was built\n",
    "gyb = \"GYb\"\n",
    "print(df[df[gyb] < df[yb]][[gyb, yb, yr]])\n",
    "\n",
    "print(df_test[df_test[gyb] < df_test[yb]][[gyb, yb, yr]]) \n",
    "# with few exceptions the year where the garage if it is before the year where the house was built is generally few years earilier\n",
    "# which suggests that the garage was meant to be built with the house, yet the house took slightly longer to complete.\n",
    "\n",
    "# if GYb is less than Yb then we will set to Yb.\n",
    "def set_garage_year(row):\n",
    "    if row[gyb] < row[yb]:\n",
    "        row[gyb] = row[yb]\n",
    "    return row\n",
    "# set the changes in both train and test data\n",
    "print(callable(set_garage_year))\n",
    "apply_functions(set_garage_year)\n",
    "\n",
    "print(df[df[gyb] < df[yb]][[gyb, yb, yr]]) \n",
    "print(df_test[df_test[gyb] < df_test[yb]][[gyb, yb, yr]])\n",
    "# the changes were applied to both data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing missing values\n",
    "The second step is imputing the missing values and making sure no Nan values are passed to our machine learning models. The main procedure is as follows:\n",
    "1. drop all columns with a nan ratio exceeding a certain treshhold\n",
    "2. imput the missing values. The strategy depends mainly on the feature in question:\n",
    "    * if the feature is highly related to other features, then a highly accurate and natural value can be deduced\n",
    "    * some statistical value could be used to impute the missing values\n",
    "    * investigating related features could help come up with an aggregated value when the data is grouped by a number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st strategy: drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage      259\n",
      "Alley           1369\n",
      "MasVnrType         8\n",
      "MasVnrArea         8\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtFinType2      38\n",
      "Electrical         1\n",
      "FireplaceQu      690\n",
      "GarageType        81\n",
      "GYb               81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "PoolQC          1453\n",
      "Fence           1179\n",
      "MiscFeature     1406\n",
      "dtype: int64\n",
      "Index(['Alley', 'PoolQC', 'Fence', 'MiscFeature'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# let's first discover which columns have Nan values\n",
    "nan_values = df.isna().sum()\n",
    "cols_nan = nan_values[nan_values > 0]\n",
    "print(cols_nan)\n",
    "NAN_THRESHOLD = 0.8 # all columns with more than 0.8 nan values will be dropped\n",
    "cols_nan = cols_nan / len(df)\n",
    "# print(cols_nan)\n",
    "cols_nan_drop = cols_nan[cols_nan > NAN_THRESHOLD].index\n",
    "print(cols_nan_drop) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see: Alley, PoolQC, fence and MiscFeature have an extremely high ratio of nan values. \n",
    "before dropping these columns, it is necessary to drop features tightly related to those.  \n",
    "Investigating the data description reveals that:  \n",
    "* PoolQC is related to PoolArea\n",
    "* MiscFeature is related to MiscVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1453\n",
      "Name: PoolArea, dtype: int64\n",
      "197     235000\n",
      "810     181000\n",
      "1170    171000\n",
      "1182    745000\n",
      "1298    160000\n",
      "1386    250000\n",
      "1423    274970\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's better understand those relations\n",
    "pq = \"PoolQC\"\n",
    "pa = \"PoolArea\"\n",
    "print(df[df[pq].isna()][pa].value_counts()) \n",
    "# Nan values are associated with 0 pool area, which means that there is no pool in the first place\n",
    "# an extremely high ratio of houses do not have a pool.\n",
    "# let's consider the prices of houses with pool\n",
    "print(df[~df[pq].isna()][Y]) # we can see that the values too few and quite variant as well\n",
    "# thus is it better to drop this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1406\n",
      "Name: MiscVal, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "misf = \"MiscFeature\"\n",
    "misv = \"MiscVal\"\n",
    "print(df[df[misf].isna()][misv].value_counts()) # we can see that houses with Nan on MiscFeature \n",
    "# have 0 on MiscVal which means that they do not any additional features to mention\n",
    "# both of these features should be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's drop the features in questions\n",
    "cols_nan_drop = cols_nan_drop.values.tolist() + [misv, pa]\n",
    "drop_cols(cols_nan_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd strategy: deduce values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage     259\n",
      "MasVnrType        8\n",
      "MasVnrArea        8\n",
      "BsmtQual         37\n",
      "BsmtCond         37\n",
      "BsmtExposure     38\n",
      "BsmtFinType1     37\n",
      "BsmtFinType2     38\n",
      "Electrical        1\n",
      "FireplaceQu     690\n",
      "GarageType       81\n",
      "GYb              81\n",
      "GarageFinish     81\n",
      "GarageQual       81\n",
      "GarageCond       81\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's consider the columns left with nan values\n",
    "nan_values = df.isna().sum()\n",
    "cols_nan = nan_values[nan_values > 0]\n",
    "print(cols_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values with Nan can be divided into categories:\n",
    "* Masonry veneer \n",
    "* Basement\n",
    "* Garage\n",
    "* FirePlace\n",
    "* LotFrontage (only one column) and Electrical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_nan(col_names:list, fill_values:list):\n",
    "    one = isinstance(col_names, str) and isinstance(fill_values, str)\n",
    "    try:\n",
    "        many = len(col_names) == len(fill_values)\n",
    "    except:\n",
    "        many = False\n",
    "    assert one or many \n",
    "    global df, df_test\n",
    "    if many: \n",
    "        for col, v in zip(col_names, fill_values):\n",
    "            df[col] = df[col].fillna(v)\n",
    "            df_test[col] = df_test[col].fillna(v)\n",
    "    else:\n",
    "        df[col_names] = df[col_names].fillna(fill_values)\n",
    "        df_test[col_names] = df_test[col_names].fillna(fill_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MasVnrArea MasVnrType\n",
      "234          NaN        NaN\n",
      "529          NaN        NaN\n",
      "650          NaN        NaN\n",
      "936          NaN        NaN\n",
      "973          NaN        NaN\n",
      "977          NaN        NaN\n",
      "1243         NaN        NaN\n",
      "1278         NaN        NaN\n"
     ]
    }
   ],
   "source": [
    "# let's consider Masonry Veneer columns\n",
    "msvt = \"MasVnrType\"\n",
    "msva = \"MasVnrArea\"\n",
    "\n",
    "print(df[(df[msvt].isna()) | (df[msva].isna())][[msva, msvt]]) \n",
    "# we can see that type and are either both nan or both non-nan\n",
    "# a reasonable assumption is that there is no Masonry Veneer\n",
    "\n",
    "set_nan([msvt, msva], ['None', 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    81\n",
      "Name: GarageArea, dtype: int64\n",
      "Series([], Name: GYb, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# let's consider the garage columns\n",
    "gt = \"GarageType\"\n",
    "gf = \"GarageFinish\"\n",
    "gc = \"GarageCars\"\n",
    "ga = \"GarageArea\"\n",
    "gcond = \"GarageCond\"\n",
    "gqua = \"GarageQual\"\n",
    "\n",
    "g = [gt, gyb, gf, gc, ga, gcond, gqua]\n",
    "print(df[df[gt].isna() | df[gyb].isna() | df[gf].isna() | df[gcond].isna() | df[gqua].isna()][ga].value_counts())\n",
    "# if any of the garage features in a certain row is set to Nan, then its area is 0\n",
    "# which means there is no garage\n",
    "\n",
    "# let's first consider the Garage built year feature for such rows\n",
    "print(df[df[gt].isna() | df[gf].isna() | df[gcond].isna() | df[gqua].isna()][gyb].value_counts())\n",
    "\n",
    "set_nan(g, [\"NA\", 0, \"NA\", 0, 0, \"NA\", \"NA\"])\n",
    "\n",
    "garage_old_new = {gt: \"gt\", gf:\"gf\", gc:\"gc\", ga:\"ga\", gcond:\"gcond\", gqua:\"gqua\"}\n",
    "\n",
    "new_col_names(garage_old_new)\n",
    "\n",
    "gt = \"gt\"\n",
    "gf = \"gf\"\n",
    "gc = \"gc\"\n",
    "ga = \"ga\"\n",
    "gcond = \"gcond\"\n",
    "gqua = \"gqua\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37\n",
      "Name: bSF1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's consider the basement nan-values\n",
    "bqua = \"BsmtQual\"\n",
    "bcond = \"BsmtCond\"\n",
    "bexp = \"BsmtExposure\"\n",
    "bf2 = \"BsmtFinType2\"\n",
    "bf1 = \"BsmtFinType1\"\n",
    "baf1 = \"bSF1\"\n",
    "baf2 = \"bSF2\"\n",
    "\n",
    "# BsmtQual         37\n",
    "# BsmtCond         37\n",
    "# BsmtExposure     38\n",
    "# BsmtFinType1     37\n",
    "# BsmtFinType2     38\n",
    "\n",
    "print(df[df[bqua].isna() & df[bcond].isna() & df[bexp].isna() & df[bf1].isna() ][baf1].value_counts())\n",
    "# we can assume that Nan values for each of these basement features reflect No basement\n",
    "\n",
    "set_nan([bqua, bcond, bexp, bf1, bf2], [\"NA\"] * 5)\n",
    "# change the basement's features \n",
    "\n",
    "basement_new_old = {bqua: \"bqua\", bcond: \"bcond\", bexp: \"bexp\", bf1:\"bf1\", bf2: \"bf2\"}\n",
    "new_col_names(basement_new_old)\n",
    "\n",
    "bqua = \"bqua\"\n",
    "bcond = \"bcond\"\n",
    "bexp = \"bexp\"\n",
    "bf2 = \"bf2\"\n",
    "bf1 = \"bf1\"\n",
    "baf1 = \"baf1\"\n",
    "baf2 = \"baf2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    690\n",
      "Name: Fireplaces, dtype: int64\n",
      "SBrkr    1334\n",
      "FuseA      94\n",
      "FuseF      27\n",
      "FuseP       3\n",
      "Mix         1\n",
      "Name: Electrical, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# let's check the rest real quick\n",
    "# LotFrontage     259\n",
    "# Electrical        1\n",
    "# FireplaceQu     690\n",
    "\n",
    "firequa = \"FireplaceQu\"\n",
    "firep = \"Fireplaces\"\n",
    "print(df[df[firequa].isna()][firep].value_counts())\n",
    "# so nan values refer to NOn existing fire places\n",
    "set_nan(firequa, \"NA\")\n",
    "\n",
    "e = \"Electrical\"\n",
    "print(df[e].value_counts())\n",
    "lf = \"LotFrontage\"\n",
    "# we can assume that the only missing value is SBrkr with a high statistical possibility\n",
    "# the simplest solution for LotFrontage is to nan values to 0\n",
    "set_nan([e, lf], [\"SBrkr\", 0])\n",
    "\n",
    "fire_new_old = {firequa:\"firequa\", firep:\"firep\"}\n",
    "new_col_names(fire_new_old)\n",
    "\n",
    "firequa = \"firequa\"\n",
    "firep = \"firep\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(df[df.isna()].sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the categorial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's consider once again categorical and numerical features\n",
    "non_num_cols = df.select_dtypes([object_type, cat_type]).columns\n",
    "# print(non_num_cols)\n",
    "num_cols = df.select_dtypes(np.number).columns\n",
    "# print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the current state of the dataframes of later modifications\n",
    "df_cat = df.copy()\n",
    "df_t_cat = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal_non_num = [\"LotShape\", \"Utilities\", \"LandSlope\", \"ExterQual\"\n",
    "# , \"ExterCond\", \"bqua\", \"bcond\", \"bexp\", \"bf1\", \"bf2\", \"Heating\", \"HeatingQC\", \"Electrical\", \n",
    "# \"KitchenQual\", \"Functional\", \"firequa\", \"gf\", \"gqua\", \"gcond\", \"PavedDrive\"]\n",
    " \n",
    "# let's define the orders for each of the ordinal columns\n",
    "usual_levels = [\"NA\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "\n",
    "ordered_levels = {\n",
    "    \"ExterQual\": usual_levels,\n",
    "    \"ExterCond\": usual_levels,\n",
    "    \"bqua\": usual_levels,\n",
    "    \"bcond\": usual_levels,\n",
    "    \"HeatingQC\": usual_levels,\n",
    "    \"KitchenQual\": usual_levels,\n",
    "    \"firequa\": usual_levels,\n",
    "    \"gqua\": usual_levels,\n",
    "    \"gcond\": usual_levels,\n",
    "    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n",
    "    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n",
    "    \"bexp\": [\"NA\", \"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    \"bf1\": [\"NA\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"bf2\": [\"NA\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    \"gf\": [\"NA\", \"Unf\", \"RFn\", \"Fin\"],\n",
    "    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n",
    "    \"CentralAir\": [\"N\", \"Y\"],\n",
    "    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's encode ordinal data\n",
    "def cat_to_ord(col:list, categories:list, ordered:bool=True):\n",
    "    global df, df_test\n",
    "    final_cat = categories if ordered else categories[::-1]\n",
    "    df[col] = df[col].apply(dict(zip(final_cat, range(0, len(final_cat)))).get)\n",
    "    df_test[col] = df_test[col].apply(dict(zip(final_cat, range(0, len(final_cat)))).get)\n",
    "\n",
    "\n",
    "for k, v in ordered_levels.items():\n",
    "    cat_to_ord(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    906\n",
      "4    488\n",
      "5     52\n",
      "2     14\n",
      "Name: ExterQual, dtype: int64\n",
      "3    1282\n",
      "4     146\n",
      "2      28\n",
      "5       3\n",
      "1       1\n",
      "Name: ExterCond, dtype: int64\n",
      "3    649\n",
      "4    618\n",
      "5    121\n",
      "0     37\n",
      "2     35\n",
      "Name: bqua, dtype: int64\n",
      "3    1311\n",
      "4      65\n",
      "2      45\n",
      "0      37\n",
      "1       2\n",
      "Name: bcond, dtype: int64\n",
      "5    741\n",
      "3    428\n",
      "4    241\n",
      "2     49\n",
      "1      1\n",
      "Name: HeatingQC, dtype: int64\n",
      "3    735\n",
      "4    586\n",
      "5    100\n",
      "2     39\n",
      "Name: KitchenQual, dtype: int64\n",
      "0    690\n",
      "4    380\n",
      "3    313\n",
      "2     33\n",
      "5     24\n",
      "1     20\n",
      "Name: firequa, dtype: int64\n",
      "3    1311\n",
      "0      81\n",
      "2      48\n",
      "4      14\n",
      "5       3\n",
      "1       3\n",
      "Name: gqua, dtype: int64\n",
      "3    1326\n",
      "0      81\n",
      "2      35\n",
      "4       9\n",
      "1       7\n",
      "5       2\n",
      "Name: gcond, dtype: int64\n",
      "0    925\n",
      "1    484\n",
      "2     41\n",
      "3     10\n",
      "Name: LotShape, dtype: int64\n",
      "2    1382\n",
      "1      65\n",
      "0      13\n",
      "Name: LandSlope, dtype: int64\n",
      "1    953\n",
      "3    221\n",
      "4    134\n",
      "2    114\n",
      "0     38\n",
      "Name: bexp, dtype: int64\n",
      "1    430\n",
      "6    418\n",
      "5    220\n",
      "4    148\n",
      "3    133\n",
      "2     74\n",
      "0     37\n",
      "Name: bf1, dtype: int64\n",
      "1    1256\n",
      "3      54\n",
      "2      46\n",
      "0      38\n",
      "4      33\n",
      "5      19\n",
      "6      14\n",
      "Name: bf2, dtype: int64\n",
      "7    1360\n",
      "5      34\n",
      "6      31\n",
      "4      15\n",
      "2      14\n",
      "3       5\n",
      "1       1\n",
      "Name: Functional, dtype: int64\n",
      "1    605\n",
      "2    422\n",
      "3    352\n",
      "0     81\n",
      "Name: gf, dtype: int64\n",
      "2    1340\n",
      "0      90\n",
      "1      30\n",
      "Name: PavedDrive, dtype: int64\n",
      "2    1459\n",
      "0       1\n",
      "Name: Utilities, dtype: int64\n",
      "1    1365\n",
      "0      95\n",
      "Name: CentralAir, dtype: int64\n",
      "4    1335\n",
      "3      94\n",
      "2      27\n",
      "1       3\n",
      "0       1\n",
      "Name: Electrical, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for k in ordered_levels.keys():\n",
    "    print(df[k].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's encode non ordinal data using the label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "non_ord_cat = [cat for cat in non_num_cols if cat not in ordered_levels.keys()]\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in non_ord_cat:\n",
    "    df[col] = le.fit_transform(df[col].values)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureEngineering\n",
    "In this section we will work on improving the performance by creating a number of sythetic features out of the given ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's save the dataframe before introducing any new feature\n",
    "df_base = df.copy()\n",
    "df_test_base = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline performance\n",
    "Creating a baseline model with the initial (left) features gives us a ground on which I base my next decisions. I will use the same performance metric as in the competition. The baseline model would be a sophisticated RandomForest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definining the cross validation procedure\n",
    "from sklearn.model_selection import KFold\n",
    "n_splits = 5 \n",
    "random_state = 3\n",
    "shuffle = True\n",
    "kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted', 'matthews_corrcoef', 'max_error', 'mutual_info_score', 'neg_brier_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_gamma_deviance', 'neg_mean_poisson_deviance', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'neg_root_mean_squared_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'rand_score', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'roc_auc_ovo', 'roc_auc_ovo_weighted', 'roc_auc_ovr', 'roc_auc_ovr_weighted', 'top_k_accuracy', 'v_measure_score']\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.get_scorer_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main score of the competition is the square of log error squared\n",
    "# let's define a function to calculate a model's performance according to this metric\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def model_performance(X, y, model):\n",
    "    global kf, scoring\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(model, X, log_y, cv=5, scoring=scoring)\n",
    "    return np.sqrt(-score.mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15927576428363702\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(Y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_base = RandomForestRegressor(max_depth=5, n_estimators=100, random_state=3)\n",
    "base_score = model_performance(X, y, rf_base)\n",
    "print(base_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Informative features: mutual information\n",
    "The mutual information is quite a powerful and general technique to determine the relevance of features with respect to the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    # discrete features are the ones with type int\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qua             5.786503e-01\n",
       "Neighborhood    5.253900e-01\n",
       "ga              4.927946e-01\n",
       "GrLivArea       4.328080e-01\n",
       "Yb              4.087151e-01\n",
       "                    ...     \n",
       "Condition2      2.664787e-03\n",
       "3SsnPorch       7.615664e-04\n",
       "Street          3.666896e-04\n",
       "Utilities       1.887379e-15\n",
       "MoSold          0.000000e+00\n",
       "Name: MI Scores, Length: 73, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores = make_mi_scores(X, y)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_feats = mi_scores[mi_scores > 0.01].index.values.tolist() + [Y]\n",
    "df = df.loc[:, relevant_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15887773882723472\n"
     ]
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(Y) \n",
    "\n",
    "new_score = model_performance(X, y, rf_base)\n",
    "print(new_score) # a very small gain is achieved out of removing the unformative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qua             0.578650\n",
      "Neighborhood    0.525390\n",
      "ga              0.492795\n",
      "GrLivArea       0.432808\n",
      "Yb              0.408715\n",
      "TotalBsmtSF     0.399518\n",
      "LotArea         0.392427\n",
      "gc              0.360102\n",
      "bqua            0.331398\n",
      "ExterQual       0.325150\n",
      "KitchenQual     0.322472\n",
      "1stFlrSF        0.283265\n",
      "mss             0.278183\n",
      "Yr              0.275659\n",
      "FullBath        0.273156\n",
      "gf              0.262945\n",
      "GYb             0.259218\n",
      "LotFrontage     0.216092\n",
      "firequa         0.209348\n",
      "TotRmsAbvGrd    0.207962\n",
      "Name: MI Scores, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(mi_scores.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's consider the overall quality of a house\n",
    "# as well as the condition\n",
    "x = df.index.values.tolist()\n",
    "plt.scatter(x, df[col].values, color='blue')\n",
    "plt.scatter(x, df[qua].values, color='red')\n",
    "plt.title(\"{col} and quality\".format(col=col))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.plot(kind='scatter', y=Y, x=cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the quality feature on its own is quite informativa however, it is somehow related to other features \n",
    "corr_with_qua = df.corr()[qua]\n",
    "corr_with_qua = corr_with_qua[(corr_with_qua > 0.4) | (corr_with_qua < -0.4)].sort_values()\n",
    "\n",
    "x = df.index.values.tolist()\n",
    "qua_values = df[qua].values\n",
    "\n",
    "# for col in corr_with_qua.index:\n",
    "#     plt.scatter(x, df[col].values, color='blue')\n",
    "#     plt.scatter(x, df[qua].values, color='red')\n",
    "#     plt.title(\"{col} and quality\".format(col=col))\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ds_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "006414dea9a04848ce797b510a25f3f28ac8668e3d3244e777242cca6bed477f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
