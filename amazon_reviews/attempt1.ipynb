{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:21.049919950Z",
     "start_time": "2023-09-17T13:55:20.867618399Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's start with the data and see how it goes\n",
    "import os\n",
    "import pandas as pd\n",
    "HOME = os.getcwd()\n",
    "train_csv = os.path.join(HOME, 'data', 'train.csv')\n",
    "test_csv = os.path.join(HOME, 'data', 'test.csv')\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_test = pd.read_csv(test_csv)\n",
    "# set the columns names to lower case \n",
    "\n",
    "df_train.columns = [c.lower() for c in df_train.columns]\n",
    "df_test.columns = [c.lower() for c in df_test.columns]\n",
    "\n",
    "# remove unnecessary columns\n",
    "df_train.drop(columns=['helpfulness', 'score'], inplace=True)\n",
    "df_test.drop(columns=['helpfulness', 'score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:21.093064586Z",
     "start_time": "2023-09-17T13:55:21.092757Z"
    }
   },
   "outputs": [],
   "source": [
    "# add a small piece of code to call the pytorch_modular code\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "current = HOME\n",
    "while 'src' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "sys.path.append(os.path.join(current, 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:21.094474458Z",
     "start_time": "2023-09-17T13:55:21.092989816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Golden Valley Natural Buffalo Jerky</td>\n",
       "      <td>The description and photo on this product need...</td>\n",
       "      <td>grocery gourmet food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Westing Game</td>\n",
       "      <td>This was a great book!!!! It is well thought t...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Westing Game</td>\n",
       "      <td>I am a first year teacher, teaching 5th grade....</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Westing Game</td>\n",
       "      <td>I got the book at my bookfair at school lookin...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I SPY A is For Jigsaw Puzzle 63pc</td>\n",
       "      <td>Hi! I'm Martine Redman and I created this puzz...</td>\n",
       "      <td>toys games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0  Golden Valley Natural Buffalo Jerky   \n",
       "1                         Westing Game   \n",
       "2                         Westing Game   \n",
       "3                         Westing Game   \n",
       "4    I SPY A is For Jigsaw Puzzle 63pc   \n",
       "\n",
       "                                                text              category  \n",
       "0  The description and photo on this product need...  grocery gourmet food  \n",
       "1  This was a great book!!!! It is well thought t...            toys games  \n",
       "2  I am a first year teacher, teaching 5th grade....            toys games  \n",
       "3  I got the book at my bookfair at school lookin...            toys games  \n",
       "4  Hi! I'm Martine Redman and I created this puzz...            toys games  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:21.096717811Z",
     "start_time": "2023-09-17T13:55:21.093288265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PetSafe Staywell Pet Door with Clear Hard Flap</td>\n",
       "      <td>We've only had it installed about 2 weeks. So ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Kaytee Timothy Cubes, 1-Pound</td>\n",
       "      <td>My bunny had a hard time eating this because t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Body Back Buddy</td>\n",
       "      <td>would never in a million years have guessed th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SnackMasters California Style Turkey Jerky</td>\n",
       "      <td>Being the jerky fanatic I am, snackmasters han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Premier Busy Buddy Tug-a-Jug Treat Dispensing ...</td>\n",
       "      <td>Wondered how quick my dog would catch on to th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0     PetSafe Staywell Pet Door with Clear Hard Flap   \n",
       "1   1                      Kaytee Timothy Cubes, 1-Pound   \n",
       "2   2                                    Body Back Buddy   \n",
       "3   3         SnackMasters California Style Turkey Jerky   \n",
       "4   4  Premier Busy Buddy Tug-a-Jug Treat Dispensing ...   \n",
       "\n",
       "                                                text  \n",
       "0  We've only had it installed about 2 weeks. So ...  \n",
       "1  My bunny had a hard time eating this because t...  \n",
       "2  would never in a million years have guessed th...  \n",
       "3  Being the jerky fanatic I am, snackmasters han...  \n",
       "4  Wondered how quick my dog would catch on to th...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:21.096915401Z",
     "start_time": "2023-09-17T13:55:21.093470176Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "try:\n",
    "    STOP_WORDS = list(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    STOP_WORDS = list(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:21.097212598Z",
     "start_time": "2023-09-17T13:55:21.093713953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See the title of this review. Fortunately, I am a packrat, and kept a bunch of hole repair kits from various blow up things that we have gone through over the years. Does not come with a hole repair kit though, just to warn you. Anyway, it is back in black and bouncing our 3 year old all over the place. Indoor only, I would say. Very highly recommended, in spite of a hole within a week of use. Hope that this is the first and last one... probably not.\n",
      "see title review . fortunately , packrat , kept bunch hole repair kits various blow things gone years . come hole repair kit though , warn . anyway , back black bouncing year old place . indoor , would say . highly recommended , spite hole within week use . hope first last one ... probably .\n"
     ]
    }
   ],
   "source": [
    "# preprocessing functions\n",
    "import re\n",
    "from typing import List\n",
    "\n",
    "def to_lower(text: str) -> str:\n",
    "    return text.lower()\n",
    "\n",
    "def no_extra_spaces(text: str) -> str:\n",
    "    return re.sub('\\s+', ' ', text)\n",
    "\n",
    "def no_extra_chars(text: str) -> str:\n",
    "    return re.sub(r'[^a-zA-Z\\s,!.;:-]+', ' ', text) \n",
    "\n",
    "text = 'aaa5531--==-||\"z2::,.a'\n",
    "\n",
    "def remove_stop_words(text: str,\n",
    "                      tokenizer: TweetTokenizer = None) -> str:\n",
    "    text = to_lower(text)    \n",
    "    tokenizer = TweetTokenizer() if tokenizer is None else tokenizer\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    # if the remove_stop_words argument is set to True, then filter stop words\n",
    "    tokens = [t.strip() for t in tokens if t not in STOP_WORDS] \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def process(text: str) -> str:\n",
    "    # first lower, remove extrac chracters\n",
    "    text1 = to_lower(no_extra_chars(text))\n",
    "    # remove redundant words\n",
    "    text2 = remove_stop_words(text1)\n",
    "    # remove extra spaces\n",
    "    return no_extra_spaces(text2)\n",
    "\n",
    "import random\n",
    "random.seed(69)\n",
    "example = df_train['text'][int(random.random() * len(df_train))]\n",
    "print(example)\n",
    "print(process(example))\n",
    "\n",
    "# # drop the 'text' column as only the title will be used for classification\n",
    "df_train.drop(columns=['text'], inplace=True)\n",
    "df_test.drop(columns=['text'], inplace=True)\n",
    "\n",
    "# 16 rows have missing values in the 'title' column, remove them\n",
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:21.097504435Z",
     "start_time": "2023-09-17T13:55:21.093860678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title       0\n",
      "category    0\n",
      "dtype: int64\n",
      "####################################################################################################\n",
      "id       0\n",
      "title    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isna().sum())\n",
    "print(\"#\" * 100)\n",
    "print(df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:28.263882527Z",
     "start_time": "2023-09-17T13:55:21.093991142Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cat2idx = {\n",
    "    'toys games': 0,\n",
    "    'health personal care': 1,\n",
    "    'beauty': 2,\n",
    "    'baby products': 3,\n",
    "    'pet supplies': 4,\n",
    "    'grocery gourmet food': 5,\n",
    "}\n",
    "\n",
    "idx2cat = {\n",
    "    0:'toys games',\n",
    "    1:'health personal care',\n",
    "    2:'beauty',\n",
    "    3:'baby products',\n",
    "    4:'pet supplies',\n",
    "    5:'grocery gourmet food' \n",
    "}\n",
    "\n",
    "# making sure the dataframes are ready for training\n",
    "def df_process_data(row):\n",
    "    if isinstance(row['title'], float):\n",
    "        row['title'] = random.choice(list(cat2idx.keys()))\n",
    "        return row\n",
    "    row['title'] = process(row['title'])\n",
    "    return row\n",
    "\n",
    "def df_process_labels(row):\n",
    "    row['category'] = process(row['category'])\n",
    "    # map it to an integer\n",
    "    row['category'] = cat2idx[row['category']]\n",
    "    return row\n",
    "\n",
    "# process the fields\n",
    "df_train = df_train.apply(df_process_data, axis=1)\n",
    "# process the labels\n",
    "df_train = df_train.apply(df_process_labels, axis=1)\n",
    "# process the data is the test split\n",
    "df_test = df_test.apply(df_process_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:28.278018893Z",
     "start_time": "2023-09-17T13:55:28.265548448Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(df_train, test_size=0.15, stratify=df_train['category'], random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.050319218Z",
     "start_time": "2023-09-17T13:55:28.277831762Z"
    }
   },
   "outputs": [],
   "source": [
    "# in the rest of the code I will be using the d\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "CHECKPOINT = 'distilbert-base-uncased' # let's keep it simple as for the first iteration\n",
    "MODEL = AutoModel.from_pretrained(CHECKPOINT).to(DEVICE)\n",
    "TOKENIZER = AutoTokenizer.from_pretrained(CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.093210680Z",
     "start_time": "2023-09-17T13:55:29.092817012Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def collate_function(batch: List[str]):\n",
    "    # batch will represent a list of tuples (text, category) \n",
    "    x, y = [list(row) for row in zip(*batch)]\n",
    "    # convert both labels and data to tensors\n",
    "    y_tensor = torch.FloatTensor(y).to(device=DEVICE)\n",
    "    embeddings = MODEL(**TOKENIZER(x, padding=True, return_tensors='pt').to(DEVICE)).last_hidden_state # make sure to return tensors\n",
    "    return embeddings.to(DEVICE), y_tensor\n",
    "\n",
    "# let's create a dataset object really quick:\n",
    "class LabeledReviewDS(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[str, int]:\n",
    "        return tuple(self.data.iloc[index, :2])\n",
    "\n",
    "# let's set the random seed\n",
    "\n",
    "torch.manual_seed(69)\n",
    "\n",
    "train_ds = LabeledReviewDS(train_data)\n",
    "val_ds = LabeledReviewDS(val_data)\n",
    "\n",
    "# create the dataloaders\n",
    "train_dl = DataLoader(dataset=train_ds, batch_size=32, shuffle=True, collate_fn=collate_function, drop_last=True)\n",
    "val_dl = DataLoader(dataset=val_ds, batch_size=32, shuffle=False, collate_fn=collate_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.093530619Z",
     "start_time": "2023-09-17T13:55:29.093114069Z"
    }
   },
   "outputs": [],
   "source": [
    "# next(iter(train_dl))\n",
    "# looks our data is loaded and ready to go, time to build a model!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train A model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.094325168Z",
     "start_time": "2023-09-17T13:55:29.093361853Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn.functional import leaky_relu\n",
    "\n",
    "class SeqClassModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                in_features: int,\n",
    "                hidden_size: int, \n",
    "                num_classes: int, \n",
    "                num_layers: int = 2, \n",
    "                dropout: float=0.25, \n",
    "                *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.output_units = num_classes if num_classes > 2 else 1\n",
    "        self.rnn = nn.LSTM(input_size=in_features, \n",
    "                           hidden_size=hidden_size, \n",
    "                           dropout=dropout, \n",
    "                           num_layers=num_layers,\n",
    "                           bidirectional=True, # bidiretional RNN are more powerful\n",
    "                           batch_first=True # easier manipulation\n",
    "                           )\n",
    "        # 2: comes from the fact that the lstm is bidirectional, the rest is similar to the LSTM documention Pytorch\n",
    "        linear_input_dim = 2 * num_layers * hidden_size \n",
    "        self.batch_layer= nn.BatchNorm1d(num_features=linear_input_dim)\n",
    "        # self.relu_layer = nn.LeakyReLU()\n",
    "        self.head = nn.Linear(in_features=linear_input_dim, out_features=self.output_units)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # first pass it through the rnn\n",
    "        _, (hidden_state, _) = self.rnn(x)\n",
    "        batch_size = hidden_state.shape[1]\n",
    "        hidden_state = hidden_state.permute((1, 0, 2)).reshape((batch_size, -1))\n",
    "        # # first permuting channels: batch_size as dimensions '0' \n",
    "        # hidden_state = hidden_state.permute((1, 0, 2))\n",
    "        # # only only the last lstm layer\n",
    "        # hidden_state = hidden_state[:, -2:, :]\n",
    "        # hidden_state = hidden_state.reshape((batch_size, -1))\n",
    "        return self.head.forward(self.batch_layer(hidden_state))\n",
    "        # return self.head.forward(self.relu_layer(self.batch_layer(hidden_state)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:29.094486140Z",
     "start_time": "2023-09-17T13:55:29.093505082Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LinearLR\n",
    "from torchmetrics.classification import MulticlassF1Score, MulticlassAccuracy\n",
    "\n",
    "base_model = SeqClassModel(in_features=768, hidden_size=128, num_classes=6)\n",
    "optimizer = AdamW(base_model.parameters(), lr=0.01)\n",
    "scheduler = LinearLR(optimizer, start_factor=1.0, end_factor=0.005, total_iters=100)\n",
    "\n",
    "accuracy_metric, f1_metric = MulticlassAccuracy(num_classes=6), MulticlassF1Score(num_classes=6)\n",
    "\n",
    "metrics = {'accuracy': accuracy_metric, 'f1_score': f1_metric}\n",
    "\n",
    "train_configuration = {'optimizer': optimizer,\n",
    "                        'scheduler': scheduler,\n",
    "                        'min_val_loss': 10 ** -4,\n",
    "                        'max_epochs': 100,\n",
    "                        'report_epoch': 5,\n",
    "                        'device': DEVICE, \n",
    "                        'metrics': metrics,\n",
    "                        'min_no_improve': 30\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:58.229534101Z",
     "start_time": "2023-09-17T13:55:29.093614286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: /home/ayhem18/DEV/My_Kaggle_Repo/amazon_reviews/runs/experience_6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:52<16:40, 52.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.680714331665506\n",
      "train_accuracy: 0.7586159706115723\n",
      "train_f1_score: 0.7343811988830566\n",
      "validation loss : 0.6809739673391302\n",
      "val_accuracy: 0.810369074344635\n",
      "val_f1_score: 0.7453927397727966\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:38<14:59, 52.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.44238820355631087\n",
      "train_accuracy: 0.8516687154769897\n",
      "train_f1_score: 0.8318035006523132\n",
      "validation loss : 0.5804920851233157\n",
      "val_accuracy: 0.816575288772583\n",
      "val_f1_score: 0.7782259583473206\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [04:24<13:14, 52.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3667366786416192\n",
      "train_accuracy: 0.8805881142616272\n",
      "train_f1_score: 0.8617884516716003\n",
      "validation loss : 0.46923734073309187\n",
      "val_accuracy: 0.8398057222366333\n",
      "val_f1_score: 0.8245567679405212\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [06:10<11:26, 52.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.38004005505315774\n",
      "train_accuracy: 0.8748003244400024\n",
      "train_f1_score: 0.8567957878112793\n",
      "validation loss : 0.4626956706113638\n",
      "val_accuracy: 0.8635684847831726\n",
      "val_f1_score: 0.8376203179359436\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [07:56<09:41, 52.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3419051736649371\n",
      "train_accuracy: 0.8863801956176758\n",
      "train_f1_score: 0.8694953322410583\n",
      "validation loss : 0.41357198226800623\n",
      "val_accuracy: 0.8613713383674622\n",
      "val_f1_score: 0.8489293456077576\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [09:42<07:58, 53.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3186508429424378\n",
      "train_accuracy: 0.8965096473693848\n",
      "train_f1_score: 0.8790865540504456\n",
      "validation loss : 0.37639242010389234\n",
      "val_accuracy: 0.8741103410720825\n",
      "val_f1_score: 0.8620558381080627\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [11:29<06:12, 53.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3005223100892708\n",
      "train_accuracy: 0.9033880233764648\n",
      "train_f1_score: 0.8875268697738647\n",
      "validation loss : 0.3644290257919025\n",
      "val_accuracy: 0.8845809698104858\n",
      "val_f1_score: 0.8746466040611267\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [13:16<04:26, 53.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.2797245794482768\n",
      "train_accuracy: 0.9085388779640198\n",
      "train_f1_score: 0.8932546377182007\n",
      "validation loss : 0.39875922308481754\n",
      "val_accuracy: 0.8689279556274414\n",
      "val_f1_score: 0.8550572395324707\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [15:03<02:39, 53.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.25926457989518925\n",
      "train_accuracy: 0.9166027307510376\n",
      "train_f1_score: 0.9020099639892578\n",
      "validation loss : 0.328317925452869\n",
      "val_accuracy: 0.9041745066642761\n",
      "val_f1_score: 0.88588547706604\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [16:48<00:53, 53.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.250880380895992\n",
      "train_accuracy: 0.9156517386436462\n",
      "train_f1_score: 0.9023367762565613\n",
      "validation loss : 0.3987730806495281\n",
      "val_accuracy: 0.8997592926025391\n",
      "val_f1_score: 0.865715503692627\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [17:41<00:00, 53.08s/it]\n"
     ]
    }
   ],
   "source": [
    "import src.pytorch_modular.image_classification.engine_classification as cls\n",
    "\n",
    "results = cls.train_model(base_model, train_dl, val_dl, train_configuration,  \n",
    "                            log_dir=os.path.join(HOME, 'runs'),         \n",
    "                            save_path=os.path.join(HOME, 'saved_models'))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-09-17T13:55:58.229436037Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's make the damn submission\n",
    "from src.pytorch_modular.pytorch_utilities import load_model\n",
    "# base_model = SeqClassModel(in_features=768, hidden_size=128, num_classes=6)\n",
    "# base_model = load_model(base_model=base_model, path=os.path.join(HOME, 'saved_models', '9-17-15-10.pt'))\n",
    "# let's create a dataset object really quick:\n",
    "class TestReviewDS(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index) -> tuple[str, int]:\n",
    "        return self.data.iloc[index, 1]\n",
    "\n",
    "# we need a different callate_function\n",
    "def test_collate_function(batch):\n",
    "    embeddings = MODEL(**TOKENIZER(batch, padding=True, return_tensors='pt').to(DEVICE)).last_hidden_state # make sure to return tensors\n",
    "    return embeddings.to(DEVICE)\n",
    "    \n",
    "# let's set the random seed\n",
    "\n",
    "torch.manual_seed(69)\n",
    "\n",
    "test_ds = TestReviewDS(data=df_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, collate_fn=test_collate_function)\n",
    "# next(iter(test_loader)).shape\n",
    "predictions = cls.inference(base_model, inference_source_data=test_loader, return_tensor='list')\n",
    "# convert the numerical labels to the string ones\n",
    "predictions = [idx2cat[p] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T13:55:58.276032280Z",
     "start_time": "2023-09-17T13:55:58.272755631Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data={\"id\": df_test['id'].tolist(), \"Category\": predictions})\n",
    "sub_dir = os.path.join(HOME, 'submissions')\n",
    "submission.to_csv(os.path.join(sub_dir, f'sub_{len(os.listdir(sub_dir)) + 1}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
