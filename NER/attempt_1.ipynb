{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a piece of code needed to \n",
    "import os \n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current = os.getcwd()\n",
    "while 'src' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "sys.path.append(os.path.join(current, 'src'))\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "random.seed(69)\n",
    "torch.manual_seed(69)\n",
    "np.random.seed(69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with the data and see how it goes\n",
    "import os\n",
    "import pandas as pd\n",
    "HOME = os.getcwd()\n",
    "train_csv = os.path.join(HOME, 'data', 'train.csv')\n",
    "test_csv = os.path.join(HOME, 'data', 'test.csv')\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_test = pd.read_csv(test_csv)\n",
    "# set the columns names to lower case \n",
    "\n",
    "df_train.columns = [c.lower() for c in df_train.columns]\n",
    "df_test.columns = [c.lower() for c in df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>entity</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>true</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>that</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>his</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  entity_id entity   tag\n",
       "0            0          0     It  PRON\n",
       "1            0          1     is  VERB\n",
       "2            0          2   true   ADJ\n",
       "3            0          3   that   ADP\n",
       "4            0          4    his   DET"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first replace any Nan objects by the word 'noun'\n",
    "df_train.fillna(value='noun', inplace=True)\n",
    "df_test.fillna(value='noun', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial implementation: iterate through the rows of \n",
    "def build_sentences(df: pd.DataFrame, train: bool = True):\n",
    "    # the idea is simple\n",
    "    last_id = df.iloc[0, :]['sentence_id']\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    s = []\n",
    "    l = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['sentence_id']\n",
    "        if sid != last_id:\n",
    "            # this means the sentence is new:\n",
    "            sentences.append(s)\n",
    "            s = [row['entity'].lower().strip()]            \n",
    "\n",
    "            if train:\n",
    "                labels.append(l)\n",
    "                l = [row['tag']]\n",
    "        else:\n",
    "            s.append(row['entity'].lower().strip())\n",
    "            if train:\n",
    "                l.append(row['tag'])\n",
    "\n",
    "        last_id = sid\n",
    "\n",
    "    # the last one should be added regardless\n",
    "    sentences.append(s)\n",
    "    s = [row['entity'].lower().strip()]            \n",
    "    if train:\n",
    "        labels.append(l)\n",
    "\n",
    "    if train:\n",
    "        return sentences, labels\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training data as sequences\n",
    "TRAIN_SENTENCES, TRAIN_LABELS = build_sentences(df_train)\n",
    "TEST_SENTENCES = build_sentences(df_test, train=False) \n",
    "# TRAIN_SENTENCES = [\" \".join(tt) for tt in TRAIN_SENTENCES]\n",
    "# TEST_SENTENCES = [\" \".join(tt) for tt in TEST_SENTENCES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some assertions to make sure the data is extracted correctly\n",
    "assert len(TRAIN_SENTENCES) == len(TRAIN_LABELS)\n",
    "for ts, tl in zip(TRAIN_LABELS, TRAIN_LABELS):\n",
    "    assert len(ts) == len(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's map the non-numerical labels to numerical ones for later use\n",
    "import itertools\n",
    "LABELS = set(list(itertools.chain(*TRAIN_LABELS))) \n",
    "\n",
    "# make sure the labels are sorted and unique \n",
    "LABELS = sorted(list(LABELS))\n",
    "lab2idx = dict([(l, i) for l, i in zip(LABELS, range(1, len(LABELS) + 1))])\n",
    "\n",
    "PSEUDO_LABEL = 0\n",
    "idx2lab = dict([(i, l) for l, i in zip(LABELS, range(1, len(LABELS) + 1))])\n",
    "idx2lab[PSEUDO_LABEL] = LABELS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, t in enumerate(TRAIN_LABELS):\n",
    "    TRAIN_LABELS[index] = [lab2idx[token] for token in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(TRAIN_SENTENCES, TRAIN_LABELS, random_state=69, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def yield_tokens():\n",
    "    for s in TRAIN_SENTENCES:\n",
    "        yield s\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(), \n",
    "                                  min_freq=1,\n",
    "                                  specials=special_symbols,\n",
    "                                  special_first=True)\n",
    "vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TrainDS(Dataset):\n",
    "    def __init__(self, data, labels) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "class TestDS(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.data = TEST_SENTENCES\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "train_ds = TrainDS(train_data, train_labels)\n",
    "val_ds = TrainDS(val_data, val_labels)\n",
    "test_ds = TestDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the collate function\n",
    "def collate_train(batch, device: str = DEVICE):\n",
    "    label_list, text_list= [], []\n",
    "    maxi = 0\n",
    "    for x, y in batch:\n",
    "        maxi = max(maxi, len(x))\n",
    "    for x, y in batch:\n",
    "        text_indices = [BOS_IDX] + [vocab[token] for token in x] + [EOS_IDX] + [PAD_IDX] * (maxi - len(x))\n",
    "        labels = [PSEUDO_LABEL] + y + [PSEUDO_LABEL] + [PSEUDO_LABEL for _ in range(maxi - len(x))]\n",
    "        label_list.append(labels)\n",
    "        text_list.append(text_indices)\n",
    "    \n",
    "    label_list = torch.tensor(label_list, dtype=torch.float32)\n",
    "    text_list = torch.tensor(text_list, dtype=torch.int64)\n",
    "\n",
    "    return text_list.to(device), label_list.to(device)\n",
    "\n",
    "def collate_test(batch, device: str = DEVICE):\n",
    "    text_list= []\n",
    "    max_length = len(max(batch, key=len))\n",
    "    text_list = [([BOS_IDX] + [vocab[token] for token in x] + [EOS_IDX] + [PAD_IDX] * (max_length - len(x))) for x in batch]\n",
    "    return torch.tensor(text_list, dtype=torch.int64).to(device)\n",
    "\n",
    "# train the dataset\n",
    "train_dl = DataLoader(train_ds, batch_size=128, shuffle=True, drop_last=True, collate_fn=collate_train)\n",
    "val_dl = DataLoader(val_ds, batch_size=128, shuffle=False, drop_last=False, collate_fn=collate_train)\n",
    "test_dl = DataLoader(test_ds, batch_size=128, shuffle=False, collate_fn=collate_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create the encoder module\n",
    "from torch import nn\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                embedding_dim: int,\n",
    "                hidden_size: int,\n",
    "                num_layers: int = 1, \n",
    "                dropout: float=0.3, \n",
    "                *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(vocab), # the number of tokens in the vocabulary \n",
    "                                      embedding_dim=embedding_dim, # the dimension of the vector representation of each word \n",
    "                                      padding_idx=PAD_IDX # we know the padding index already\n",
    "                                      )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=embedding_dim, \n",
    "                           hidden_size=hidden_size, \n",
    "                           dropout=dropout, \n",
    "                           num_layers=num_layers,\n",
    "                           bidirectional=True, # bidiretional RNN are more powerful\n",
    "                           batch_first=True # easier manipulation\n",
    "                           )\n",
    "        \n",
    "        # 2: comes from the fact that the lstm is bidirectional, the rest is similar to the LSTM documention Pytorch\n",
    "        self.hidden_state_dim = 2 * num_layers * hidden_size     \n",
    "        self.lstm_output_dim = 2 * hidden_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # first pass it through the rnn\n",
    "        rnn_output , (hidden_state, cell_state) = self.rnn(self.dropout(self.embedding(x)))\n",
    "        # the shape according to LSTM documentation are: \n",
    "        # rnn_output: (batch, L, 2 * self.hidden_size)\n",
    "        # hidden_state, cell_state (2 * num_layers, batch, self.hidden_size)\n",
    "        return rnn_output, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                hidden_size, \n",
    "                output_size,\n",
    "                num_layers: int = 1, \n",
    "                dropout: float=0.2): \n",
    "        self.hidden_size = hidden_size\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # the decoder is a sequence model as well \n",
    "        self.rnn = nn.LSTM(1, \n",
    "                           hidden_size, \n",
    "                           batch_first=True, \n",
    "                           num_layers=num_layers, \n",
    "                           dropout=dropout,\n",
    "                           bidirectional=True,\n",
    "                           )\n",
    "        # given a variable number of tensors of size 'hidden_size' return the same number of tesnors but with dimension: 'output_size'\n",
    "        self.classifier = nn.Linear(2 * hidden_size, output_size)\n",
    "\n",
    "    def forward_step(self, decoder_input, decoder_hs, decoder_cs):\n",
    "        # this function expects a decoder_input: of shape: (batch_size, 1, 1)\n",
    "        # decoder_hs should be of the shape (2 * num_layers, )\n",
    "        \n",
    "        output, (hs, cs) = self.rnn(decoder_input, (decoder_hs, decoder_cs))\n",
    "        # output at this stage will be (batch_size, 1, self.hidden_size)\n",
    "        output = self.classifier(output.squeeze(dim=1))\n",
    "        # output at this point is batch_Size, classes\n",
    "        return output, hs, cs\n",
    "\n",
    "    def forward(self, \n",
    "                encoder_hidden_state, \n",
    "                encoder_cell_state,\n",
    "                max_seq_length: int,\n",
    "                batch_size: int = None, \n",
    "                target: torch.Tensor = None,\n",
    "                device=DEVICE):\n",
    "        \n",
    "        if target is None and batch_size is None:\n",
    "            raise ValueError(f\"either the 'batch_size' or the 'target' arguments must be explicitly passed. Both of them are {None}\")\n",
    "\n",
    "    \n",
    "        batch_size = target.dim(0) if target is not None else batch_size\n",
    "        # the first input is of the size (batch_size, L = 1, input_size = hidden_size)\n",
    "        # according to the documentation of the nn.embedding layer, padding_idx are initialized to zero_values\n",
    "        # we are using -1 as the label that represets \n",
    "        decoder_input = torch.empty(size=(batch_size, 1, 1), dtype=torch.float).fill_(value=PSEUDO_LABEL).to(device)\n",
    "\n",
    "        decoder_hidden_state = encoder_hidden_state\n",
    "        decoder_cell_state = encoder_cell_state\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(max_seq_length):\n",
    "            decoder_output, decoder_hidden_state, decoder_cell_state  = self.forward_step(decoder_input, decoder_hidden_state, decoder_cell_state)\n",
    "            # decoder_ouput will be of the shape (batch_size, num_classes)\n",
    "            decoder_outputs.append(decoder_output.unsqueeze(dim=1))\n",
    "\n",
    "            if target is not None:\n",
    "                # using the target tensor is a technique known as Teacher Forcing\n",
    "                # the target is expected to be of shape: (batch, L) (as each label is uni dimensional)\n",
    "                decoder_input = target[:, i].unsqueeze(dim=-1)\n",
    "            else:\n",
    "                _, best_prediction =  decoder_output.topk(1)\n",
    "                # detach (so that the error from the previous output is not propagated further to the rest of the sequence)\n",
    "                # + set to float, as most optimizers work with float data (mainly as input)\n",
    "                decoder_input = best_prediction.unsqueeze(dim=-1).detach().to(torch.float)  \n",
    "        \n",
    "        # the final output should be (batch_size, max_seq_length, classes)\n",
    "        # each element inside the list is of shape: (batch_size, 1, classes)\n",
    "        # they should be stacked according to dim = 1\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        # reduce to classes predictions\n",
    "        # decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) \n",
    "        return decoder_outputs, decoder_hidden_state, decoder_cell_state\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayhem18/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# import optimizer\n",
    "from torch.optim import Adam\n",
    "encoder = EncoderRNN(embedding_dim=100, hidden_size=50)\n",
    "# the output of the encoder\n",
    "decoder = DecoderRNN(hidden_size=50, output_size=len(lab2idx) + 1)\n",
    "\n",
    "e_opt = Adam(encoder.parameters(), lr=0.01)\n",
    "d_opt = Adam(decoder.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "def train_per_epoch(encoder: EncoderRNN,\n",
    "                    decoder: DecoderRNN, \n",
    "                    train_dataloader: DataLoader[torch.tensor],\n",
    "                    loss_function: nn.Module,\n",
    "                    e_opt: torch.optim, \n",
    "                    d_opt: torch.optim,\n",
    "                    device: str = DEVICE,\n",
    "                    ) -> Dict[str, float]:\n",
    "\n",
    "    # set both components to 'train' mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    # set both components to the right 'device'\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    # set the train loss and metrics\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for _, (x, y) in enumerate(train_dataloader):\n",
    "        x.to(device)\n",
    "        y.to(device)\n",
    "        # first set both optimizers to zero gradients\n",
    "        e_opt.zero_grad()\n",
    "        d_opt.zero_grad()\n",
    "\n",
    "        # extract the batch size, sequence length (with padding) \n",
    "        batch_size, seq_length = x.shape\n",
    "\n",
    "        _, hidden_state, cell_state = encoder.forward(x)\n",
    "        # pass the outputs of the encoder to the decoder\n",
    "        decoder_outputs, _ , _ = decoder.forward(hidden_state, cell_state, max_seq_length=seq_length, batch_size=batch_size)\n",
    "\n",
    "        # the decoder's outputs are expected to be of shape (batch_size, seq_length, num_classes)\n",
    "        loss = torch.zeros(size=()) # scalar vector\n",
    "        \n",
    "        for batch_index in range(batch_size):\n",
    "            output_index = decoder_outputs[batch_index]\n",
    "            y_index = y[batch_index].squeeze().to(torch.long)\n",
    "\n",
    "            seq_loss = torch.mean(loss_function(output_index, y_index))\n",
    "            loss = torch.add(loss, seq_loss)\n",
    "        \n",
    "        # average the loss accross the batch\n",
    "        loss /= batch_size \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # take a backward step to calculate the gradients\n",
    "        loss.backward()\n",
    "        # optimize both for encoder and decoder\n",
    "        e_opt.step()\n",
    "        d_opt.step()\n",
    "\n",
    "        y_pred = decoder_outputs.argmax(dim=-1)\n",
    "        train_acc += (y_pred == y).type(torch.float32).mean().item()\n",
    "\n",
    "    train_acc = train_acc / len(train_dataloader)\n",
    "    train_loss = train_loss / len(train_dataloader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_per_epoch(encoder: EncoderRNN,\n",
    "                  decoder: DecoderRNN,\n",
    "                  dataloader: DataLoader[torch.tensor],\n",
    "                  loss_function: nn.Module,\n",
    "                  device=DEVICE\n",
    "                  ) -> Dict[str, float]:\n",
    "\n",
    "    val_loss, val_acc = 0, 0\n",
    "    # set both components to 'train' mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # set both components to the right 'device'\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for _, (x, y) in enumerate(dataloader):\n",
    "            # extract the batch size, sequence length (with padding) \n",
    "            batch_size, seq_length = x.shape\n",
    "\n",
    "            _, hidden_state, cell_state = encoder.forward(x)\n",
    "            # pass the outputs of the encoder to the decoder\n",
    "            decoder_outputs, _ , _ = decoder.forward(hidden_state, cell_state, max_seq_length=seq_length, batch_size=batch_size)\n",
    "\n",
    "            # the decoder's outputs are expected to be of shape (batch_size, seq_length, num_classes)\n",
    "            loss = torch.zeros(size=()) # scalar vector\n",
    "            \n",
    "            for batch_index in range(batch_size):\n",
    "                output_index = decoder_outputs[batch_index]\n",
    "                y_index = y[batch_index].squeeze().to(torch.long)\n",
    "                seq_loss = torch.mean(loss_function(output_index, y_index))\n",
    "                loss = torch.add(loss, seq_loss)\n",
    "            \n",
    "            # average the loss accross the batch\n",
    "            loss /= batch_size\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            y_pred = decoder_outputs.argmax(dim=-1)\n",
    "            val_acc += (y_pred == y).type(torch.float32).mean().item()\n",
    "\n",
    "    # average by epoch\n",
    "    val_acc = val_acc / len(dataloader)\n",
    "    val_loss = val_loss / len(dataloader)\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pytorch_modular.image_classification import utilities as ut, engine_classification as cls\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(\n",
    "                encoder: EncoderRNN, \n",
    "                decoder: DecoderRNN,\n",
    "                train_dataloader: DataLoader[torch.Tensor],\n",
    "                test_dataloader: DataLoader[torch.Tensor],\n",
    "                loss_function,\n",
    "                e_opt, \n",
    "                d_opt,\n",
    "                epochs: int = 5,\n",
    "                log_dir: Optional[Union[Path, str]] = None,\n",
    "                save_path: Optional[Union[Path, str]] = None,\n",
    "                ):\n",
    "\n",
    "    save_path = save_path if save_path is not None else log_dir\n",
    "\n",
    "    performance_dict = {ut.TRAIN_LOSS: [],\n",
    "                        ut.VAL_LOSS: [],\n",
    "                        'train_accuracy': [],\n",
    "                        'val_accuracy': []}\n",
    "    \n",
    "\n",
    "    # best_model, best_loss = None, None\n",
    "    min_training_loss, no_improve_counter, best_model = float('inf'), 0, None\n",
    "\n",
    "    # before proceeding with the training, let's set the summary writer\n",
    "    writer = None if log_dir is None else cls.create_summary_writer(log_dir)\n",
    "\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        epoch_train_loss, epoch_train_acc = train_per_epoch(encoder=encoder,\n",
    "                                                            decoder=decoder,\n",
    "                                                            e_opt=e_opt,\n",
    "                                                            d_opt=d_opt,\n",
    "                                                            train_dataloader=train_dataloader,\n",
    "                                                            loss_function=criterion)\n",
    "\n",
    "        epoch_val_loss, epoch_val_acc = val_per_epoch(encoder=encoder,\n",
    "                                                      decoder=decoder,\n",
    "                                                      dataloader=test_dataloader,\n",
    "                                                      loss_function=loss_function)\n",
    "\n",
    "        epoch_train_metrics = {'accuracy': epoch_train_acc}\n",
    "        epoch_val_metrics = {'accuracy': epoch_val_acc}\n",
    "\n",
    "        no_improve_counter = no_improve_counter + 1 if min_training_loss < epoch_train_loss else 0\n",
    "\n",
    "        if min_training_loss > epoch_train_loss:\n",
    "            # save the model with the lowest training error\n",
    "            min_training_loss = epoch_train_loss\n",
    "\n",
    "            cls._report_performance(epoch_train_loss,\n",
    "                                    epoch_val_loss,\n",
    "                                    epoch_train_metrics,\n",
    "                                    epoch_val_metrics)\n",
    "\n",
    "        # save the model's performance for this epoch\n",
    "        cls._track_performance(performance_dict=performance_dict,\n",
    "                           train_loss=epoch_train_loss,\n",
    "                           val_loss=epoch_val_loss,\n",
    "                           train_metric=epoch_train_metrics,\n",
    "                           val_metrics=epoch_val_metrics)\n",
    "        \n",
    "        cls._set_summary_writer(writer,\n",
    "                            epoch_train_loss=epoch_train_loss,\n",
    "                            epoch_val_loss=epoch_val_loss,\n",
    "                            epoch_train_metrics=epoch_train_metrics,\n",
    "                            epoch_val_metrics=epoch_val_metrics,\n",
    "                            epoch=_\n",
    "                            )\n",
    "\n",
    "        # abort training if 2 conditions were met:\n",
    "        # 1. NO_IMPROVE_STOP is larger than the minimum value\n",
    "        # 2. the training loss did not decrease for consecutive NO_IMPROVE_STOP epochs\n",
    "\n",
    "        # if ut.MIN_NO_IMPROVE_STOP <= train_configuration[ut.NO_IMPROVE_STOP] <= no_improve_counter:\n",
    "        #     warnings.warn(f\"The training loss did not improve for {no_improve_counter} consecutive epochs.\"\n",
    "        #                   f\"\\naborting training!!\", category=RuntimeWarning)\n",
    "        #     break\n",
    "\n",
    "    # if log_dir is not None:\n",
    "    #     save_info(save_path=log_dir, details=details)\n",
    "\n",
    "    # if save_path is not None:\n",
    "    #     save_model(best_model, path=save_path)\n",
    "\n",
    "    return performance_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:25<21:13, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.6384384084144249\n",
      "train_accuracy: 0.7927044842190343\n",
      "validation loss : 0.5000104308128357\n",
      "val_accuracy: 0.8286975997945537\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:52<20:58, 26.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.4744993649019396\n",
      "train_accuracy: 0.8346876437440881\n",
      "validation loss : 0.43475866058598395\n",
      "val_accuracy: 0.8490147499934487\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:18<20:31, 26.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.4227140040820455\n",
      "train_accuracy: 0.8524150821962967\n",
      "validation loss : 0.40155773966208747\n",
      "val_accuracy: 0.8599113459172456\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [01:44<20:01, 26.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.40062445383794204\n",
      "train_accuracy: 0.859926366306878\n",
      "validation loss : 0.3810061336211536\n",
      "val_accuracy: 0.8676801207272903\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [02:10<19:35, 26.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3843888160336781\n",
      "train_accuracy: 0.8651272429914897\n",
      "validation loss : 0.3759720571663069\n",
      "val_accuracy: 0.8663645736549211\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [02:36<19:10, 26.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.38145269668234394\n",
      "train_accuracy: 0.8648108841456803\n",
      "validation loss : 0.37720892416394275\n",
      "val_accuracy: 0.8658137295557105\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [03:02<18:41, 26.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3772246128709739\n",
      "train_accuracy: 0.8646786267240646\n",
      "validation loss : 0.36782406788805255\n",
      "val_accuracy: 0.8685771926589634\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [03:28<18:14, 26.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.36886301266001953\n",
      "train_accuracy: 0.867406167273451\n",
      "validation loss : 0.3622622243736101\n",
      "val_accuracy: 0.8699158559674802\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [03:54<17:45, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3633910666582326\n",
      "train_accuracy: 0.8690385231243566\n",
      "validation loss : 0.3603634047119514\n",
      "val_accuracy: 0.8697890095088793\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [04:20<17:18, 25.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.35465778949959526\n",
      "train_accuracy: 0.8720503014883971\n",
      "validation loss : 0.35203496852646704\n",
      "val_accuracy: 0.8734328980031221\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [04:46<16:50, 25.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3536800705446986\n",
      "train_accuracy: 0.8722343490335155\n",
      "validation loss : 0.3504695289808771\n",
      "val_accuracy: 0.8737068124439406\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [05:11<16:21, 25.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.34802541048655955\n",
      "train_accuracy: 0.8741871259482623\n",
      "validation loss : 0.34620003596596094\n",
      "val_accuracy: 0.8750998429630114\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [06:29<15:01, 25.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3467271219149893\n",
      "train_accuracy: 0.8745330783533932\n",
      "validation loss : 0.34845624507769296\n",
      "val_accuracy: 0.8739308403885883\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [10:45<10:41, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.34125176464836\n",
      "train_accuracy: 0.8781349987819277\n",
      "validation loss : 0.346361768634423\n",
      "val_accuracy: 0.8763255515824193\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [13:20<08:08, 25.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.34082292969077094\n",
      "train_accuracy: 0.8770679532013503\n",
      "validation loss : 0.34895045310258865\n",
      "val_accuracy: 0.874350764181303\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [17:11<04:17, 25.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3386147062436407\n",
      "train_accuracy: 0.8775546393664599\n",
      "validation loss : 0.3396204369871513\n",
      "val_accuracy: 0.8780712342780569\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [18:28<02:59, 25.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.33649270396147457\n",
      "train_accuracy: 0.878408877867196\n",
      "validation loss : 0.33974288209624914\n",
      "val_accuracy: 0.8774375604546588\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [18:54<02:34, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3363799002994164\n",
      "train_accuracy: 0.8783678403628871\n",
      "validation loss : 0.33829960162224976\n",
      "val_accuracy: 0.8779204060202059\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [19:46<01:43, 25.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3354616681746955\n",
      "train_accuracy: 0.8781310685456093\n",
      "validation loss : 0.3367294986610827\n",
      "val_accuracy: 0.8789340853691101\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [21:03<00:25, 25.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3339520150180814\n",
      "train_accuracy: 0.8794513885023558\n",
      "validation loss : 0.3364624002057573\n",
      "val_accuracy: 0.8791823866574661\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [21:29<00:00, 25.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "training loss: 0.3334510827372814\n",
      "train_accuracy: 0.879442945636552\n",
      "validation loss : 0.3380738759170408\n",
      "val_accuracy: 0.8786558858726335\n",
      "#########################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CUDA_LAUNCH_BLOCKING=\"1\"\n",
    "# shit\n",
    "# let's see how the model trains\n",
    "results = train_model(encoder=encoder, \n",
    "            decoder=decoder,\n",
    "            loss_function=criterion, \n",
    "            train_dataloader=train_dl, \n",
    "            test_dataloader=val_dl,\n",
    "            e_opt=e_opt,\n",
    "            d_opt=d_opt,\n",
    "            epochs=50\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(encoder, \n",
    "            decoder, \n",
    "            test_loader: DataLoader[torch.tensor],\n",
    "            device=DEVICE) -> torch.tensor:\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # set both components to the right 'device'\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # iterate through the loader\n",
    "        for x in test_loader:\n",
    "            x.to(device)\n",
    "            # extract the batch size, sequence length (with padding) \n",
    "            batch_size, seq_length = x.shape\n",
    "\n",
    "            _, hidden_state, cell_state = encoder.forward(x)\n",
    "            # pass the outputs of the encoder to the decoder\n",
    "            decoder_outputs, _ , _ = decoder.forward(hidden_state, cell_state, max_seq_length=seq_length, batch_size=batch_size)\n",
    "\n",
    "            y_pred = decoder_outputs.argmax(dim=-1)\n",
    "\n",
    "            predictions.extend([[p for s, p in zip(sen, pred) if s not in [PAD_IDX, BOS_IDX, EOS_IDX]] for (sen, pred) in zip(x, y_pred)])\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_predictions = predict(encoder=encoder, \n",
    "                          decoder=decoder, \n",
    "                          test_loader=test_dl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to convert them to the original labels\n",
    "final_predictions = [[idx2lab[l.item()] for l in num_p] for num_p in num_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the list\n",
    "final_predictions = list(itertools.chain(*final_predictions))\n",
    "results = pd.Series(final_predictions)\n",
    "sub_folder = os.path.join(HOME, 'submissions')\n",
    "sub_path = os.path.join(HOME, 'submissions', f'sub_{len(os.listdir(sub_folder))}.csv')\n",
    "results.to_csv(sub_path, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
