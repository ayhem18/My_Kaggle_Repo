{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a piece of code needed to \n",
    "import os \n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "current = os.getcwd()\n",
    "while 'src' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "sys.path.append(os.path.join(current, 'src'))\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np \n",
    "\n",
    "random.seed(69)\n",
    "torch.manual_seed(69)\n",
    "np.random.seed(69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with the data and see how it goes\n",
    "import os\n",
    "import pandas as pd\n",
    "HOME = os.getcwd()\n",
    "train_csv = os.path.join(HOME, 'data', 'train.csv')\n",
    "test_csv = os.path.join(HOME, 'data', 'test.csv')\n",
    "\n",
    "df_train = pd.read_csv(train_csv)\n",
    "df_test = pd.read_csv(test_csv)\n",
    "# set the columns names to lower case \n",
    "\n",
    "df_train.columns = [c.lower() for c in df_train.columns]\n",
    "df_test.columns = [c.lower() for c in df_test.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>entity_id</th>\n",
       "      <th>entity</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>is</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>true</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>that</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>his</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_id  entity_id entity   tag\n",
       "0            0          0     It  PRON\n",
       "1            0          1     is  VERB\n",
       "2            0          2   true   ADJ\n",
       "3            0          3   that   ADP\n",
       "4            0          4    his   DET"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first replace any Nan objects by the word 'noun'\n",
    "df_train.fillna(value='noun', inplace=True)\n",
    "df_test.fillna(value='noun', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial implementation: iterate through the rows of \n",
    "def build_sentences(df: pd.DataFrame, train: bool = True):\n",
    "    # the idea is simple\n",
    "    last_id = df.iloc[0, :]['sentence_id']\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    s = []\n",
    "    l = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['sentence_id']\n",
    "        if sid != last_id:\n",
    "            # this means the sentence is new:\n",
    "            sentences.append(s)\n",
    "            s = [row['entity'].lower().strip()]            \n",
    "\n",
    "            if train:\n",
    "                labels.append(l)\n",
    "                l = [row['tag']]\n",
    "        else:\n",
    "            s.append(row['entity'].lower().strip())\n",
    "            if train:\n",
    "                l.append(row['tag'])\n",
    "\n",
    "        last_id = sid\n",
    "\n",
    "    # the last one should be added regardless\n",
    "    sentences.append(s)\n",
    "    s = [row['entity'].lower().strip()]            \n",
    "    if train:\n",
    "        labels.append(l)\n",
    "\n",
    "    if train:\n",
    "        return sentences, labels\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the training data as sequences\n",
    "TRAIN_SENTENCES, TRAIN_LABELS = build_sentences(df_train)\n",
    "TEST_SENTENCES = build_sentences(df_test, train=False) \n",
    "# TRAIN_SENTENCES = [\" \".join(tt) for tt in TRAIN_SENTENCES]\n",
    "# TEST_SENTENCES = [\" \".join(tt) for tt in TEST_SENTENCES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some assertions to make sure the data is extracted correctly\n",
    "assert len(TRAIN_SENTENCES) == len(TRAIN_LABELS)\n",
    "for ts, tl in zip(TRAIN_LABELS, TRAIN_LABELS):\n",
    "    assert len(ts) == len(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's map the non-numerical labels to numerical ones for later use\n",
    "import itertools\n",
    "LABELS = set(list(itertools.chain(*TRAIN_LABELS))) \n",
    "# make sure the labels are sorted and unique \n",
    "LABELS = sorted(list(LABELS))\n",
    "lab2idx = dict([(l, i) for l, i in zip(LABELS, range(len(LABELS)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, t in enumerate(TRAIN_LABELS):\n",
    "    TRAIN_LABELS[index] = [lab2idx[token] for token in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(TRAIN_SENTENCES, TRAIN_LABELS, random_state=69, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def yield_tokens():\n",
    "    for s in TRAIN_SENTENCES:\n",
    "        yield s\n",
    "\n",
    "# Define special symbols and indices\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(), \n",
    "                                  min_freq=1,\n",
    "                                  specials=special_symbols,\n",
    "                                  special_first=True)\n",
    "vocab.set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TrainDS(Dataset):\n",
    "    def __init__(self, data, labels) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "class TestDS(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.data = TEST_SENTENCES\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "train_ds = TrainDS(train_data, train_labels)\n",
    "val_ds = TrainDS(val_data, val_labels)\n",
    "test_ds = TestDS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the collate function\n",
    "def collate_train(batch):\n",
    "    label_list, text_list= [], []\n",
    "    maxi = 0\n",
    "    for x, y in batch:\n",
    "        maxi = max(maxi, len(x))\n",
    "    for x, y in batch:\n",
    "        text_indices = [BOS_IDX] + [vocab[token] for token in x] + [EOS_IDX] + [PAD_IDX] * (maxi - len(x))\n",
    "        labels = [-1] + y + [-1] + [-1 for _ in range(maxi - len(x))]\n",
    "        label_list.append(labels)\n",
    "        text_list.append(text_indices)\n",
    "    \n",
    "    label_list = torch.tensor(label_list, dtype=torch.float32)\n",
    "    text_list = torch.tensor(text_list, dtype=torch.int64)\n",
    "\n",
    "    return text_list.to(DEVICE), label_list.to(DEVICE)\n",
    "\n",
    "# train the dataset\n",
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, drop_last=True, collate_fn=collate_train)\n",
    "val_dl = DataLoader(val_ds, batch_size=16, shuffle=False, drop_last=False, collate_fn=collate_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create the encoder module\n",
    "from torch import nn\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                embedding_dim: int,\n",
    "                hidden_size: int,\n",
    "                num_layers: int = 1, \n",
    "                dropout: float=0.3, \n",
    "                *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=len(vocab), # the number of tokens in the vocabulary \n",
    "                                      embedding_dim=embedding_dim, # the dimension of the vector representation of each word \n",
    "                                      padding_idx=PAD_IDX # we know the padding index already\n",
    "                                      )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size=embedding_dim, \n",
    "                           hidden_size=hidden_size, \n",
    "                           dropout=dropout, \n",
    "                           num_layers=num_layers,\n",
    "                           bidirectional=True, # bidiretional RNN are more powerful\n",
    "                           batch_first=True # easier manipulation\n",
    "                           )\n",
    "        \n",
    "        # 2: comes from the fact that the lstm is bidirectional, the rest is similar to the LSTM documention Pytorch\n",
    "        self.hidden_state_dim = 2 * num_layers * hidden_size     \n",
    "        self.lstm_output_dim = 2 * hidden_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # first pass it through the rnn\n",
    "        rnn_output , (hidden_state, cell_state) = self.rnn(self.dropout(self.embedding(x)))\n",
    "        # the shape according to LSTM documentation are: \n",
    "        # rnn_output: (batch, L, 2 * self.hidden_size)\n",
    "        # hidden_state, cell_state (2 * num_layers, batch, self.hidden_size)\n",
    "        return rnn_output, hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                hidden_size, \n",
    "                output_size,\n",
    "                num_layers: int = 1, \n",
    "                dropout: float=0.2): \n",
    "        self.hidden_size = hidden_size\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # the decoder is a sequence model as well \n",
    "        self.rnn = nn.LSTM(1, \n",
    "                           hidden_size, \n",
    "                           batch_first=True, \n",
    "                           num_layers=num_layers, \n",
    "                           dropout=dropout,\n",
    "                           bidirectional=True,\n",
    "                           )\n",
    "        # given a variable number of tensors of size 'hidden_size' return the same number of tesnors but with dimension: 'output_size'\n",
    "        self.classifier = nn.Linear(2 * hidden_size, output_size)\n",
    "\n",
    "    def forward_step(self, decoder_input, decoder_hs, decoder_cs):\n",
    "        # this function expects a decoder_input: of shape: (batch_size, 1, 1)\n",
    "        # decoder_hs should be of the shape (2 * num_layers, )\n",
    "        \n",
    "        output, (hs, cs) = self.rnn(decoder_input, (decoder_hs, decoder_cs))\n",
    "        # output at this stage will be (batch_size, 1, self.hidden_size)\n",
    "        output = self.classifier(output.squeeze(dim=1))\n",
    "        # output at this point is batch_Size, classes\n",
    "        return output, hs, cs\n",
    "\n",
    "    def forward(self, \n",
    "                encoder_hidden_state, \n",
    "                encoder_cell_state,\n",
    "                max_seq_length: int,\n",
    "                batch_size: int = None, \n",
    "                target: torch.Tensor = None):\n",
    "        \n",
    "        if target is None and batch_size is None:\n",
    "            raise ValueError(f\"either the 'batch_size' or the 'target' arguments must be explicitly passed. Both of them are {None}\")\n",
    "\n",
    "    \n",
    "        batch_size = target.dim(0) if target is not None else batch_size\n",
    "        # the first input is of the size (batch_size, L = 1, input_size = hidden_size)\n",
    "        # according to the documentation of the nn.embedding layer, padding_idx are initialized to zero_values\n",
    "        # we are using -1 as the label that represets \n",
    "        decoder_input = torch.empty(size=(batch_size, 1, 1), dtype=torch.float).fill_(value=-1).to(DEVICE)\n",
    "\n",
    "        decoder_hidden_state = encoder_hidden_state\n",
    "        decoder_cell_state = encoder_cell_state\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(max_seq_length):\n",
    "            decoder_output, decoder_hidden_state, decoder_cell_state  = self.forward_step(decoder_input, decoder_hidden_state, decoder_cell_state)\n",
    "            # decoder_ouput will be of the shape (batch_size, num_classes)\n",
    "            decoder_outputs.append(decoder_output.unsqueeze(dim=1))\n",
    "\n",
    "            if target is not None:\n",
    "                # using the target tensor is a technique known as Teacher Forcing\n",
    "                # the target is expected to be of shape: (batch, L) (as each label is uni dimensional)\n",
    "                decoder_input = target[:, i].unsqueeze(dim=-1)\n",
    "            else:\n",
    "                _, best_prediction =  decoder_output.topk(1)\n",
    "                # detach (so that the error from the previous output is not propagated further to the rest of the sequence)\n",
    "                # + set to float, as most optimizers work with float data (mainly as input)\n",
    "                decoder_input = best_prediction.unsqueeze(dim=-1).detach().to(torch.float)  \n",
    "        \n",
    "        # the final output should be (batch_size, max_seq_length, classes)\n",
    "        # each element inside the list is of shape: (batch_size, 1, classes)\n",
    "        # they should be stacked according to dim = 1\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        # reduce to classes predictions\n",
    "        # decoder_outputs = F.log_softmax(decoder_outputs, dim=-1) \n",
    "        return decoder_outputs, decoder_hidden_state, decoder_cell_state\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayhem18/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/ayhem18/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# import optimizer\n",
    "from torch.optim import Adam\n",
    "encoder = EncoderRNN(embedding_dim=100, hidden_size=50)\n",
    "# the output of the encoder\n",
    "decoder = DecoderRNN(hidden_size=50, output_size=len(lab2idx) + 1)\n",
    "\n",
    "e_opt = Adam(encoder.parameters(), lr=0.01)\n",
    "d_opt = Adam(decoder.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "def train_per_epoch(encoder: EncoderRNN,\n",
    "                    decoder: DecoderRNN, \n",
    "                    train_dataloader: DataLoader[torch.tensor],\n",
    "                    loss_function: nn.Module,\n",
    "                    e_opt: torch.optim, \n",
    "                    d_opt: torch.optim,\n",
    "                    device: str = DEVICE,\n",
    "                    ) -> Dict[str, float]:\n",
    "\n",
    "    # set both components to 'train' mode\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    # set both components to the right 'device'\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    # set the train loss and metrics\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for _, (x, y) in enumerate(train_dataloader):\n",
    "        # first set both optimizers to zero gradients\n",
    "        e_opt.zero_grad()\n",
    "        d_opt.zero_grad()\n",
    "\n",
    "        # extract the batch size, sequence length (with padding) \n",
    "        batch_size, seq_length = x.shape\n",
    "\n",
    "        _, hidden_state, cell_state = encoder.forward(x)\n",
    "        # pass the outputs of the encoder to the decoder\n",
    "        decoder_outputs, _ , _ = decoder.forward(hidden_state, cell_state, max_seq_length=seq_length, batch_size=batch_size)\n",
    "\n",
    "        # the decoder's outputs are expected to be of shape (batch_size, seq_length, num_classes)\n",
    "        loss = torch.zeros(size=(batch_size,))\n",
    "        for seq_index in range(seq_length):\n",
    "            output_index = decoder_outputs[seq_index]\n",
    "            y_index = y[seq_index].squeeze().to(torch.long)\n",
    "\n",
    "            seq_loss = loss_function(output_index, y_index)\n",
    "            loss = torch.add(loss, seq_loss)\n",
    "        \n",
    "        # average the loss accross the batch\n",
    "        loss /= batch_size\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # take a backward step to calculate the gradients\n",
    "        loss.backward()\n",
    "        # optimize both for encoder and decoder\n",
    "        e_opt.step()\n",
    "        d_opt.step()\n",
    "\n",
    "        y_pred = decoder_outputs.argmax(dim=-1)\n",
    "        train_acc += (y_pred == y).type(torch.float32).mean().item()\n",
    "\n",
    "    train_acc = train_acc / len(train_dataloader)\n",
    "    train_loss = train_loss / len(train_dataloader)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_per_epoch(encoder: EncoderRNN,\n",
    "                  decoder: DecoderRNN,\n",
    "                  dataloader: DataLoader[torch.tensor],\n",
    "                  loss_function: nn.Module,\n",
    "                  ) -> Dict[str, float]:\n",
    "\n",
    "    val_loss, val_acc = 0, 0\n",
    "    # set both components to 'train' mode\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    # set both components to the right 'device'\n",
    "    encoder.to(DEVICE)\n",
    "    decoder.to(DEVICE)\n",
    "\n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for _, (x, y) in enumerate(dataloader):\n",
    "            # extract the batch size, sequence length (with padding) \n",
    "            batch_size, seq_length = x.shape\n",
    "\n",
    "            rnn_output, hidden_state, cell_state = encoder.forward(x)\n",
    "            # pass the outputs of the encoder to the decoder\n",
    "            decoder_outputs, _ , _ = decoder.forward(rnn_output, hidden_state, cell_state, max_seq_length=seq_length, batch_size=batch_size)\n",
    "\n",
    "            # the decoder's outputs are expected to be of shape (batch_size, seq_length, num_classes)\n",
    "            loss = torch.zeros(size=(batch_size,))\n",
    "            for seq_index in range(seq_length):\n",
    "                output_index = decoder_outputs[seq_index]\n",
    "                y_index = y[index].squeeze().to(torch.long)\n",
    "                # iterate through each sequence in the batch\n",
    "                seq_loss = loss_function(output_index, y_index)\n",
    "                loss = torch.add(loss, seq_loss)\n",
    "                    \n",
    "            # average the loss accross the batch\n",
    "            loss /= batch_size\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "\n",
    "            y_pred = decoder_outputs.argmax(dim=-1)\n",
    "            val_acc += (y_pred == y).type(torch.float32).mean().item()\n",
    "\n",
    "    # average by epoch\n",
    "    val_acc = val_acc / len(dataloader)\n",
    "    val_loss = val_loss / len(dataloader)\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pytorch_modular.image_classification import utilities as ut, engine_classification as cls\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(\n",
    "                encoder: EncoderRNN, \n",
    "                decoder: DecoderRNN,\n",
    "                train_dataloader: DataLoader[torch.Tensor],\n",
    "                test_dataloader: DataLoader[torch.Tensor],\n",
    "                loss_function,\n",
    "                e_opt, \n",
    "                d_opt,\n",
    "                epochs: int = 5,\n",
    "                log_dir: Optional[Union[Path, str]] = None,\n",
    "                save_path: Optional[Union[Path, str]] = None,\n",
    "                ):\n",
    "\n",
    "    save_path = save_path if save_path is not None else log_dir\n",
    "\n",
    "    performance_dict = {ut.TRAIN_LOSS: [],\n",
    "                        ut.VAL_LOSS: []}\n",
    "\n",
    "    # best_model, best_loss = None, None\n",
    "    min_training_loss, no_improve_counter, best_model = float('inf'), 0, None\n",
    "\n",
    "    # before proceeding with the training, let's set the summary writer\n",
    "    writer = None if log_dir is None else cls.create_summary_writer(log_dir)\n",
    "\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        epoch_train_loss, epoch_train_acc = train_per_epoch(encoder=encoder,\n",
    "                                                            decoder=decoder,\n",
    "                                                            e_opt=e_opt,\n",
    "                                                            d_opt=d_opt,\n",
    "                                                            train_dataloader=train_dataloader,\n",
    "                                                            loss_function=criterion)\n",
    "\n",
    "        epoch_val_loss, epoch_val_acc = val_per_epoch(encoder=encoder,\n",
    "                                                      decoder=decoder,\n",
    "                                                      dataloader=test_dataloader,\n",
    "                                                      loss_function=loss_function)\n",
    "\n",
    "        epoch_train_metrics = {'train_loss': epoch_train_loss, 'train_accuracy': epoch_train_acc}\n",
    "        epoch_val_metrics = {'val_loss': epoch_val_loss, 'val_accuracy': epoch_val_acc}\n",
    "\n",
    "        no_improve_counter = no_improve_counter + 1 if min_training_loss < epoch_train_loss else 0\n",
    "\n",
    "        if min_training_loss > epoch_train_loss:\n",
    "            # save the model with the lowest training error\n",
    "            min_training_loss = epoch_train_loss\n",
    "\n",
    "            cls._report_performance(epoch_train_loss,\n",
    "                                epoch_val_loss,\n",
    "                                epoch_train_metrics,\n",
    "                                epoch_val_metrics)\n",
    "\n",
    "        # save the model's performance for this epoch\n",
    "        cls._track_performance(performance_dict=performance_dict,\n",
    "                           train_loss=epoch_train_loss,\n",
    "                           val_loss=epoch_val_loss,\n",
    "                           train_metric=epoch_train_metrics,\n",
    "                           val_metrics=epoch_val_metrics)\n",
    "\n",
    "        cls._set_summary_writer(writer,\n",
    "                            epoch_train_loss=epoch_train_loss,\n",
    "                            epoch_val_loss=epoch_val_loss,\n",
    "                            epoch_train_metrics=epoch_train_metrics,\n",
    "                            epoch_val_metrics=epoch_val_metrics,\n",
    "                            epoch=_\n",
    "                            )\n",
    "\n",
    "        # abort training if 2 conditions were met:\n",
    "        # 1. NO_IMPROVE_STOP is larger than the minimum value\n",
    "        # 2. the training loss did not decrease for consecutive NO_IMPROVE_STOP epochs\n",
    "\n",
    "        # if ut.MIN_NO_IMPROVE_STOP <= train_configuration[ut.NO_IMPROVE_STOP] <= no_improve_counter:\n",
    "        #     warnings.warn(f\"The training loss did not improve for {no_improve_counter} consecutive epochs.\"\n",
    "        #                   f\"\\naborting training!!\", category=RuntimeWarning)\n",
    "        #     break\n",
    "\n",
    "    # if log_dir is not None:\n",
    "    #     save_info(save_path=log_dir, details=details)\n",
    "\n",
    "    # if save_path is not None:\n",
    "    #     save_model(best_model, path=save_path)\n",
    "\n",
    "    return performance_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m CUDA_LAUNCH_BLOCKING\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[39m# shit\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# let's see how the model trains\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m train_model(encoder\u001b[39m=\u001b[39;49mencoder, \n\u001b[1;32m      5\u001b[0m             decoder\u001b[39m=\u001b[39;49mdecoder,\n\u001b[1;32m      6\u001b[0m             loss_function\u001b[39m=\u001b[39;49mcriterion, \n\u001b[1;32m      7\u001b[0m             train_dataloader\u001b[39m=\u001b[39;49mtrain_dl, \n\u001b[1;32m      8\u001b[0m             test_dataloader\u001b[39m=\u001b[39;49mval_dl,\n\u001b[1;32m      9\u001b[0m             e_opt\u001b[39m=\u001b[39;49me_opt,\n\u001b[1;32m     10\u001b[0m             d_opt\u001b[39m=\u001b[39;49md_opt,\n\u001b[1;32m     11\u001b[0m             )\n",
      "Cell \u001b[0;32mIn[39], line 29\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(encoder, decoder, train_dataloader, test_dataloader, loss_function, e_opt, d_opt, epochs, log_dir, save_path)\u001b[0m\n\u001b[1;32m     26\u001b[0m writer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m log_dir \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcreate_summary_writer(log_dir)\n\u001b[1;32m     28\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[0;32m---> 29\u001b[0m     epoch_train_loss, epoch_train_acc \u001b[39m=\u001b[39m train_per_epoch(encoder\u001b[39m=\u001b[39;49mencoder,\n\u001b[1;32m     30\u001b[0m                                                         decoder\u001b[39m=\u001b[39;49mdecoder,\n\u001b[1;32m     31\u001b[0m                                                         e_opt\u001b[39m=\u001b[39;49me_opt,\n\u001b[1;32m     32\u001b[0m                                                         d_opt\u001b[39m=\u001b[39;49md_opt,\n\u001b[1;32m     33\u001b[0m                                                         train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     34\u001b[0m                                                         loss_function\u001b[39m=\u001b[39;49mcriterion)\n\u001b[1;32m     36\u001b[0m     epoch_val_loss, epoch_val_acc \u001b[39m=\u001b[39m val_per_epoch(encoder\u001b[39m=\u001b[39mencoder,\n\u001b[1;32m     37\u001b[0m                                                   decoder\u001b[39m=\u001b[39mdecoder,\n\u001b[1;32m     38\u001b[0m                                                   dataloader\u001b[39m=\u001b[39mtest_dataloader,\n\u001b[1;32m     39\u001b[0m                                                   loss_function\u001b[39m=\u001b[39mloss_function)\n\u001b[1;32m     41\u001b[0m     epoch_train_metrics \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mtrain_loss\u001b[39m\u001b[39m'\u001b[39m: epoch_train_loss, \u001b[39m'\u001b[39m\u001b[39mtrain_accuracy\u001b[39m\u001b[39m'\u001b[39m: epoch_train_acc}\n",
      "Cell \u001b[0;32mIn[37], line 17\u001b[0m, in \u001b[0;36mtrain_per_epoch\u001b[0;34m(encoder, decoder, train_dataloader, loss_function, e_opt, d_opt, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m decoder\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     16\u001b[0m \u001b[39m# set both components to the right 'device'\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m encoder\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     18\u001b[0m decoder\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m \u001b[39m# set the train loss and metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/DEV/My_Kaggle_Repo/kaggle_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "CUDA_LAUNCH_BLOCKING=\"1\"\n",
    "# shit\n",
    "# let's see how the model trains\n",
    "train_model(encoder=encoder, \n",
    "            decoder=decoder,\n",
    "            loss_function=criterion, \n",
    "            train_dataloader=train_dl, \n",
    "            test_dataloader=val_dl,\n",
    "            e_opt=e_opt,\n",
    "            d_opt=d_opt,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
