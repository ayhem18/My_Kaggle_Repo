{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Practical machine learning and deep learning. Lab 4\n","\n","# Many-to-many NLP task.\n","\n","# [Competition](https://www.kaggle.com/t/afa89356762e438cad5f04bf0e23f3ce)\n","\n","## Goal\n","\n","Your goal is to implement Neural Network for tagging the part-of-speech entities.\n","\n","## Submission\n","\n","Submission format is described at competition page.\n","\n","> Remember, you can use any structure of the solution. The template classes/function in this file is just the tip for you. "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:00:01.453145Z","iopub.status.busy":"2023-09-18T08:00:01.452764Z","iopub.status.idle":"2023-09-18T08:00:01.458956Z","shell.execute_reply":"2023-09-18T08:00:01.457734Z","shell.execute_reply.started":"2023-09-18T08:00:01.453113Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","import warnings\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["## Data reading and preprocessing"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:00:02.845257Z","iopub.status.busy":"2023-09-18T08:00:02.844559Z","iopub.status.idle":"2023-09-18T08:00:03.583229Z","shell.execute_reply":"2023-09-18T08:00:03.582223Z","shell.execute_reply.started":"2023-09-18T08:00:02.845221Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv('/kaggle/input/pmldl-week4-many-to-many-nlp-task/train.csv')\n","test = pd.read_csv('/kaggle/input/pmldl-week4-many-to-many-nlp-task/test.csv')"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:00:03.585809Z","iopub.status.busy":"2023-09-18T08:00:03.585410Z","iopub.status.idle":"2023-09-18T08:00:03.600476Z","shell.execute_reply":"2023-09-18T08:00:03.599307Z","shell.execute_reply.started":"2023-09-18T08:00:03.585772Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>entity_id</th>\n","      <th>entity</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>It</td>\n","      <td>PRON</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>is</td>\n","      <td>VERB</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>true</td>\n","      <td>ADJ</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>that</td>\n","      <td>ADP</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>his</td>\n","      <td>DET</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sentence_id  entity_id entity   tag\n","0            0          0     It  PRON\n","1            0          1     is  VERB\n","2            0          2   true   ADJ\n","3            0          3   that   ADP\n","4            0          4    his   DET"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:00:05.145618Z","iopub.status.busy":"2023-09-18T08:00:05.145240Z","iopub.status.idle":"2023-09-18T08:00:05.177975Z","shell.execute_reply":"2023-09-18T08:00:05.176684Z","shell.execute_reply.started":"2023-09-18T08:00:05.145588Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>sentence_id</th>\n","      <th>entity_id</th>\n","      <th>entity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>In</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>another</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>setback</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>yesterday</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>,</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  sentence_id  entity_id     entity\n","0   0            0          0         In\n","1   1            0          1    another\n","2   2            0          2    setback\n","3   3            0          3  yesterday\n","4   4            0          4          ,"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["test.head()"]},{"cell_type":"markdown","metadata":{},"source":["First, let's divide dataset on train and validation. And split the dataframe according to random split."]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:00:29.555970Z","iopub.status.busy":"2023-09-18T08:00:29.555268Z","iopub.status.idle":"2023-09-18T08:00:29.581627Z","shell.execute_reply":"2023-09-18T08:00:29.580711Z","shell.execute_reply.started":"2023-09-18T08:00:29.555937Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","VALIDATION_RATIO = 0.2\n","train_split, val_split = train_test_split(range(train['sentence_id'].max()), test_size=VALIDATION_RATIO, random_state=420)"]},{"cell_type":"markdown","metadata":{},"source":["And then split the original dataframe by ids that we splitted."]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:00:31.255516Z","iopub.status.busy":"2023-09-18T08:00:31.254436Z","iopub.status.idle":"2023-09-18T08:00:31.349488Z","shell.execute_reply":"2023-09-18T08:00:31.348405Z","shell.execute_reply.started":"2023-09-18T08:00:31.255472Z"},"trusted":true},"outputs":[],"source":["train_dataframe = train[train['sentence_id'].isin(train_split)]\n","val_dataframe = train[train['sentence_id'].isin(val_split)]"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:03:24.456282Z","iopub.status.busy":"2023-09-18T08:03:24.455196Z","iopub.status.idle":"2023-09-18T08:03:24.463135Z","shell.execute_reply":"2023-09-18T08:03:24.461861Z","shell.execute_reply.started":"2023-09-18T08:03:24.456245Z"},"trusted":true},"outputs":[],"source":["pos_tags = ['ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRT', 'PRON', 'VERB', '.', 'X']\n","cat2idx = {tag: i for i, tag in enumerate(pos_tags)}\n","idx2cat = {v: k for k, v in cat2idx.items()}\n","\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"]},{"cell_type":"markdown","metadata":{},"source":["For working with datasets more efficiently, let's create separate classes for datasets. \n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:03:59.348445Z","iopub.status.busy":"2023-09-18T08:03:59.348067Z","iopub.status.idle":"2023-09-18T08:03:59.548524Z","shell.execute_reply":"2023-09-18T08:03:59.547557Z","shell.execute_reply.started":"2023-09-18T08:03:59.348413Z"},"trusted":true},"outputs":[],"source":["import torch\n","torch.manual_seed(420)\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","\n","class PosTaggingDataset(torch.utils.data.Dataset):\n","    def __init__(self, dataframe: pd.DataFrame, vocab = None, max_size=100):\n","        self.dataframe = dataframe\n","        self._preprocess()\n","        self.vocab = vocab or self._create_vocab()\n","\n","    def _preprocess(self):\n","        # fill missing values in entities\n","        ...\n","\n","        # Fill missing tag to `other` - `X`\n","        ...\n","\n","        # Clean entities column\n","        ...\n","        \n","        # Split the dataset, so that we will have \n","        # full sentences and full tags by the same index\n","        ...\n","\n","        self.sentences = ...\n","        self.tags = ...\n","    \n","    def _create_vocab(self):\n","        # creates vocabulary that is used for encoding \n","        # the sequence of tokens (splitted sentence)\n","        vocab = ...\n","        return vocab\n","\n","    def _get_sentence(self, index: int) -> list:\n","        # retrieves sentence from dataset by index\n","        ...\n","        return self.vocab(sent)\n","\n","    def _get_labels(self, index: int) -> list:\n","        # retrieves tags from dataset by index\n","        tags = ...\n","        return tags\n","\n","    def __getitem__(self, index) -> tuple[list, list]:\n","        return self._get_sentence(index), self._get_labels(index)\n","    \n","    def __len__(self) -> int:\n","        return len(self.sentences)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:04:00.395736Z","iopub.status.busy":"2023-09-18T08:04:00.395046Z","iopub.status.idle":"2023-09-18T08:04:05.863331Z","shell.execute_reply":"2023-09-18T08:04:05.862306Z","shell.execute_reply.started":"2023-09-18T08:04:00.395684Z"},"trusted":true},"outputs":[],"source":["# Create train dataset\n","train_dataset = ...\n","val_dataset = ..."]},{"cell_type":"markdown","metadata":{},"source":["And now we are able to create dataloader faster, because we created torch datasets"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:08:26.908224Z","iopub.status.busy":"2023-09-18T08:08:26.907869Z","iopub.status.idle":"2023-09-18T08:08:26.919813Z","shell.execute_reply":"2023-09-18T08:08:26.918764Z","shell.execute_reply.started":"2023-09-18T08:08:26.908192Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","max_size = 50\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","def collate_batch(batch: list):\n","    # Collate list of samples into tensor batch\n","    # As an input we have list of pair from dataset:\n","    # [([ent1, ent2, ...], [tag1, tag2, ...]), ([ent1, ent2, ...], [tag1, tag2, ...]), ...]\n","    # as an output, we want to have tensor of entities and tensor of tags \n","    sentences_batch, postags_batch = [], []\n","    for _sent, _postags in batch:\n","        ...\n","\n","    # Remember, that if we want to perform many to many mapping with our network with recurrent units, \n","    # we want pass first item from all sequences as first input, thus\n","    # we want to have tensor with shape (max_size, ...., batch_size)\n","    return ..., ...\n","\n","train_dataloader = ...\n","val_dataloader = ..."]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:08:45.442091Z","iopub.status.busy":"2023-09-18T08:08:45.441732Z","iopub.status.idle":"2023-09-18T08:08:45.462464Z","shell.execute_reply":"2023-09-18T08:08:45.461486Z","shell.execute_reply.started":"2023-09-18T08:08:45.442060Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([50, 128])\n","torch.Size([50, 128])\n"]}],"source":["# just to check that all shapes are correct\n","\n","for batch in train_dataloader:\n","    inp, out = batch\n","    print(inp.shape)\n","    print(out.shape)\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["## Creating the network\n","\n","For the many-to-many or seq2seq netoworks, we want to have recurrent units in the network. This gives the ability for network to learn the hidden features and pass the knowledge from one token to other. \n","\n","### Embeddings\n","\n","For embeddings you can use `nn.Embedding` for creating your own features or use pretrained embedding (like GloVe or FastText or Bert).\n","\n","### Recurrent\n","\n","For processing sequences you can use recurrent units like `LSTM`.\n","\n","### Linear\n","\n","Add simple nn.Linear. ~~This is basic stuff what do you want~~\n","\n","### Regularization\n","\n","Remeber to set up Dropout and Batch Normalization for regularization purposes."]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:15:59.837253Z","iopub.status.busy":"2023-09-18T08:15:59.836884Z","iopub.status.idle":"2023-09-18T08:15:59.846976Z","shell.execute_reply":"2023-09-18T08:15:59.845829Z","shell.execute_reply.started":"2023-09-18T08:15:59.837224Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","\n","class POSTagger(nn.Module):\n","    def __init__(self,  ...):\n","        \n","        super().__init__()\n","        \n","        ...\n","    def forward(self, text):\n","\n","        # text shape= [sent len, batch size]\n","        \n","        ...\n","        \n","        # predictions shape = [sent len, batch size, output dim]\n","        return predictions"]},{"cell_type":"markdown","metadata":{},"source":["## Training\n","\n","As for training you should take into account that the shape of your output and shape of the labels. Perform required transformations and use loss function that fits your task.\n","\n","> Do not forget about tqdm and logging, you want normal training not some unreadable ~~sht~~ logs. "]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:18:44.904098Z","iopub.status.busy":"2023-09-18T08:18:44.903728Z","iopub.status.idle":"2023-09-18T08:18:44.920970Z","shell.execute_reply":"2023-09-18T08:18:44.919987Z","shell.execute_reply.started":"2023-09-18T08:18:44.904066Z"},"trusted":true},"outputs":[],"source":["from tqdm.autonotebook import tqdm\n","\n","def train_one_epoch(\n","    model,\n","    loader,\n","    optimizer,\n","    loss_fn,\n","    epoch_num=-1\n","):\n","    loop = tqdm(\n","        enumerate(loader, 1),\n","        total=len(loader),\n","        desc=f\"Epoch {epoch}: train\",\n","        leave=True,\n","    )\n","    model.train()\n","    train_loss = 0.0\n","    total = 0\n","    for i, batch in loop:\n","        texts, labels = batch\n","        \n","        ...\n","\n","        loop.set_postfix({\"loss\": train_loss/total})\n","\n","def val_one_epoch(\n","    model,\n","    loader,\n","    loss_fn,\n","    epoch_num=-1,\n","    best_so_far=0.0,\n","    ckpt_path='best.pt'\n","):\n","    \n","    loop = tqdm(\n","        enumerate(loader, 1),\n","        total=len(loader),\n","        desc=f\"Epoch {epoch}: val\",\n","        leave=True,\n","    )\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        model.eval()  # evaluation mode\n","        for i, batch in loop:\n","            texts, labels = batch\n","\n","            ...\n","\n","            loop.set_postfix({\"loss\": val_loss/total, \"acc\": correct / total})\n","        \n","        if correct / total > best:\n","            ...\n","\n","    return best_so_far"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:24:11.673902Z","iopub.status.busy":"2023-09-18T08:24:11.673094Z","iopub.status.idle":"2023-09-18T08:24:11.734966Z","shell.execute_reply":"2023-09-18T08:24:11.734053Z","shell.execute_reply.started":"2023-09-18T08:24:11.673866Z"},"trusted":true},"outputs":[],"source":["INPUT_DIM = len(train_dataset.vocab)\n","OUTPUT_DIM = len(pos_tags)\n","\n","...\n","\n","\n","model = ....to(device)\n","\n","optimizer = ...\n","loss_fn = ..."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:24:12.375499Z","iopub.status.busy":"2023-09-18T08:24:12.374478Z","iopub.status.idle":"2023-09-18T08:27:34.116975Z","shell.execute_reply":"2023-09-18T08:27:34.115857Z","shell.execute_reply.started":"2023-09-18T08:24:12.375455Z"},"trusted":true},"outputs":[],"source":["best = -float('inf')\n","num_epochs = ...\n","for epoch in range(num_epochs):\n","    train_one_epoch(model, train_dataloader, optimizer, loss_fn, epoch_num=epoch)\n","    best_so_far = val_one_epoch(model, val_dataloader, loss_fn, epoch, best_so_far=best)"]},{"cell_type":"markdown","metadata":{},"source":["# Predictions\n","\n","Write prediction. That's it. No more instructions, you already made it 3 times."]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:28:20.107494Z","iopub.status.busy":"2023-09-18T08:28:20.107085Z","iopub.status.idle":"2023-09-18T08:28:21.272345Z","shell.execute_reply":"2023-09-18T08:28:21.271329Z","shell.execute_reply.started":"2023-09-18T08:28:20.107463Z"},"trusted":true},"outputs":[],"source":["# you can use the same dataset class\n","test_dataset = ..."]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:28:21.274793Z","iopub.status.busy":"2023-09-18T08:28:21.274161Z","iopub.status.idle":"2023-09-18T08:28:21.294821Z","shell.execute_reply":"2023-09-18T08:28:21.293881Z","shell.execute_reply.started":"2023-09-18T08:28:21.274757Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","\n","# remebder that for training we can use pads but for testing we need to write \n","# exact length of the sentence into the seubmission\n","def collate_batch(batch: list):\n","    sentences_batch, sentences_lengths = [], []\n","    for _sent, _ in batch:\n","        ...\n","\n","    return ...\n","\n","test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:28:21.297045Z","iopub.status.busy":"2023-09-18T08:28:21.296388Z","iopub.status.idle":"2023-09-18T08:28:21.308636Z","shell.execute_reply":"2023-09-18T08:28:21.307624Z","shell.execute_reply.started":"2023-09-18T08:28:21.297010Z"},"trusted":true},"outputs":[],"source":["def predict(\n","    model,\n","    loader,\n","):\n","    loop = tqdm(\n","        enumerate(loader, 1),\n","        total=len(loader),\n","        desc=f\"Predictions\",\n","        leave=True,\n","    )\n","    predictions = []\n","    with torch.no_grad():\n","        model.eval()  # evaluation mode\n","        for i, batch in loop:\n","            ...\n","\n","    return predictions"]},{"cell_type":"code","execution_count":44,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:28:21.556273Z","iopub.status.busy":"2023-09-18T08:28:21.555980Z","iopub.status.idle":"2023-09-18T08:28:24.133156Z","shell.execute_reply":"2023-09-18T08:28:24.132149Z","shell.execute_reply.started":"2023-09-18T08:28:21.556248Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8df1e5c66c54d0fb91e8ad76dd1cff4","version_major":2,"version_minor":0},"text/plain":["Predictions:   0%|          | 0/113 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["[1, 4, 5, 5, 10, 5, 7, 5, 5, 9]"]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["ckpt = torch.load(\"best.pt\")\n","model.load_state_dict(ckpt)\n","\n","predictions = predict(model, test_dataloader)\n","predictions[:10]"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:28:24.136096Z","iopub.status.busy":"2023-09-18T08:28:24.135242Z","iopub.status.idle":"2023-09-18T08:28:25.033942Z","shell.execute_reply":"2023-09-18T08:28:25.032807Z","shell.execute_reply.started":"2023-09-18T08:28:24.136058Z"},"trusted":true},"outputs":[],"source":["results = pd.Series(predictions).apply(lambda x: idx2cat[x])\n","results.to_csv('submission.csv', index_label='id')"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2023-09-18T08:28:25.036048Z","iopub.status.busy":"2023-09-18T08:28:25.035507Z","iopub.status.idle":"2023-09-18T08:28:25.045347Z","shell.execute_reply":"2023-09-18T08:28:25.044276Z","shell.execute_reply.started":"2023-09-18T08:28:25.036000Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0          ADP\n","1          DET\n","2         NOUN\n","3         NOUN\n","4            .\n","          ... \n","303020    NOUN\n","303021     PRT\n","303022    VERB\n","303023    NOUN\n","303024       .\n","Length: 303025, dtype: object"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
